{"summary": "- Asynchronously processes OpenAI API ChatCompletion responses.\n- Input: `response` (ChatCompletion), optional `response_model` (type of expected model), `stream` flag, `validation_context`, `strict` flag, and processing `mode`.\n- If no `response_model` provided, returns raw `ChatCompletion`.\n- For streaming responses with models subclassing `IterableBase` or `PartialBase`, uses `from_streaming_response_async` to build model.\n- Otherwise, constructs model via `response_model.from_response` with validation and mode options.\n- Handles special cases:\n  - If model is `IterableBase`, returns list of its tasks.\n  - If `response_model` is `ParallelBase`, returns the model directly.\n  - If model is `AdapterBase`, returns its `content`.\n- Attaches raw response to model (`_raw_response`) before returning.\n- Output: processed model instance (or list/content) or raw `ChatCompletion` if no model specified.", "prompt_id": "28ad819ea97a795ed2ae85e64d974c5c", "created_at": "2026-02-04T20:43:20.565855"}