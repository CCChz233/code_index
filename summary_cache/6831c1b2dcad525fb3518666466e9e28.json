{"summary": "- The function `update_total_usage` aggregates token usage statistics from a response object into a cumulative usage tracker.\n- Input parameters:\n  - `response` (optional): An object of a type derived from `Response` that may contain a `usage` attribute with token counts.\n  - `total_usage`\u00a0:\u00a0\u00a0the\u00a0\u00a0\u00a0\u00a0\u00a0... ... ... ... ... ... ... ... ... ... \nWe need to produce final answer: a summary in Chinese (or Chinese/English) focusing on business logic, inputs, outputs. Must start directly with summary content, no preamble. Provide concise description.\n\nWe need to read the code: It's a function update_total_usage that takes response (optional) and total_usage (OpenAIUsage or AnthropicUsage). It updates total_usage by adding usage from response. Handles OpenAI usage details (completion_tokens, prompt_tokens, total_tokens, and token details). For Anthropic usage, adds input_tokens and output_tokens. Returns updated response (or ChatCompletion?) Actually return type is T_Model | ChatCompletion | None. It returns response after updating its usage attribute to total_usage. If response is None returns None. If usage types not compatible, logs debug and returns response unchanged.\n\nThus summary: function aggregates token usage from a single LLM response into a cumulative usage object, supporting both OpenAI and Anthropic usage structures, updates response's usage field, returns the response (or None). Input: response object possibly containing usage attribute; total_usage cumulative usage object. Output: updated response or None.\n\nLet's craft final answer. Use Chinese with occasional English terms. Ensure start directly with summary content. No \"This code does\". Provide business logic.\n\nLet's produce final answer.assistantfinal\u805a\u5408\u5e76\u7d2f\u8ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8c03\u7528\u7684 token \u4f7f\u7528\u91cf\u3002  \n**\u8f93\u5165**  \n- `response`\uff08\u53ef\u9009\uff09\uff1a\u5b9e\u73b0\u81ea\u5b9a\u4e49 `Response` \u57fa\u7c7b\u7684\u5bf9\u8c61\uff0c\u901a\u5e38\u5305\u542b `usage` \u5c5e\u6027\uff0c\u8bb0\u5f55\u672c\u6b21\u8c03\u7528\u7684 token \u6d88\u8017\u3002  \n- `total_usage`\uff1a\u7d2f\u8ba1\u7684\u4f7f\u7528\u7edf\u8ba1\u5bf9\u8c61\uff0c\u652f\u6301 OpenAI (`openai.types.CompletionUsage`) \u6216 Anthropic (`anthropic.types.Usage`) \u4e24\u79cd\u7ed3\u6784\u3002  \n\n**\u4e1a\u52a1\u903b\u8f91**  \n1. \u82e5 `response` \u4e3a `None`\uff0c\u76f4\u63a5\u8fd4\u56de `None`\u3002  \n2. \u8bfb\u53d6 `response.usage`\uff0c\u5224\u65ad\u5176\u7c7b\u578b\uff1a  \n   - **OpenAI**\uff1a\u5c06\u672c\u6b21 `completion_tokens`\u3001`prompt_tokens`\u3001`total_tokens`", "prompt_id": "28ad819ea97a795ed2ae85e64d974c5c", "created_at": "2026-02-04T20:39:50.762632"}