{"summary": "- This module defines utilities for processing responses from OpenAI's chat completion API, particularly handling JSON schema validation and streaming options.\n- The `handle_fireworks_json` function ensures that the `stream` parameter is set to `false` (unless already provided), and adds a `response_format` field to the JSON JSON.\nWe need to produce a summary in Chinese (or Chinese/English) focusing on business logic, inputs, outputs. Must start directly with the summary content, no preamble. Provide concise description of functionality of the code snippet. The code includes imports, definitions, and a function handle_fireworks_json. So summarize that function: takes response_model (a Pydantic BaseModel subclass) and new_kwargs dict, ensures stream false, adds response_format with json_object and schema derived from model_json_schema, returns tuple of response_model and updated kwargs. Also mention overall module purpose: utilities for processing OpenAI chat responses, handling JSON schema validation, streaming, etc. Provide business logic: preparing request parameters for OpenAI API, ensuring proper format. Input: response_model type, kwargs dict. Output: tuple (type, dict). Provide Chinese. Let's craft.assistantfinal\u8be5\u6a21\u5757\u63d0\u4f9b OpenAI ChatCompletion \u54cd\u5e94\u7684\u9884\u5904\u7406\u5de5\u5177\uff0c\u6838\u5fc3\u4e1a\u52a1\u662f\u6839\u636e Pydantic \u6a21\u578b\u81ea\u52a8\u6784\u9020 API \u8c03\u7528\u53c2\u6570\uff0c\u786e\u4fdd\u8fd4\u56de JSON \u4e25\u683c\u7b26\u5408\u6a21\u578b\u5b9a\u4e49\uff0c\u5e76\u7edf\u4e00\u5904\u7406\u6d41\u5f0f\u8f93\u51fa\u9009\u9879\u3002\n\n**handle_fireworks_json**  \n- **\u8f93\u5165**  \n  1. `response_model: type[T]` \u2013 \u7ee7\u627f\u81ea `pydantic.BaseModel` \u7684\u6a21\u578b\u7c7b\uff0c\u7528\u4e8e\u63cf\u8ff0\u671f\u671b\u7684\u8fd4\u56de\u7ed3\u6784\u3002  \n  2. `new_kwargs: dict[str, Any]` \u2013 \u8c03\u7528 OpenAI \u63a5\u53e3\u65f6\u7684\u5173\u952e\u5b57\u53c2\u6570\u96c6\u5408\u3002  \n- **\u5904\u7406\u903b\u8f91**  \n  1. \u82e5 `new_kwargs` \u4e2d\u672a\u663e\u5f0f\u8bbe\u7f6e `stream`\uff0c\u5219\u5f3a\u5236\u8bbe\u4e3a `False`\uff08\u5173\u95ed\u6d41\u5f0f\u8fd4\u56de\uff09\u3002  \n  2. \u4e3a `new_kwargs` \u6dfb\u52a0 `response_format` \u952e\uff0c\u503c\u4e3a `{\"type\": \"json_object\", \"schema\": response_model.model_json_schema()}`\uff0c\u5373\u4f7f\u7528\u6a21\u578b\u7684 JSON Schema \u7ea6\u675f\u8fd4\u56de\u6570\u636e\u683c\u5f0f\u3002  \n- **\u8f93\u51fa**  \n  - \u8fd4\u56de `(response_model, new_kwargs)`\uff0c\u5176\u4e2d `new_kwargs` \u5df2\u7ecf\u88ab\u8865\u5168\u4e3a\u7b26\u5408 JSON\u2011Schema \u7684\u8bf7\u6c42\u53c2\u6570\uff0c\u53ef\u76f4\u63a5\u4f20\u9012\u7ed9 OpenAI \u7684 chat \u5b8c\u6210\u63a5\u53e3\u3002\n\n\u6574\u4f53\u4e0a\uff0c", "prompt_id": "28ad819ea97a795ed2ae85e64d974c5c", "created_at": "2026-02-04T20:44:14.492354"}