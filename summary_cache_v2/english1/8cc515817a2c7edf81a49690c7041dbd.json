{"summary": "Defines a configurable neural module that uses a ResNet backbone to process video frames (grayscale or RGB) and generate per‑frame visual embeddings for lip‑reading and multimodal speech systems. The module supports various ResNet depths, applies spatial average pooling, optional projection to a target dimension, and can emit tensors in either channels‑first or channels‑last format.", "business_intent": "Enable developers to incorporate high‑quality visual feature extraction into speech‑centric applications such as lip‑reading, audio‑visual speech recognition, and other multimodal AI solutions, reducing the effort required to build and train custom video front‑ends.", "keywords": ["ResNet", "video front‑end", "visual feature extraction", "lip reading", "multimodal speech", "NeuralModule", "PyTorch", "spatial pooling", "dimensionality projection", "channels‑first", "channels‑last"], "summary_hash": "d1c0564e2470", "cached_at": "2026-02-08T10:59:19+00:00"}