{"summary": "Defines an abstract base class for token-level encoder heads in Megatron-based language models, specifying required input and output neural type specifications such as token embeddings, attention masks, and output logits, to serve as a reusable foundation for NLP encoder components.", "business_intent": "Enable modular development of token-wise prediction modules (e.g., language modeling, token classification) within the NeMo Megatron framework, ensuring consistent interfaces and simplifying integration across large language model pipelines.", "keywords": ["Megatron", "token head", "encoder", "NeuralModule", "NeuralType", "NLP", "token-level", "abstract base class", "mask", "logits"], "summary_hash": "885e9bc186d2", "cached_at": "2026-02-08T11:23:25+00:00"}