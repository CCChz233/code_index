{"summary": "Implements a safety checking component for Stable Diffusion outputs, evaluating generated images for inappropriate or unsafe content using a model and returning classification results.", "business_intent": "Provide automated content moderation for AIâ€‘generated images, allowing platforms to filter out NSFW or harmful visuals and ensure compliance with safety policies.", "keywords": ["safety checker", "content moderation", "Stable Diffusion", "image filtering", "NSFW detection", "AI safety", "model inference", "ONNX support", "unsafe content detection"], "summary_hash": "b264b605be9f", "cached_at": "2026-02-09T04:16:32+00:00"}