{"summary": "Encapsulates a pretrained multilingual BART transformer adapted for extractive question answering, handling model setup and inference over input token sequences to generate answer predictions.", "business_intent": "Enable cross-language question answering functionality in applications like chatbots, search engines, and support systems.", "keywords": ["MBart", "multilingual", "question answering", "transformer", "NLP", "model inference", "extractive QA", "pretrained"], "summary_hash": "77f1ab664028", "cached_at": "2026-02-09T11:04:58+00:00"}