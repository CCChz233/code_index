{"summary": "The module defines a dataset class that converts raw question‑answer pairs and associated passages into tokenized inputs suitable for GPT‑style generative question answering models. It manages context encoding, query and answer construction, feature caching, and label masking to support both training and inference workflows.", "business_intent": "Enable efficient preparation and loading of data for training and evaluating generative QA systems based on GPT architectures, reducing preprocessing overhead and ensuring correct input formatting for downstream neural models.", "keywords": ["question answering", "GPT", "dataset", "tokenization", "preprocessing", "caching", "training", "inference", "generative model", "NeMo", "PyTorch"], "summary_hash": "a716470c7b49", "cached_at": "2026-02-08T11:31:49+00:00"}