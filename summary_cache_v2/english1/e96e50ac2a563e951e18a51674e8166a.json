{"summary": "Provides high‑performance implementations of the Recurrent Neural Network Transducer (RNNT) loss for automatic speech recognition, including CPU/GPU accelerated versions via Numba and CUDA, a NumPy reference implementation, and PyTorch‑compatible loss modules with configurable options such as FastEmit, multi‑blank, and gradient clipping.", "business_intent": "Accelerate training and deployment of speech‑recognition models that rely on RNNT loss, offering scalable, GPU‑enabled computation and seamless integration with PyTorch pipelines to reduce development time and improve model accuracy.", "keywords": ["RNNT loss", "automatic speech recognition", "Numba", "CUDA", "GPU acceleration", "CPU", "PyTorch", "FastEmit", "multi-blank", "token-and-duration", "gradient clipping", "autograd"], "summary_hash": "ebe26016afc3", "cached_at": "2026-02-08T12:06:51+00:00"}