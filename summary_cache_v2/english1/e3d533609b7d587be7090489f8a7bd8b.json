{"summary": "Implements a UNet upsampling block that combines residual convolutions, optional upsampling, self‑attention and transformer layers, and SPADE normalization for conditioning on semantic label maps. The block is highly configurable across spatial dimensions, channel sizes, attention heads, cross‑attention context, and precision settings.", "business_intent": "Provides a modular component for generative or segmentation networks that require semantic‑conditioned upsampling, enabling high‑fidelity image synthesis or reconstruction in AI pipelines such as diffusion models or conditional GANs.", "keywords": ["UNet", "upsampling", "residual block", "SPADE", "semantic conditioning", "self‑attention", "transformer", "cross‑attention", "flash attention", "group normalization", "deep learning", "generative model"], "summary_hash": "2d56fb439e55", "cached_at": "2026-02-08T11:32:14+00:00"}