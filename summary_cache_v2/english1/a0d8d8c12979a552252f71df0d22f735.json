{"summary": "Implements a forced‑alignment decoder for recurrent neural network transducer (RNNT) models using a minimal graph topology. It operates as a Viterbi decoder over the RNNT lattice when no predictor window is set, and switches to a uniformly pruned emission‑FSA compilation when a predictor window size is supplied, reducing memory and compute load.", "business_intent": "Provide an efficient, resource‑aware alignment tool for speech‑recognition pipelines that need precise timing information from RNNT models, enabling downstream tasks such as transcript synchronization, model evaluation, and data annotation.", "keywords": ["RNNT", "forced alignment", "Viterbi decoder", "uniform pruning", "emission FSA", "predictor window size", "minimal topology", "speech recognition", "resource optimization"], "summary_hash": "0d6f4d3249d5", "cached_at": "2026-02-08T09:26:29+00:00"}