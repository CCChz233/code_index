{"summary": "Utility module for evaluating confidence estimation in automatic speech recognition models. It extracts token and word level targets with associated confidence scores, applies configurable confidence parameters, and runs comprehensive benchmarking that computes calibration and discrimination metrics (AUC, ROC, PR, ECE, NCE) and saves visualizations such as curves and histograms.", "business_intent": "Provide a standardized way for ASR developers and researchers to assess and improve the reliability and calibration of confidence scores produced by speech recognition models, supporting model selection, debugging, and performance reporting.", "keywords": ["ASR", "confidence estimation", "benchmarking", "calibration", "AUC", "ROC", "PR", "ECE", "NCE", "token confidence", "word confidence", "RNNT", "metrics visualization", "model evaluation"], "summary_hash": "f47b628c2f5f", "cached_at": "2026-02-08T11:12:44+00:00"}