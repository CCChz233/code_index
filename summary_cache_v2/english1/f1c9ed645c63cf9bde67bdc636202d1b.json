{"summary": "A model class that leverages the Longformer‑Encoder‑Decoder architecture to perform sequence‑level classification on long textual inputs, processing the data through the encoder‑decoder stack and outputting class logits.", "business_intent": "Provide a ready‑to‑use solution for classifying lengthy documents or sequences in applications such as sentiment analysis, topic detection, or regulatory compliance, where standard transformers struggle with input length.", "keywords": ["LED", "Longformer", "Encoder‑Decoder", "Sequence Classification", "Transformer", "Long Documents", "NLP", "Text Classification", "Pretrained Model"], "summary_hash": "12d431f19047", "cached_at": "2026-02-09T07:09:04+00:00"}