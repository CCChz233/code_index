{"summary": "Implements a tokenizer that splits text into words and then merges adjacent words that form known multi‑word expressions from a supplied vocabulary, producing single phrase tokens separated by a configurable delimiter.", "business_intent": "Enhance text preprocessing for embedding models by recognizing and preserving multi‑word phrases, improving semantic representation in downstream NLP tasks.", "keywords": ["tokenizer", "phrase detection", "vocabulary", "separator", "NLP", "sentence-transformers", "word tokenization", "multi-word expressions", "text preprocessing"], "summary_hash": "d91f74e5b2a8", "cached_at": "2026-02-08T13:56:58+00:00"}