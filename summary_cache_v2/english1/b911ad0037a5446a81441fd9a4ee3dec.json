{"summary": "The module provides two example training scripts that demonstrate the Model-Agnostic Meta-Learning (MAML) algorithm on the Omniglot few‑shot classification benchmark. One script uses raw PyTorch with Learn2Learn and Cherry‑RL utilities, while the other leverages Lightning Fabric to orchestrate distributed, multi‑GPU execution. Both implementations set up task sampling, inner‑loop adaptation, outer‑loop optimization, and evaluation of rapid adaptation performance.", "business_intent": "Illustrate how to implement and scale meta‑learning (MAML) workflows, offering developers a reference for fast few‑shot model adaptation and a template for deploying distributed training with Lightning Fabric.", "keywords": ["meta-learning", "MAML", "few-shot learning", "PyTorch", "Lightning Fabric", "distributed training", "Omniglot", "task sampling", "inner loop adaptation", "outer loop optimization", "Learn2Learn", "Cherry RL"], "summary_hash": "a28b2de38f86", "cached_at": "2026-02-08T09:12:04+00:00"}