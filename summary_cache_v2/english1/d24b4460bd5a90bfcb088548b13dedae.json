{"summary": "Implements the decoder component of the Deformable DETR architecture, stacking multiple decoder layers that iteratively refine query embeddings through self‑attention and deformable cross‑attention while incorporating positional embeddings, reference points, spatial shapes, and valid ratios, and returning intermediate query states and reference points for each layer.", "business_intent": "Provides a flexible, multi‑scale attention decoder for end‑to‑end object detection systems, enabling integration into vision models that require iterative query refinement across multiple feature levels.", "keywords": ["Deformable DETR", "transformer decoder", "self-attention", "cross-attention", "query embeddings", "reference points", "multi-scale attention", "intermediate outputs", "object detection"], "summary_hash": "4d32ad5ba01f", "cached_at": "2026-02-09T11:10:18+00:00"}