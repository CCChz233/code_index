{"summary": "Implements a decoder layer of the Autoformer architecture, handling self‑attention, cross‑attention and feed‑forward processing for time‑series forecasting.", "business_intent": "Provide the core computational block for an Autoformer model to generate future predictions from past observations, supporting business use cases such as demand planning, financial forecasting, and IoT analytics.", "keywords": ["Autoformer", "decoder layer", "self-attention", "cross-attention", "feed-forward", "time series forecasting", "neural network", "transformer", "sequence modeling"], "summary_hash": "c60b60f7b18d", "cached_at": "2026-02-09T10:34:25+00:00"}