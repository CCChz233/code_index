{"summary": "This module defines a mixin that equips diffusion models with comprehensive utilities for handling PEFT adapters (e.g., LoRA). It enables loading adapter state dictionaries, attaching them to the model, activating/deactivating specific adapters, fusing adapters into the base weights, and querying adapter metadata, while handling version checks and backend selection.", "business_intent": "Facilitate seamless integration and management of parameter‑efficient fine‑tuning adapters within diffusion pipelines, allowing developers to quickly apply, switch, or fuse LoRA/PEFT adapters without manual low‑level handling.", "keywords": ["PEFT", "LoRA", "adapter loading", "parameter-efficient fine-tuning", "diffusion models", "model mixin", "state dict conversion", "adapter activation", "adapter fusion", "torch", "version checking"], "summary_hash": "3c12ccd7896f", "cached_at": "2026-02-09T05:10:59+00:00"}