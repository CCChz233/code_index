{"summary": "A wrapper class that delegates attribute access to an underlying data-parallel model, allowing seamless interaction with a model that runs across multiple devices while preserving its original interface.", "business_intent": "Enable developers to run machine learning models on multiple GPUs without changing code, abstracting parallel execution and simplifying deployment.", "keywords": ["data parallelism", "attribute delegation", "wrapper", "model", "GPU", "parallel computing", "abstraction", "torch"], "summary_hash": "50f38ba2548d", "cached_at": "2026-02-08T08:50:50+00:00"}