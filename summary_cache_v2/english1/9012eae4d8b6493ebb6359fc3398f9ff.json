{"summary": "The script evaluates a trained ASR Transducer model by decoding audio with beam‑search that incorporates an external KenLM n‑gram language model. It automatically detects character or BPE tokenization, runs decoding over configurable beam widths, language model weights and other hyper‑parameters (including MAES settings and HAT internal LM handling), computes error metrics such as WER, and optionally stores the generated hypotheses.", "business_intent": "Provide a tool for measuring and optimizing speech‑recognition accuracy when combining neural transducer models with statistical language models, enabling systematic hyper‑parameter tuning and performance reporting for production or research deployments.", "keywords": ["ASR", "Transducer", "beam search", "n‑gram language model", "KenLM", "evaluation", "WER", "hyperparameter grid search", "BPE", "character encoding", "decoding strategies", "HAT model", "MAES"], "summary_hash": "7c50e4181dfc", "cached_at": "2026-02-08T11:51:34+00:00"}