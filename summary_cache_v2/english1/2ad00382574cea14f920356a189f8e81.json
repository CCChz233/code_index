{"summary": "Provides a bilingual tokenizer for Marian translation models built on separate SentencePiece models for source and target languages, handling tokenization, conversion between tokens and IDs, special token insertion, language code management, normalization, and vocabulary operations.", "business_intent": "Facilitate preprocessing and postprocessing of text for Marian machine translation systems by converting raw sentences into token IDs and reconstructing them, supporting bilingual tokenization and special token handling.", "keywords": ["tokenizer", "sentencepiece", "machine translation", "bilingual", "source language", "target language", "special tokens", "normalization", "vocabulary", "encode", "decode"], "summary_hash": "54167add279e", "cached_at": "2026-02-09T11:28:08+00:00"}