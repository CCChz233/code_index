{"summary": "The module defines utilities for constructing TensorRT‑compatible transformer decoder layers. It provides builders that translate model configuration and weight tensors into a fully assembled decoder layer, handling attention, feed‑forward, and normalization components, and optionally applying linear quantization.", "business_intent": "Facilitate the export of large language model decoder components to TensorRT for high‑performance inference, with support for configurable architecture and optional quantization to reduce runtime latency and memory usage.", "keywords": ["transformer", "decoder layer", "TensorRT", "LLM", "builder pattern", "quantization", "attention", "MLP", "layer normalization", "weight assignment"], "summary_hash": "406593278e81", "cached_at": "2026-02-08T11:39:48+00:00"}