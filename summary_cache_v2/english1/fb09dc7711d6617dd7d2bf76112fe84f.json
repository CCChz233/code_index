{"summary": "A plugin that activates automatic mixed‑precision (AMP) for Fully Sharded Data Parallel (FSDP) training, allowing models to run with reduced‑precision tensors to lower memory consumption and speed up computation.", "business_intent": "Enable developers to easily apply mixed‑precision training to FSDP‑based models for performance gains, while signaling that this approach is now superseded by a newer precision API.", "keywords": ["mixed precision", "automatic mixed precision", "AMP", "FSDP", "fully sharded data parallel", "distributed training", "experimental", "deprecated"], "summary_hash": "bfea2691214e", "cached_at": "2026-02-08T08:14:41+00:00"}