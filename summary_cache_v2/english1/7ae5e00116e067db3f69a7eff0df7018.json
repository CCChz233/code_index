{"summary": "Implements the CodeBLEU evaluation metric, combining BLEU n‑gram scoring, weighted n‑gram matching, syntactic similarity via abstract syntax trees, and data‑flow similarity to assess generated source code against references.", "business_intent": "Provide a robust, multi‑faceted metric for evaluating code generation models, capturing lexical, syntactic, and semantic fidelity of generated programs across multiple programming languages.", "keywords": ["CodeBLEU", "code evaluation", "BLEU scoring", "syntactic similarity", "data flow analysis", "AST parsing", "weighted n‑gram", "programming language assessment", "machine learning evaluation"], "summary_hash": "14270df91671", "cached_at": "2026-02-08T12:46:01+00:00"}