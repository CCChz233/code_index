{"summary": "Provides a pretrained ESM transformer model configured for masked language modeling, handling input encoding, forward passes, and output of token predictions for protein sequences.", "business_intent": "Facilitate protein sequence analysis and variant effect prediction by offering masked language modeling capabilities using a state‑of‑the‑art pretrained model.", "keywords": ["ESM", "masked language modeling", "protein sequences", "transformer", "pretrained model", "inference", "token prediction"], "summary_hash": "c11684f54e5f", "cached_at": "2026-02-09T07:02:32+00:00"}