{"summary": "The module defines wrappers that extend pretrained causal and seq2seq language models with an additional neural value head, enabling simultaneous text generation and token‑level value estimation for reinforcement‑learning based workflows.", "business_intent": "To simplify the integration of value estimation into language model pipelines, supporting reinforcement learning, RLHF, and other reward‑driven text generation scenarios.", "keywords": ["value head", "language model", "causal LM", "seq2seq", "reinforcement learning", "RLHF", "token scoring", "generation", "wrapper", "pretrained model", "PyTorch", "transformers"], "summary_hash": "25eb58431bef", "cached_at": "2026-02-09T06:00:56+00:00"}