{"summary": "A dataset wrapper that prepares a list of user queries for joint intent detection and slot filling inference with a pretrained language model. It tokenizes each query, truncates to a configurable maximum length, adds special tokens, creates attention masks, and pads slot label sequences with a neutral label, exposing standard indexing and length interfaces for batch processing.", "business_intent": "Facilitates scalable, real-time natural language understanding in conversational applications by providing ready-to-use inputs for intent and slot classification models during inference.", "keywords": ["intent detection", "slot filling", "inference dataset", "tokenization", "pretrained model", "NLU", "conversational AI", "batch processing", "sequence padding"], "summary_hash": "20b5d0850207", "cached_at": "2026-02-08T09:59:36+00:00"}