{"summary": "Defines TVM compute expressions and scheduling strategies for Sampled Dense‑Dense Matrix Multiplication (SDDMM) kernels, including helper utilities for edge handling and GPU tree‑reduction.", "business_intent": "Enable high‑performance, hardware‑accelerated SDDMM operations used in graph neural network and sparse linear algebra workloads.", "keywords": ["SDDMM", "TVM", "compute", "schedule", "GPU", "kernel", "sparse matrix", "dense matrix", "graph neural network", "optimization"], "summary_hash": "2e0909c2ef3a", "cached_at": "2026-02-08T23:57:55+00:00"}