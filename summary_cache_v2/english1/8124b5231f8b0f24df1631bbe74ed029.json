{"summary": "Implements a configurable 2‑D downsampling block for Flax models, converting input feature maps to a lower spatial resolution while adjusting channel dimensions. It supports multiple attention‑style layers, optional dropout for regularization, and can prepend a downsampling operation before producing the final output, all with a specified data type.", "business_intent": "Provides a reusable component for constructing hierarchical neural architectures such as encoders or UNet backbones, enabling efficient spatial reduction and feature enrichment in JAX‑based deep learning pipelines.", "keywords": ["Flax", "downsampling", "2D block", "neural network", "attention layers", "dropout", "feature map reduction", "hierarchical encoder", "JAX", "dtype"], "summary_hash": "f37bacb2ad24", "cached_at": "2026-02-09T04:31:26+00:00"}