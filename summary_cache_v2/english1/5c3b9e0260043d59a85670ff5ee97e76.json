{"summary": "A reference script that fine‑tunes a Hugging Face sequence‑classification model using Accelerate, automatically finding the largest batch size that fits GPU memory and providing data loading, tokenization, training and evaluation utilities.", "business_intent": "Help developers efficiently utilize GPU resources and avoid out‑of‑memory errors when training transformer models, enabling scalable and reproducible fine‑tuning pipelines.", "keywords": ["accelerate", "GPU memory management", "batch size optimization", "transformer", "sequence classification", "data loading", "tokenization", "training loop", "evaluation", "huggingface", "pytorch"], "summary_hash": "404a24d9abbd", "cached_at": "2026-02-09T02:17:04+00:00"}