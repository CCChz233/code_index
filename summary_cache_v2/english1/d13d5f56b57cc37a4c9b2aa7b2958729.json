{"summary": "A neural network module that expands an input hidden vector to a larger intermediate dimension, applies a non‑linear activation, and projects the result back to the original size, serving as a feed‑forward block.", "business_intent": "Supply a reusable, high‑capacity feed‑forward component for transformer‑style models to improve representation power while keeping computational cost manageable.", "keywords": ["MLP", "feed‑forward network", "hidden dimension expansion", "projection", "nonlinear activation", "SwiGLU", "deep learning", "transformer"], "summary_hash": "67dd55821ac8", "cached_at": "2026-02-09T04:19:53+00:00"}