{"summary": "The module provides asynchronous utilities for calling OpenAI language models with built-in Agenta observability. It includes a basic async helper, a nested async workflow that manages request lifecycle with tracing, and a dictionaryâ€‘driven async interface that leverages litellm to generate GPT responses while automatically collecting metrics and traces.", "business_intent": "Show developers how to integrate LLM calls into an async Python application while capturing observability data (traces, metrics) for monitoring, debugging, and performance analysis.", "keywords": ["asynchronous", "OpenAI", "LLM", "Agenta", "observability", "tracing", "metrics", "litellm", "GPT", "workflow", "wrapper", "dictionary"], "summary_hash": "2e57d9d88a5c", "cached_at": "2026-02-08T05:31:19+00:00"}