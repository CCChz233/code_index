{"summary": "Encapsulates a neural network model that stores pre‑computed total parameter sizes in megabytes for both half‑precision (FP16) and single‑precision (FP32) formats, and provides a simple forward helper.", "business_intent": "Enable rapid estimation of a model's memory requirements for different precision settings to aid deployment planning and hardware selection.", "keywords": ["model", "parameter size", "FP16", "FP32", "memory footprint", "precomputed", "inference", "deployment", "resource estimation"], "summary_hash": "a8e5bb1311ca", "cached_at": "2026-02-08T07:53:19+00:00"}