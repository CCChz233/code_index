{"summary": "Defines a compressed sparse matrix/tensor abstraction that offers arithmetic, logical, and linear‑algebra operations, along with utilities for device placement, dtype management, shape inspection, and conversion between sparse and dense formats, supporting efficient sparse attention computations.", "business_intent": "Enable high‑performance transformer models by using sparse representations to lower memory usage and computational cost of attention layers.", "keywords": ["sparse matrix", "compressed sparse row", "CSR", "COO", "attention", "transformer", "xformers", "torch", "GPU acceleration", "linear algebra", "device placement", "dtype handling", "dense to sparse conversion"], "summary_hash": "0b7021aac450", "cached_at": "2026-02-08T23:31:35+00:00"}