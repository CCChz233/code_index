{"summary": "Implements a vector‑quantized autoencoder that encodes inputs into discrete latent representations, optionally using exponential‑moving‑average updates, and decodes them back to the original domain. Provides training, validation, optimizer configuration, checkpoint loading, and utilities for logging and visualizing reconstructed images.", "business_intent": "Enable efficient image compression and representation learning for applications such as generative modeling, storage reduction, or downstream vision tasks.", "keywords": ["vector quantization", "autoencoder", "latent codes", "image reconstruction", "EMA", "training loop", "validation", "optimizer configuration", "checkpoint loading", "image logging", "PyTorch Lightning"], "summary_hash": "62477f122c96", "cached_at": "2026-02-08T09:09:10+00:00"}