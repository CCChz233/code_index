{"summary": "A configuration container for the text encoder of a BridgeTower multimodal model, encapsulating all transformer hyperparameters such as vocabulary size, hidden dimensions, layer counts, attention heads, activation, dropout rates, positional embedding settings, and decoder/cache flags. It inherits from the generic pretrained model config to enable seamless loading of pretrained weights and consistent model initialization.", "business_intent": "Provide a ready‑to‑use, RoBERTa‑based default configuration that lets developers instantiate or fine‑tune the text component of BridgeTower models without manually specifying each hyperparameter, ensuring compatibility with existing BridgeTower checkpoints.", "keywords": ["BridgeTower", "text configuration", "transformer hyperparameters", "vocab size", "hidden layers", "attention heads", "dropout", "position embeddings", "decoder flag", "pretrained config", "RoBERTa"], "summary_hash": "d8b3a9740367", "cached_at": "2026-02-09T08:52:05+00:00"}