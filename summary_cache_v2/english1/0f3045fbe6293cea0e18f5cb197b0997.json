{"summary": "This module defines a data model that encapsulates the configuration and current state of a rate limit applied to language model executions, and provides methods to serialize the rate‑limit information into dictionary or JSON formats for transport or persistence.", "business_intent": "Support the Agenta client in tracking, enforcing, and communicating usage quotas for LLM runs, helping downstream services respect rate‑limit policies and avoid over‑consumption of model resources.", "keywords": ["rate limit", "LLM", "language model", "configuration", "state", "serialization", "JSON", "dictionary", "backend", "client", "usage quota"], "summary_hash": "0696df9864e5", "cached_at": "2026-02-08T05:21:04+00:00"}