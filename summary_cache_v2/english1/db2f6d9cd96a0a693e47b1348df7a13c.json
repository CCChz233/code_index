{"summary": "Implements a diffusion pipeline for image-to-image generation using the Stable UnCLIP model, combining VAE decoding, UNet conditioning, CLIP text and vision encoders, and supporting LoRA and textual inversion extensions.", "business_intent": "Provide developers with a ready-to-use pipeline to create new images guided by an input image and optional text prompts, leveraging the Stable UnCLIP architecture within the Diffusers ecosystem.", "keywords": ["Stable UnCLIP", "image-to-image", "diffusion pipeline", "VAE", "UNet", "CLIP", "LoRA", "textual inversion", "scheduler", "torch", "transformers"], "summary_hash": "513a0f7a5221", "cached_at": "2026-02-09T05:25:16+00:00"}