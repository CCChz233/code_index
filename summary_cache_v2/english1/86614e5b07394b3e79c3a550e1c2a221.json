{"summary": "Implements a metric that quantifies how vulnerable a language model's answers are to variations in the input. It decomposes each response into individual statements, evaluates each for consistency and faithfulness using NLI-based prompts, and aggregates the results to produce an overall robustness score.", "business_intent": "Enable product teams to assess and improve the reliability of AI-powered conversational or QA systems by detecting sensitivity to noisy or altered user inputs, thereby ensuring consistent and trustworthy outputs.", "keywords": ["noise sensitivity", "robustness", "LLM evaluation", "statement-level analysis", "faithfulness", "consistency", "reproducibility", "metric", "ragas", "NLI", "prompt engineering"], "summary_hash": "42a1a0a70d05", "cached_at": "2026-02-08T22:50:38+00:00"}