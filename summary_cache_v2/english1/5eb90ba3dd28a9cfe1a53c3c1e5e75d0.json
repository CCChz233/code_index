{"summary": "Implements a batch semi‑hard triplet loss for training SentenceTransformer models, selecting semi‑hard negative examples within each batch to compute the triplet loss.", "business_intent": "Provide a metric‑learning loss that encourages similar sentences to have close embeddings while pushing dissimilar sentences apart, improving the quality of sentence embeddings for similarity and retrieval tasks.", "keywords": ["triplet loss", "semi-hard", "batch", "sentence embeddings", "metric learning", "PyTorch", "loss function", "SentenceTransformer", "training objective"], "summary_hash": "76ed59f08086", "cached_at": "2026-02-08T13:53:00+00:00"}