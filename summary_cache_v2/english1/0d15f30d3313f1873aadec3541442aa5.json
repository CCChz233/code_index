{"summary": "Provides an iterator that streams text files and yields token sequences of a fixed length, managing a configurable buffer of sequences, handling on‑the‑fly tokenization or pre‑tokenized inputs, optionally looping indefinitely, and allowing optional shuffling of the data.", "business_intent": "Enables efficient feeding of language‑model training pipelines with uniformly sized token batches from large text corpora while minimizing memory usage and supporting continuous or epoch‑based data streams.", "keywords": ["tokenization", "fixed-length sequences", "streaming dataset", "infinite iterator", "buffer management", "shuffle", "language model training", "text preprocessing"], "summary_hash": "672e49dc6e4a", "cached_at": "2026-02-09T06:11:30+00:00"}