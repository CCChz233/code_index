{"summary": "A TensorFlow data structure that encapsulates the outputs of a transformer model, including the final hidden representations and optional intermediate hidden states, self‑attention maps, and decoder cross‑attention maps.", "business_intent": "Enable downstream applications to easily access and manipulate transformer outputs for tasks such as feature extraction, model inspection, and integration into larger TensorFlow workflows.", "keywords": ["transformer", "TensorFlow", "model output", "hidden states", "attention weights", "cross‑attention", "decoder", "sequence representation"], "summary_hash": "74ca66126bcf", "cached_at": "2026-02-09T06:30:45+00:00"}