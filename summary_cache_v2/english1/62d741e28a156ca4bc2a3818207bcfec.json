{"summary": "Provides a collection of inference pipelines that orchestrate the Flux diffusion model for text‑to‑image generation and its extensions (ControlNet conditioning, image‑to‑image editing, and inpainting). Each pipeline handles tokenization, embedding, latent preparation, conditional transformer denoising with a scheduler, and VAE decoding, while exposing advanced options such as guidance scaling, LoRA/PEFT weights, VAE slicing/tiling, and interruption handling.", "business_intent": "Enable developers and enterprises to generate, edit, and customize high‑quality images from textual descriptions using the latest diffusion technology, supporting flexible workflows like guided generation, control‑net conditioning, image transformation, and masked inpainting for creative, marketing, or product‑design applications.", "keywords": ["Flux", "diffusion", "text-to-image", "ControlNet", "inpainting", "image-to-image", "VAE", "scheduler", "CLIP", "T5", "LoRA", "guidance scaling", "latent manipulation"], "summary_hash": "3560b4f4223b", "cached_at": "2026-02-09T05:40:58+00:00"}