{"summary": "We need to produce JSON with keys: summary, business_intent, keywords (list). Must not list method names verbatim. Focus on class responsibility and state/behavior. Provide English description.\n\nClass LaborSampler: builds computational dependency of node representations via labor sampling for multilayer GNN. It samples a fixed number of neighbors per edge type per layer, using uniform or importance sampling, with options for edge direction, probability weighting, layer dependency, prefetching features/labels, output device. Used for node classification, edge classification, link prediction. Provides random variates per vertex, can share across layers.\n\nSo summary: a sampler that constructs mini-batch subgraphs (MFGs) for GNN training by sampling neighbors per edge type according to fanout, supporting uniform, probability-based, importance sampling, layer dependency, prefetching, device placement.\n\nBusiness intent: enable efficient, scalable training of GNNs on large (heterogeneous) graphs by reducing neighborhood explosion, providing flexible sampling strategies and data prefetching.\n\nKeywords: neighbor sampling, GNN, multilayer, importance sampling, heterogeneous graph, mini-batch, MFG, data loader, edge direction, prefetch, fanout.\n\nMake sure not to list method names. Provide JSON.\n\nLet's craft.\n\nNeed to output only JSON object, no markdown.\n\nLet's produce:\n\n{\n  \"summary\": \"...\",\n  \"business_intent\": \"...\",\n  \"keywords\": [...]\n}\n\nMake sure to escape quotes properly.\n\nLet's write.\n\nSummary: \"LaborSampler constructs layer‑wise mini‑batches for graph neural networks by sampling a configurable number of inbound or outbound neighbors per edge type, optionally using probability‑weighted or importance sampling, and can share random variates across layers. It also supports prefetching node and edge features and placing the sampled subgraphs on a chosen device.\"\n\nBusiness intent: \"Provide a scalable, flexible neighbor‑sampling mechanism that mitigates the neighborhood explosion problem in GNN training, enabling efficient minibatch learning on large homogeneous or heterogeneous graphs for tasks such as node classification, edge classification, and link prediction.\"\n\nKeywords list: [\"neighbor sampling\",\"graph neural network\",\"mini‑batch\",\"heterogeneous graph\",\"importance sampling\",\"probability weighting\",\"layer dependency\",\"feature prefetch\",\"device placement\",\"fanout control\"].\n\nReturn JSON.\n\nLet's ensure proper JSON formatting: double quotes, no trailing commas.\n\nOutput:\n\n{\n  \"summary\": \"...\",\n  \"business_intent\": \"...\",\n  \"keywords\": [...]\n}\n\nLet's craft final answer.\n{\n  \"summary\": \"", "business_intent": "We need to produce JSON with keys: summary, business_intent, keywords (list). Must not list method names verbatim. Focus on class responsibility and state/behavior. Provide English description.\n\nClass LaborSampler: builds computational dependency of node representations via labor sampling for multilayer GNN. It samples a fixed number of neighbors per edge type per layer, using uniform or importance sampling, with options for edge direction, probability weighting, layer dependency, prefetching features/labels, output device. Used for node classification, edge classification, link prediction. Provides random variates per vertex, can share across layers.\n\nSo summary: a sampler that constructs mini-batch subgraphs (MFGs) for GNN training by sampling neighbors per edge type according to fanout, supporting uniform, probability-based, importance sampling, layer dependency, prefetching, device placement.\n\nBusiness intent: enable efficient, scalable training of GNNs on large (heterogeneous) graphs by reducing neighborhood explosion, providing flexible sampling strategies and data prefetching.\n\nKeywords: neighbor sampling, GNN, multilayer, importance sampling, heterogeneous graph, mini-batch, MFG, data loader, edge direction, prefetch, fanout.\n\nMake sure not to list method names. Provide JSON.\n\nLet's craft.\n\nNeed to output only JSON object, no markdown.\n\nLet's produce:\n\n{\n  \"summary\": \"...\",\n  \"business_intent\": \"...\",\n  \"keywords\": [...]\n}\n\nMake sure to escape quotes properly.\n\nLet's write.\n\nSummary: \"LaborSampler constructs layer‑wise mini‑batches for graph neural networks by sampling a configurable number of inbound or outbound neighbors per edge type, optionally using probability‑weighted or importance sampling, and can share random variates across layers. It also supports prefetching node and edge features and placing the sampled subgraphs on a chosen device.\"\n\nBusiness intent: \"Provide a scalable, flexible neighbor‑sampling mechanism that mitigates the neighborhood explosion problem in GNN training, enabling efficient minibatch learning on large homogeneous or heterogeneous graphs for tasks such as node classification, edge classification, and link prediction.\"\n\nKeywords list: [\"neighbor sampling\",\"graph neural network\",\"mini‑batch\",\"heterogeneous graph\",\"importance sampling\",\"probability weighting\",\"layer dependency\",\"feature prefetch\",\"device placement\",\"fanout control\"].\n\nReturn JSON.\n\nLet's ensure proper JSON formatting: double quotes, no trailing commas.\n\nOutput:\n\n{\n  \"summary\": \"...\",\n  \"business_intent\": \"...\",\n  \"keywords\": [...]\n}\n\nLet's craft final answer.\n{\n  \"summary\": \"", "keywords": [], "summary_hash": "ce97fb6df7b9", "cached_at": "2026-02-08T23:37:09+00:00"}