{"summary": "A structured container that encapsulates the outputs of a causal (autoregressive) language model, including optional loss, token prediction scores, cached attention key/value tensors for fast sequential decoding, and optionally the hidden states and attention weights of each layer.", "business_intent": "Facilitate downstream processing of language model results such as text generation, loss monitoring, and model introspection while supporting efficient cached decoding for productionâ€‘grade inference.", "keywords": ["loss", "logits", "past_key_values", "hidden_states", "attentions", "causal language model", "autoregressive", "output container", "caching", "generation"], "summary_hash": "7db794759d1b", "cached_at": "2026-02-09T06:28:51+00:00"}