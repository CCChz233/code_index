{"summary": "Provides a thin integration layer that adapts llama-index embedding models for use within the Ragas ecosystem, exposing both synchronous and asynchronous methods to generate vector representations for single queries and batches of documents.", "business_intent": "Facilitates seamless incorporation of external embedding services into Ragas pipelines, enabling downstream tasks such as semantic search, similarity scoring, and context retrieval without modifying the original llama-index models.", "keywords": ["embeddings", "wrapper", "llama-index", "asynchronous", "synchronous", "query vectorization", "document vectorization", "Ragas integration", "semantic similarity", "vector representation"], "summary_hash": "7258592b81a2", "cached_at": "2026-02-08T22:43:33+00:00"}