{"summary": "Encapsulates a neural network model prepared for Fully Sharded Data Parallel version 2 (FSDP2) training, offering utilities to set up and adjust the model for distributed execution.", "business_intent": "Facilitate scalable, memoryâ€‘efficient training of large deep learning models across multiple GPUs or nodes by applying FSDP2 sharding and related configuration.", "keywords": ["FSDP2", "distributed training", "model sharding", "memory optimization", "PyTorch", "configuration helper"], "summary_hash": "cb4041358a60", "cached_at": "2026-02-08T07:49:50+00:00"}