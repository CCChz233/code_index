{"summary": "Provides a PyTorch-compatible dataset that prepares utterances for a pretrained BERT model to jointly predict user intent and slot labels, handling token conversion, position mapping, and sequence padding.", "business_intent": "Supports development of intent-aware dialogue systems by supplying ready-to-train data for joint intent detection and slot extraction.", "keywords": ["BERT", "intent classification", "slot filling", "joint modeling", "dataset", "preprocessing", "tokenization", "padding", "truncation", "conversational AI"], "summary_hash": "e18b93f73829", "cached_at": "2026-02-08T10:05:05+00:00"}