{"summary": "Provides a proxy integration that connects LiteLLM's request flow to Azure's Content Safety service, preparing requests, applying configurable thresholds, processing responses, handling errors, and supporting asynchronous lifecycle hooks for content moderation.", "business_intent": "To enforce content safety and compliance for AI-generated outputs by leveraging Azure's moderation capabilities within the LiteLLM platform.", "keywords": ["azure", "content safety", "moderation", "proxy integration", "hooks", "asynchronous", "thresholds", "caching", "error handling", "litellm"], "summary_hash": "bf776d0fd045", "cached_at": "2026-02-08T07:51:07+00:00"}