{"summary": "Implements a neural network layer that computes attention restricted to a local neighborhood, providing a forward pass and the ability to prune attention heads for efficiency.", "business_intent": "Provide models with a lightweight, locally focused attention mechanism that can be trimmed by removing unnecessary heads, reducing computation and memory usage.", "keywords": ["attention", "neighborhood", "neural network", "module", "pruning", "heads", "forward pass", "transformer", "local context", "efficiency"], "summary_hash": "29650bbdb7c6", "cached_at": "2026-02-09T11:11:16+00:00"}