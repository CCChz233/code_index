{"summary": "Base class representing an attention mask used in splash attention mechanisms, providing common functionality such as logical combination, boolean evaluation, element access, and shape information.", "business_intent": "Facilitate the creation and manipulation of attention masks in deep learning models, allowing developers to compose complex mask patterns efficiently for neural network attention computations.", "keywords": ["attention", "mask", "splash", "logical operators", "boolean", "indexing", "shape", "deep learning", "neural network"], "summary_hash": "b6977e48c8ff", "cached_at": "2026-02-09T11:48:54+00:00"}