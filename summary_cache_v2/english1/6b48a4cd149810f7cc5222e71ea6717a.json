{"summary": "A neural network module that implements a transformer-based processing block for textual inputs, encapsulating self‑attention and feed‑forward sub‑layers to generate contextualized text embeddings within the OneFormer framework.", "business_intent": "Enable reusable, high‑performance text feature extraction for multimodal vision‑language models such as OneFormer, supporting downstream tasks like segmentation, classification, or captioning.", "keywords": ["transformer", "text encoder", "self-attention", "feed-forward network", "OneFormer", "multimodal", "neural network layer", "contextual embeddings"], "summary_hash": "a5866db72232", "cached_at": "2026-02-09T09:56:26+00:00"}