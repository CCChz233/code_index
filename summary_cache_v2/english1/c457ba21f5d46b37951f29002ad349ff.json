{"summary": "Encapsulates a BERT-based encoder that converts input token sequences into contextualized vector embeddings.", "business_intent": "Provide a reusable component for generating text representations to support downstream NLP tasks such as classification, similarity matching, or feature extraction.", "keywords": ["BERT", "encoder", "transformer", "text embeddings", "forward pass", "NLP"], "summary_hash": "fd2486cf74a5", "cached_at": "2026-02-09T11:08:34+00:00"}