{"summary": "Provides a high‑level interface for interacting with Vertex AI and Google AI Studio context‑caching APIs, encapsulating authentication, request URL construction, and cache lifecycle actions such as verification, creation, and retrieval, with support for both synchronous and asynchronous calls.", "business_intent": "Enable applications to efficiently reuse previously generated LLM context by managing Vertex AI cache resources, thereby reducing token consumption, latency, and cost for downstream language model requests.", "keywords": ["Vertex AI", "Google AI Studio", "context caching", "authentication", "endpoint management", "cache verification", "cache creation", "cache retrieval", "synchronous", "asynchronous", "HTTP handling", "LiteLLM"], "summary_hash": "cc4e6e2654d1", "cached_at": "2026-02-08T07:58:03+00:00"}