{"summary": "TensorFlow layer that applies a layer‑normalization step to RoBERTa hidden states and then pools them to produce a fixed‑size representation, typically the [CLS] token embedding.", "business_intent": "Enable downstream NLP tasks such as classification, retrieval, or similarity scoring by providing a ready‑to‑use sentence embedding extractor for RoBERTa models.", "keywords": ["TensorFlow", "RoBERTa", "pooling", "layer normalization", "sentence embedding", "NLP", "transformer", "pre‑layer norm"], "summary_hash": "a2032d28218e", "cached_at": "2026-02-09T09:08:52+00:00"}