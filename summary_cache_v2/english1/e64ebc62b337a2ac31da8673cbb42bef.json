{"summary": "An example script that sets up and runs self‑alignment pretraining for an Entity Linking model using NVIDIA NeMo. It loads a configuration via Hydra, initializes the model and PyTorch Lightning trainer, manages experiment logging, and starts training.", "business_intent": "Showcase how to pretrain an entity linking model with self‑alignment, enabling developers and researchers to replicate the workflow and adapt it for their own NLP projects.", "keywords": ["entity linking", "self-alignment", "pretraining", "NeMo", "Hydra", "PyTorch Lightning", "experiment management"], "summary_hash": "3ef1225e288f", "cached_at": "2026-02-08T10:42:41+00:00"}