{"summary": "Provides a scheduler-like interface that proxies the learning‑rate values from an Adafactor optimizer, returning the preset initial learning rate at the start of training and the optimizer’s current learning rate thereafter.", "business_intent": "Allows training pipelines that expect a separate learning‑rate scheduler (e.g., for logging or monitoring) to work seamlessly with Adafactor, which manages its own schedule internally.", "keywords": ["Adafactor", "learning rate proxy", "scheduler compatibility", "training loop integration", "optimizer monitoring", "learning rate retrieval"], "summary_hash": "940726f19951", "cached_at": "2026-02-09T06:27:10+00:00"}