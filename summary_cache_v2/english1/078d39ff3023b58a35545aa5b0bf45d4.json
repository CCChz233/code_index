{"summary": "A stopping criterion that halts text generation once the total number of tokens (including the initial prompt for decoderâ€‘only models) exceeds a predefined maximum length, optionally respecting the model's positional embedding limit.", "business_intent": "Enforce length limits on generated sequences to avoid exceeding model capacity, control resource usage, and ensure outputs stay within desired size constraints.", "keywords": ["max length", "token limit", "stopping criterion", "generation control", "position embeddings", "decoder-only", "transformer", "output truncation"], "summary_hash": "0c5872dc0531", "cached_at": "2026-02-09T07:56:47+00:00"}