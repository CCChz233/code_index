{"summary": "The module offers command‑line tools to train a multitask encoder‑decoder speech‑to‑text model (ASR and speech translation) with configurable data, batching, distributed execution, and experiment logging, and to run inference on long audio by chunking it, processing each segment with the trained model, and recombining the results.", "business_intent": "Enable developers and researchers to quickly set up, train, and evaluate multitask speech recognition/translation models using NVIDIA NeMo, accelerating product development and experimentation in speech AI applications.", "keywords": ["speech recognition", "speech translation", "multitask", "encoder-decoder", "NVIDIA NeMo", "training", "inference", "audio chunking", "command line", "distributed training", "experiment logging"], "summary_hash": "3f3b713d5676", "cached_at": "2026-02-08T11:57:33+00:00"}