{"summary": "Provides a PyTorch module that converts token‑level embeddings into a fixed‑size sentence embedding by applying configurable pooling operations (CLS token, mean, max, weighted mean) while respecting attention masks and optional normalization.", "business_intent": "Supply a reusable pooling layer for generating sentence representations from transformer outputs, supporting downstream NLP tasks like semantic search, similarity scoring, and classification.", "keywords": ["pooling", "sentence embedding", "transformer", "mean pooling", "max pooling", "CLS token", "weighted mean", "attention mask", "normalization", "PyTorch", "neural network"], "summary_hash": "e9f38c70b16d", "cached_at": "2026-02-08T13:54:46+00:00"}