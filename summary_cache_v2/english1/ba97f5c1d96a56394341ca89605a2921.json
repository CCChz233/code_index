{"summary": "A lightweight example model that configures a Zero Redundancy Optimizer for distributed training, providing a simple reference implementation.", "business_intent": "Showcase the integration of ZeRO optimizer to reduce memory overhead and enable efficient multiâ€‘GPU training in a minimal model.", "keywords": ["Zero Redundancy Optimizer", "distributed training", "memory efficiency", "PyTorch Lightning", "example model", "optimizer configuration"], "summary_hash": "4e781a3a05a7", "cached_at": "2026-02-08T07:51:14+00:00"}