{"summary": "Implements utilities for building Azure OpenAI Realtime endpoint URLs and managing asynchronous websocket connections to the OpenAI service, enabling real‑time streaming of chat completions through the LiteLLM proxy.", "business_intent": "To integrate Azure OpenAI's Realtime API into LiteLLM, providing developers with low‑latency, streaming chat capabilities via websocket communication.", "keywords": ["Azure OpenAI", "Realtime API", "websocket", "asynchronous communication", "streaming chat completions", "LiteLLM proxy", "endpoint URL construction"], "summary_hash": "283eafdb4853", "cached_at": "2026-02-08T08:09:38+00:00"}