{"summary": "A utility that converts raw text into a sequence of basic tokens by normalizing case, optionally removing accents, splitting on punctuation, handling Chinese characters, and preserving specified tokens unchanged.", "business_intent": "Prepare and normalize textual input for natural language processing pipelines, ensuring consistent token boundaries and character handling before further tokenization or model ingestion.", "keywords": ["tokenization", "text normalization", "punctuation splitting", "lowercasing", "accent stripping", "Chinese character handling", "preserve tokens", "NLP preprocessing"], "summary_hash": "7e11efc30d95", "cached_at": "2026-02-09T12:05:54+00:00"}