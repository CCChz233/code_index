{"summary": "A utility module that wraps PyTorch's multiprocessing primitives to launch functions in separate processes, share DGL tensors via shared memory, and manage result queues with proper error propagation.", "business_intent": "Enable scalable and efficient parallel execution of graph neural network workloads in DGL by leveraging PyTorch's multiprocessing infrastructure.", "keywords": ["multiprocessing", "PyTorch", "shared memory", "tensor sharing", "process management", "result queue", "error handling", "DGL", "parallel execution", "inter-process communication"], "summary_hash": "b8e222ecccbd", "cached_at": "2026-02-09T00:58:56+00:00"}