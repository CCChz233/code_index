{"summary": "Implements a 2‑dimensional multi‑head attention component that computes the attention scores, applies softmax, and returns only the resulting probability matrix, omitting the subsequent value multiplication.", "business_intent": "Provides raw attention distributions for model interpretability, debugging, or as input to other processing stages in transformer‑based vision systems such as DETR.", "keywords": ["attention", "softmax", "multi-head", "transformer", "DETR", "attention map", "visualization", "interpretability"], "summary_hash": "3e23d4b44573", "cached_at": "2026-02-09T09:23:08+00:00"}