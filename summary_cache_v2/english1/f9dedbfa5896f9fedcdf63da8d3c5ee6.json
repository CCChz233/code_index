{"summary": "A recurrent graph neural network cell that extends the traditional GRU by substituting its linear transformations with a customizable messageâ€‘passing network, processing node features and previous hidden states to produce an updated hidden representation for each node.", "business_intent": "Enable developers to build temporal graph models that capture both structural relationships and sequential dynamics, supporting use cases such as traffic flow prediction, social interaction evolution, and molecular simulation.", "keywords": ["graph neural network", "GRU", "recurrent cell", "message passing", "temporal graph", "torch", "modular architecture", "hidden state update", "graph dynamics"], "summary_hash": "e40e61ea7201", "cached_at": "2026-02-08T23:15:32+00:00"}