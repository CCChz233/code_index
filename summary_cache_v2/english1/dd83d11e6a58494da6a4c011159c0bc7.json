{"summary": "Implements a dynamic rate‑limiting system for the Litellm proxy. It tracks the number of active projects using each model via a dual‑layer cache, evaluates available usage before a request, and updates counters after the request completes, providing asynchronous pre‑ and post‑call hooks to enforce limits.", "business_intent": "Protects backend resources and ensures fair, controlled access to AI models by automatically throttling requests based on real‑time usage per project and model, preventing overload and abuse of the proxy service.", "keywords": ["dynamic rate limiting", "dual cache", "usage tracking", "proxy", "asynchronous hooks", "model quota", "project limits", "Litellm", "resource protection", "throttling"], "summary_hash": "aea241f2992a", "cached_at": "2026-02-08T07:50:59+00:00"}