{"summary": "Implements a dataset that streams data directly from storage to GPU memory using DMA (GPU Direct Storage), bypassing the CPU and eliminating intermediate buffers. It builds on a persistent dataset and adds cache handling for metadata, enabling fast, low‑latency access to large image‑label collections.", "business_intent": "Speed up training and inference for data‑intensive deep‑learning workloads (e.g., medical imaging) by reducing I/O latency and CPU/GPU overhead, thereby increasing throughput and resource efficiency.", "keywords": ["GPU Direct Storage", "DMA", "PersistentDataset", "high-performance I/O", "low latency", "GPU memory", "data loading", "medical imaging", "deep learning", "MONAI"], "summary_hash": "3eff3cdad07e", "cached_at": "2026-02-08T13:10:59+00:00"}