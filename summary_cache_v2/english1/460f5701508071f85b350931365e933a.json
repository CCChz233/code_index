{"summary": "Provides classes to encapsulate and construct BERT-compatible examples from text‑normalization editing tasks, handling word‑piece tokenization, tag generation, and uniform sequence padding for training or inference.", "business_intent": "Support the creation of input data for BERT models that perform text normalization as a tagging problem, streamlining the data pipeline within the NeMo NLP framework.", "keywords": ["BERT", "text normalization", "tagging", "tokenization", "padding", "editing task", "NLP", "NeMo", "dataset preparation", "token-level labels"], "summary_hash": "97cfcdbc8d09", "cached_at": "2026-02-08T11:28:56+00:00"}