{"summary": "Defines a metric class that calculates perplexity for language modeling outputs, processing model logits to compute token-level crossâ€‘entropy and aggregating results across batches.", "business_intent": "Enable reliable evaluation of language model performance by providing a standard perplexity measurement that can be integrated into training and validation pipelines.", "keywords": ["perplexity", "language modeling", "metric", "evaluation", "torch", "torchmetrics", "cross-entropy", "NLP"], "summary_hash": "5e1379f6c0a4", "cached_at": "2026-02-08T10:53:00+00:00"}