{"summary": "Implements a CUDA‑graph based greedy decoder for recurrent neural network transducer (RNNT) models, providing kernel generators for the decoding loops and a wrapper class that builds, reinitializes and executes the graph on the GPU.", "business_intent": "Boost real‑time speech‑to‑text inference speed by using CUDA graphs to minimise kernel launch overhead and maximise throughput of RNNT greedy decoding on NVIDIA GPUs.", "keywords": ["RNNT", "greedy decoding", "CUDA graph", "GPU acceleration", "ASR inference", "kernel generation", "performance optimization", "NVIDIA NeMo", "PyTorch"], "summary_hash": "a001649fce28", "cached_at": "2026-02-08T11:15:39+00:00"}