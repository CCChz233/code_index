{"summary": "The script parses command‑line options, locates raw text files, and generates index and memory‑mapped data files required for Megatron‑LM style language model pre‑training using NeMo utilities.", "business_intent": "Prepare and optimize large text corpora for efficient, scalable language model training on high‑performance GPU clusters.", "keywords": ["Megatron", "pretraining", "language modeling", "memory‑mapped dataset", "index building", "NeMo", "data preprocessing", "text corpus", "argparse", "glob"], "summary_hash": "a23aff80f341", "cached_at": "2026-02-08T11:42:51+00:00"}