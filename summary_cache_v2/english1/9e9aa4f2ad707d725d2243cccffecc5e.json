{"summary": "Defines two neural modules that implement a transformer‑based bottleneck architecture for automatic speech recognition: one module builds and runs the encoder side, the other builds and runs the decoder side. Both modules assemble configurable sub‑encoders (bridge, perceiver, pooling) and a transformer encoder/decoder, expose supported configuration options, and handle input masking and neural type validation.", "business_intent": "Provide reusable, configurable transformer bottleneck components that can be integrated into ASR pipelines to improve model efficiency and flexibility while supporting various encoder/decoder configurations.", "keywords": ["transformer", "bottleneck", "encoder", "decoder", "ASR", "speech recognition", "neural module", "configuration", "bridge encoder", "perceiver encoder", "pooling encoder", "masking", "neural types"], "summary_hash": "f0dc9140275f", "cached_at": "2026-02-08T11:18:11+00:00"}