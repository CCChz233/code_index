{"summary": "A container class for the Conditional DETR decoder that stores the final hidden states, optional per‑layer hidden states, self‑attention and cross‑attention weights, and an optional stack of layer‑normalized intermediate decoder activations for use with auxiliary decoding losses.", "business_intent": "Enable downstream processing and training of Conditional DETR models by providing a unified, structured representation of decoder outputs, including auxiliary intermediate activations needed for multi‑layer loss computation.", "keywords": ["decoder output", "hidden states", "self‑attention", "cross‑attention", "intermediate activations", "layernorm", "auxiliary loss", "Conditional DETR", "model output container", "torch tensors"], "summary_hash": "1e3ad190703e", "cached_at": "2026-02-09T09:48:27+00:00"}