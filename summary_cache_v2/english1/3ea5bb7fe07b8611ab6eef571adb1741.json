{"summary": "Encapsulates a neural network building block that sequentially applies a convolution operation, a ReLU activation, and a normalization step to an input tensor, providing a reusable layer for feature extraction.", "business_intent": "Enable developers to quickly assemble stable and efficient deep‑learning models, particularly for computer‑vision tasks, by offering a ready‑made component that improves training convergence and model performance.", "keywords": ["convolution", "ReLU", "normalization", "neural network layer", "deep learning", "computer vision", "feature extraction", "module", "forward pass"], "summary_hash": "55ea8abbf317", "cached_at": "2026-02-08T08:32:18+00:00"}