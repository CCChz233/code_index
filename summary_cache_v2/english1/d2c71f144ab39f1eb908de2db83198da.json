{"summary": "A neural encoder that wraps the LUKE language model to transform input text into contextual embeddings, exposing a forward method for inference.", "business_intent": "Enable applications to obtain rich token and entity representations for tasks such as classification, information extraction, or semantic search.", "keywords": ["LUKE", "encoder", "transformer", "embeddings", "NLP", "forward", "PyTorch", "representation", "language model"], "summary_hash": "5256af444c9e", "cached_at": "2026-02-09T10:45:08+00:00"}