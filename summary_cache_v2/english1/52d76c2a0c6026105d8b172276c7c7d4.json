{"summary": "A collection of example scripts that demonstrate how to work with Megatron‑based CLIP models in the NVIDIA NeMo framework, covering conversion of external checkpoints to NeMo format, distributed pre‑training, inference for embedding extraction or similarity scoring, and zero‑shot ImageNet evaluation.", "business_intent": "Help AI developers and researchers quickly adopt and deploy large‑scale vision‑language models by providing ready‑to‑run pipelines for model conversion, training, inference, and evaluation within a scalable, distributed environment.", "keywords": ["CLIP", "vision-language", "Megatron", "NeMo", "model conversion", "pretraining", "inference", "zero-shot evaluation", "ImageNet", "distributed training", "checkpoint", "embeddings"], "summary_hash": "18b837638108", "cached_at": "2026-02-08T11:56:17+00:00"}