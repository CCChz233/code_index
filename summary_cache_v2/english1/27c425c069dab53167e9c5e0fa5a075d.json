{"summary": "Provides a multilingual token classification model built on the XLM-Roberta transformer, handling the forward computation to produce token-level label predictions.", "business_intent": "Allow applications to perform token-level NLP tasks such as named entity recognition, part-of-speech tagging, or other sequence labeling across many languages.", "keywords": ["XLM-Roberta", "token classification", "multilingual", "transformer", "NLP", "sequence labeling", "named entity recognition", "model inference"], "summary_hash": "b371853fb93f", "cached_at": "2026-02-09T12:01:51+00:00"}