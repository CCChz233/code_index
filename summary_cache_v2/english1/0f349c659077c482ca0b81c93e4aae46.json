{"summary": "A TensorFlow data structure that encapsulates the outputs of a Longformer model, including the full sequence of hidden states, a pooled representation of the first token, and optional intermediate hidden layers and attention matrices.", "business_intent": "Facilitates downstream processing such as classification or analysis by providing both tokenâ€‘level embeddings and a compact pooled vector, while also exposing detailed attention information for debugging or interpretability.", "keywords": ["Longformer", "TensorFlow", "model output", "hidden states", "pooled representation", "attention weights", "global attention", "sequence embedding"], "summary_hash": "70bb889578f8", "cached_at": "2026-02-09T11:14:27+00:00"}