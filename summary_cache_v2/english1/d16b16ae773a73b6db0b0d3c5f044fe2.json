{"summary": "Defines a backend class that integrates Llama‑Cpp language models into the Optimum Benchmark framework. It manages model loading based on a configuration object, prepares input tensors, maintains a pre‑fill cache for efficient generation, and executes forward passes to produce generated text.", "business_intent": "Provide a reusable component for evaluating the performance and latency of Llama‑Cpp models during text generation tasks, supporting systematic benchmarking and comparison within the Optimum ecosystem.", "keywords": ["LlamaCpp", "backend", "model loading", "inference", "pre‑fill cache", "benchmarking", "Optimum", "language model", "text generation", "configuration"], "summary_hash": "707aacea301d", "cached_at": "2026-02-09T02:30:56+00:00"}