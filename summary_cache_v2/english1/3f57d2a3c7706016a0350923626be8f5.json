{"summary": "Implements a fused scaled dot‑product attention module for the CogVideoX model, applying rotary positional embeddings to query and key tensors while skipping spatial normalization, to efficiently compute attention scores.", "business_intent": "Accelerate and simplify the integration of high‑performance attention mechanisms in video generation pipelines based on CogVideoX, reducing computational overhead and improving inference speed.", "keywords": ["scaled dot-product attention", "rotary embedding", "CogVideoX", "fused processor", "video transformer", "query", "key", "no spatial normalization", "AI video generation"], "summary_hash": "848006633fe4", "cached_at": "2026-02-09T04:06:07+00:00"}