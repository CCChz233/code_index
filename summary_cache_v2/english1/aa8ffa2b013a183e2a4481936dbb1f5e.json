{"summary": "A command‑line utility that loads a pretrained speech‑to‑text model, runs it on a calibration dataset, computes activation maximum values, and stores the calibration data needed for post‑training quantization.", "business_intent": "Facilitate the deployment of automatic speech recognition models on resource‑constrained hardware by preparing them for low‑precision quantization, thereby reducing memory footprint and inference latency.", "keywords": ["ASR", "speech-to-text", "quantization", "calibration", "activation max", "NeMo", "pretrained model", "torch", "command-line"], "summary_hash": "7603cb4d37e7", "cached_at": "2026-02-08T10:38:54+00:00"}