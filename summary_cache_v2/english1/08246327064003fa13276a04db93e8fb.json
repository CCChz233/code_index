{"summary": "We need to produce JSON with keys: summary, business_intent, keywords (list). Provide description of class responsibility and behavior.\n\nClass VideoToCharDataset loads video and transcript data from manifest JSON lines, filters by duration, limits utterances, maps characters to indices, optional normalization, optional BOS/EOS tokens, returns samples possibly with IDs, supports channel selection for audio (though video dataset maybe includes audio). Provide business intent: preparing data for training speech/video-to-character models, e.g., speech recognition or video captioning.\n\nKeywords: dataset, video, transcript, manifest, duration filtering, character mapping, normalization, BOS/EOS, sample ID, channel selection, PyTorch (maybe), data loading.\n\nLet's craft summary: \"Dataset class that reads a manifest file where each line is a JSON object describing a video file, its transcription and timing information. It loads the video (or audio) tensors, applies optional duration filters, limits number of utterances, normalizes and tokenizes the transcript into character indices, optionally adds BOS/EOS tokens, and returns each sample (and optionally its ID) in a format suitable for training models.\"\n\nBusiness intent: \"Facilitate preparation of training data for video‑to‑text or speech‑recognition models by providing a ready‑to‑use PyTorch‑compatible dataset that handles loading, filtering, and character‑level encoding of video and transcript pairs.\"\n\nKeywords list.\n\nNow produce JSON.\n\nMake sure no method names verbatim (they said do NOT list method names verbatim). So we shouldn't mention __init__ or output_types. That's fine.\n\nLet's craft.\n\nJSON object with keys.\n\nOk.assistantfinal{\n  \"summary\": \"A dataset implementation that reads a line‑by‑line JSON manifest describing video file paths, corresponding transcripts, and timing metadata. It loads each video (or its audio channel), filters entries based on configurable minimum and maximum durations, optionally caps the total number of utterances, normalizes and tokenizes the transcript into a sequence of character IDs using a supplied alphabet, and can prepend/append BOS/EOS symbols. Each sample is returned as tensors ready for model consumption, with an optional sample identifier.\",\n  \"business_intent\": \"Enable efficient preparation of video‑to‑text training data for speech recognition, video captioning, or similar sequence‑to‑sequence models by providing a ready‑to‑use, configurable dataset that handles loading, filtering, and character‑level encoding of video and transcript pairs.\",\n  \"keywords\": [\n    \"dataset", "business_intent": "We need to produce JSON with keys: summary, business_intent, keywords (list). Provide description of class responsibility and behavior.\n\nClass VideoToCharDataset loads video and transcript data from manifest JSON lines, filters by duration, limits utterances, maps characters to indices, optional normalization, optional BOS/EOS tokens, returns samples possibly with IDs, supports channel selection for audio (though video dataset maybe includes audio). Provide business intent: preparing data for training speech/video-to-character models, e.g., speech recognition or video captioning.\n\nKeywords: dataset, video, transcript, manifest, duration filtering, character mapping, normalization, BOS/EOS, sample ID, channel selection, PyTorch (maybe), data loading.\n\nLet's craft summary: \"Dataset class that reads a manifest file where each line is a JSON object describing a video file, its transcription and timing information. It loads the video (or audio) tensors, applies optional duration filters, limits number of utterances, normalizes and tokenizes the transcript into character indices, optionally adds BOS/EOS tokens, and returns each sample (and optionally its ID) in a format suitable for training models.\"\n\nBusiness intent: \"Facilitate preparation of training data for video‑to‑text or speech‑recognition models by providing a ready‑to‑use PyTorch‑compatible dataset that handles loading, filtering, and character‑level encoding of video and transcript pairs.\"\n\nKeywords list.\n\nNow produce JSON.\n\nMake sure no method names verbatim (they said do NOT list method names verbatim). So we shouldn't mention __init__ or output_types. That's fine.\n\nLet's craft.\n\nJSON object with keys.\n\nOk.assistantfinal{\n  \"summary\": \"A dataset implementation that reads a line‑by‑line JSON manifest describing video file paths, corresponding transcripts, and timing metadata. It loads each video (or its audio channel), filters entries based on configurable minimum and maximum durations, optionally caps the total number of utterances, normalizes and tokenizes the transcript into a sequence of character IDs using a supplied alphabet, and can prepend/append BOS/EOS symbols. Each sample is returned as tensors ready for model consumption, with an optional sample identifier.\",\n  \"business_intent\": \"Enable efficient preparation of video‑to‑text training data for speech recognition, video captioning, or similar sequence‑to‑sequence models by providing a ready‑to‑use, configurable dataset that handles loading, filtering, and character‑level encoding of video and transcript pairs.\",\n  \"keywords\": [\n    \"dataset", "keywords": [], "summary_hash": "42bb6c952b99", "cached_at": "2026-02-08T08:49:11+00:00"}