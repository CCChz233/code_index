{"summary": "A neural network class that encapsulates a GPT-style transformer with a language modeling head for predicting the next token in a sequence.", "business_intent": "Enable developers to load, fine‑tune, or use a pre‑trained GPT language model for text generation, completion, and downstream NLP tasks.", "keywords": ["GPT", "transformer", "language model", "text generation", "token prediction", "neural network", "fine‑tuning", "pre‑trained model"], "summary_hash": "ba592712c3c2", "cached_at": "2026-02-09T07:16:54+00:00"}