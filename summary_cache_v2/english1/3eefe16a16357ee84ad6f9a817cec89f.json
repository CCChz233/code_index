{"summary": "We need to produce JSON with keys: summary, business_intent, keywords (list). Must not list method names verbatim. Provide summary of class responsibility and behavior. Business intent: what business problem it solves. Keywords: relevant terms.\n\nLet's craft.\n\nClass S3KeySensorDecorator: a decorator that attaches Airflow S3KeySensor before start step of flow, ensuring start step waits for S3 objects. Works only when flow scheduled on Airflow and compiled using airflow create. Supports multiple sensors, all must complete. Configurable parameters: timeout, poke_interval, mode, exponential_backoff, pool, soft_fail, name, description, bucket_key(s), bucket_name, wildcard_match, aws_conn_id, verify. Provide validation helper.\n\nNow produce JSON.\n\nKeywords: airflow, s3, sensor, decorator, start step, scheduling, timeout, poke_interval, mode, exponential_backoff, pool, soft_fail, bucket_key, bucket_name, wildcard, aws_conn_id, ssl verification.\n\nLet's craft.\n\nSummary: \"Decorator that injects an Airflow S3KeySensor into a flow, causing the flow’s initial step to wait until specified S3 objects become available. Supports multiple sensors, configurable timeout, polling interval, execution mode, back‑off, pooling, soft‑fail, naming, description, bucket/key specifications, wildcard matching, and AWS connection settings. Validation ensures parameters are correct.\"\n\nBusiness intent: \"Enable data pipelines to reliably start only after required data files are present in S3, preventing downstream failures and coordinating execution in Airflow‑managed workflows.\"\n\nNow produce JSON.\n\nMake sure no markdown.\n\nLet's output.\n{\n  \"summary\": \"A decorator that attaches an Airflow S3KeySensor to a flow, making the flow's start step wait until the specified S3 objects are available. It works only with Airflow‑scheduled flows compiled via `airflow create` and supports multiple sensors, each configurable with timeout, poke interval, mode (poke or reschedule), exponential backoff, pool, soft‑fail, name, description, bucket/key definitions, wildcard matching, AWS connection ID, and SSL verification. Includes a simple validation helper.\",\n  \"business_intent\": \"Guarantee that data pipelines begin execution only after required files are present in S3, ensuring data availability, reducing downstream errors, and coordinating task start times within Airflow‑managed workflows.\",\n  \"keywords\": [\n    \"airflow\",\n    \"s3\",\n    \"sensor\",\n    \"decorator\",\n    \"pipeline\",\n    \"data availability", "business_intent": "We need to produce JSON with keys: summary, business_intent, keywords (list). Must not list method names verbatim. Provide summary of class responsibility and behavior. Business intent: what business problem it solves. Keywords: relevant terms.\n\nLet's craft.\n\nClass S3KeySensorDecorator: a decorator that attaches Airflow S3KeySensor before start step of flow, ensuring start step waits for S3 objects. Works only when flow scheduled on Airflow and compiled using airflow create. Supports multiple sensors, all must complete. Configurable parameters: timeout, poke_interval, mode, exponential_backoff, pool, soft_fail, name, description, bucket_key(s), bucket_name, wildcard_match, aws_conn_id, verify. Provide validation helper.\n\nNow produce JSON.\n\nKeywords: airflow, s3, sensor, decorator, start step, scheduling, timeout, poke_interval, mode, exponential_backoff, pool, soft_fail, bucket_key, bucket_name, wildcard, aws_conn_id, ssl verification.\n\nLet's craft.\n\nSummary: \"Decorator that injects an Airflow S3KeySensor into a flow, causing the flow’s initial step to wait until specified S3 objects become available. Supports multiple sensors, configurable timeout, polling interval, execution mode, back‑off, pooling, soft‑fail, naming, description, bucket/key specifications, wildcard matching, and AWS connection settings. Validation ensures parameters are correct.\"\n\nBusiness intent: \"Enable data pipelines to reliably start only after required data files are present in S3, preventing downstream failures and coordinating execution in Airflow‑managed workflows.\"\n\nNow produce JSON.\n\nMake sure no markdown.\n\nLet's output.\n{\n  \"summary\": \"A decorator that attaches an Airflow S3KeySensor to a flow, making the flow's start step wait until the specified S3 objects are available. It works only with Airflow‑scheduled flows compiled via `airflow create` and supports multiple sensors, each configurable with timeout, poke interval, mode (poke or reschedule), exponential backoff, pool, soft‑fail, name, description, bucket/key definitions, wildcard matching, AWS connection ID, and SSL verification. Includes a simple validation helper.\",\n  \"business_intent\": \"Guarantee that data pipelines begin execution only after required files are present in S3, ensuring data availability, reducing downstream errors, and coordinating task start times within Airflow‑managed workflows.\",\n  \"keywords\": [\n    \"airflow\",\n    \"s3\",\n    \"sensor\",\n    \"decorator\",\n    \"pipeline\",\n    \"data availability", "keywords": [], "summary_hash": "01aaffdb17af", "cached_at": "2026-02-08T08:38:59+00:00"}