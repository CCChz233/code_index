{"summary": "A command‑line utility that loads a trained Megatron‑based BERT model from NVIDIA NeMo, builds the necessary trainer components, and exports the model weights and architecture to an ONNX file for downstream inference.", "business_intent": "Provide a straightforward way to package a NeMo BERT language model for production deployment, enabling fast, platform‑agnostic inference via the ONNX runtime.", "keywords": ["NeMo", "Megatron BERT", "ONNX conversion", "language model export", "model deployment", "inference optimization", "command line tool", "PyTorch"], "summary_hash": "07100b6c1aee", "cached_at": "2026-02-08T11:43:16+00:00"}