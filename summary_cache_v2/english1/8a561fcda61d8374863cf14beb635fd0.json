{"summary": "Implements a dataset wrapper that transforms raw question‑answer pairs and supporting passages into tokenized features suitable for training or evaluating GPT‑style generative question‑answering models, handling context encoding, query and answer preparation, feature caching, and label masking.", "business_intent": "Enable developers and researchers to quickly prepare and load processed data for GPT‑based generative QA pipelines, reducing preprocessing effort and ensuring consistent input formatting for model training and inference.", "keywords": ["GPT", "generative QA", "dataset", "preprocessing", "tokenization", "context encoding", "answer preparation", "feature conversion", "caching", "label masking"], "summary_hash": "a5a63d3ff12a", "cached_at": "2026-02-08T10:04:03+00:00"}