{"summary": "Utility module that assesses whether the current PyTorch environment and hardware support the optimized Cutlass and Flash attention kernels, allowing the library to choose compatible highâ€‘performance attention implementations.", "business_intent": "To ensure that the most efficient attention kernels are selected when available, improving model inference and training speed while safely falling back to standard implementations when compatibility constraints are not met.", "keywords": ["compatibility", "attention", "cutlass", "flash", "pytorch", "hardware", "optimization", "fallback"], "summary_hash": "9544fe48c12e", "cached_at": "2026-02-08T23:32:55+00:00"}