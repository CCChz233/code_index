{"summary": "A structured container that holds the outputs of a Vision Transformer Masked AutoEncoder, including the final hidden representations, the binary mask of patched inputs, the indices to restore original patch order, and optional intermediate hidden states and attention matrices.", "business_intent": "Facilitate image reconstruction, model inspection, and downstream vision tasks by providing easy access to the model's core outputs and internal representations for analysis, debugging, and fineâ€‘tuning.", "keywords": ["vision transformer", "masked autoencoder", "output container", "hidden states", "attention maps", "mask tensor", "restore indices", "batch processing", "tensor outputs"], "summary_hash": "89a8669121a1", "cached_at": "2026-02-09T11:43:17+00:00"}