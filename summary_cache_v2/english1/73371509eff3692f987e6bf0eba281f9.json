{"summary": "A Keras layer that encapsulates a recurrent network and runs it simultaneously in forward and backward directions, optionally merging the two streams, while preserving the standard RNN interface for building, calling, masking, and state handling.", "business_intent": "Allow neural network models to capture both past and future context in sequential inputs by providing an easy-to-use bidirectional wrapper for any compatible RNN layer.", "keywords": ["bidirectional", "RNN", "LSTM", "GRU", "sequence processing", "forward pass", "backward pass", "merge mode", "Keras layer", "neural network", "masking", "state management", "configurable"], "summary_hash": "f6939e71d8b4", "cached_at": "2026-02-09T12:00:47+00:00"}