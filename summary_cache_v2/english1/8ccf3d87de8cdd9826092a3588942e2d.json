{"summary": "Provides data structures and iterable dataset implementations for loading and serving tokenized text‑normalization examples used in decoder (spoken‑to‑written) training, supporting both in‑memory and tarred‑pickle storage with sharding, shuffling, and context handling.", "business_intent": "Enable scalable training of text‑normalization models within speech‑to‑text pipelines by efficiently delivering decoded examples to neural networks.", "keywords": ["text normalization", "decoder", "dataset", "NeMo", "PyTorch", "iterable dataset", "tarred files", "sharding", "tokenization", "speech processing"], "summary_hash": "14d69c1c1b1d", "cached_at": "2026-02-08T11:28:32+00:00"}