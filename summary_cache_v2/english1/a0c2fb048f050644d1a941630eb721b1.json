{"summary": "The package supplies example command‑line tools that demonstrate how to train, evaluate, and run inference for speech classification and voice activity detection models using the NeMo toolkit. It covers both frame‑wise and segment‑wise VAD, handling dataset manifests, configurable Hydra settings, multi‑GPU distributed training, post‑processing of frame predictions into speech segments or RTTM files, and optional quality metrics such as AUROC and DER, plus utilities for visualising results.", "business_intent": "To accelerate development of speech‑related AI solutions by providing ready‑to‑use scripts that simplify model training, validation, and deployment for tasks like voice activity detection, command recognition, and language identification.", "keywords": ["speech classification", "voice activity detection", "frame-level VAD", "segment-level VAD", "NeMo", "distributed training", "manifest files", "AUROC", "DER", "RTTM", "visualization"], "summary_hash": "54f72bf87f54", "cached_at": "2026-02-08T11:57:29+00:00"}