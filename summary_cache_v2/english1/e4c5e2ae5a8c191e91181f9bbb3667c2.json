{"summary": "Defines a neural network module that transforms natural language inputs into dense vector embeddings compatible with 2‑D or 3‑D image feature maps. The encoder can be initialized with pretrained CLIP weights or with random parameters, allowing seamless multimodal fusion of text and visual data in downstream models.", "business_intent": "Enable developers of medical imaging AI systems to incorporate textual context (e.g., radiology reports) alongside image data, improving diagnostic accuracy and supporting multimodal research and product development.", "keywords": ["text embedding", "CLIP", "multimodal", "encoder", "vision-language", "pretrained weights", "torch", "neural network", "medical imaging", "MONAI"], "summary_hash": "bf0f932e4742", "cached_at": "2026-02-08T13:20:31+00:00"}