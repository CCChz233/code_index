{"summary": "Provides Triton‑based GPU kernels and supporting utilities to execute split‑K fast multi‑head attention, handling forward computation, reduction, dequantization, autotuning and cache management.", "business_intent": "Enable high‑performance, scalable transformer attention operations on GPUs by leveraging split‑K parallelism and Triton kernels, reducing latency and improving throughput for AI workloads.", "keywords": ["Triton", "GPU kernels", "split‑K", "multi‑head attention", "fast attention", "forward computation", "reduction", "dequantization", "autotuning", "cache management", "performance optimization"], "summary_hash": "7a4e65eefc76", "cached_at": "2026-02-08T23:35:09+00:00"}