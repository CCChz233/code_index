{"summary": "Implements an evaluation component that measures how well a language model ranks relevant context items by computing the average precision against a reference set.", "business_intent": "Enable organizations to quantitatively assess and improve the relevance ranking of retrieved context in LLM-driven applications, supporting model validation and performance monitoring.", "keywords": ["average precision", "LLM evaluation", "context relevance", "ranking metric", "reference comparison", "model assessment", "reproducibility"], "summary_hash": "dd6c50f60754", "cached_at": "2026-02-08T22:44:12+00:00"}