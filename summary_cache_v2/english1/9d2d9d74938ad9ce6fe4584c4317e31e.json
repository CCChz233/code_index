{"summary": "Implements Groq chat integration for the Litellm framework, constructing HTTP calls to Groq's chat endpoint, handling both streaming and non‑streaming responses, and converting them into Litellm's unified ModelResponse format. Includes logic to translate OpenAI‑style chat requests into Groq‑compatible payloads and to map Groq responses back to the expected OpenAI‑like schema.", "business_intent": "Provide a seamless bridge that allows Litellm users to leverage Groq's chat models through a familiar OpenAI‑compatible interface, supporting real‑time streaming and standard completions while abstracting away provider‑specific details.", "keywords": ["Groq", "chat completion", "Litellm", "API integration", "streaming", "response transformation", "OpenAI compatibility", "HTTP request"], "summary_hash": "6a103156db55", "cached_at": "2026-02-08T08:09:20+00:00"}