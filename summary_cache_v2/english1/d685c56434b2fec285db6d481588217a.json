{"summary": "A stopping criterion that halts text generation once the count of newly generated tokens surpasses a predefined limit, disregarding the tokens present in the initial prompt.", "business_intent": "To enforce a maximum output length for language model generation, preventing overly long responses and managing token usage costs.", "keywords": ["token limit", "generation stopping", "max new tokens", "decoder-only models", "output length control", "language model", "early termination"], "summary_hash": "2e12de2fe013", "cached_at": "2026-02-09T07:56:50+00:00"}