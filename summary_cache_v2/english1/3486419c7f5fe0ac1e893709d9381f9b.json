{"summary": "Encapsulates a sub‑layer by applying layer normalization to the input, passing the normalized tensor through a given sub‑module, applying dropout to its output, and finally adding the original input as a residual connection.", "business_intent": "Provide a reusable component that streamlines the construction of deep learning models—especially transformer‑style architectures—by automatically handling normalization, dropout, and residual addition in a single, composable wrapper.", "keywords": ["normalization", "dropout", "residual connection", "wrapper", "sublayer", "transformer", "neural network", "module", "layer composition"], "summary_hash": "a8bc6d4272e1", "cached_at": "2026-02-08T23:29:38+00:00"}