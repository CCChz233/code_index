{"summary": "We need to produce JSON with summary, business_intent, keywords list.\n\nWe need to infer from file-level metadata and class summaries.\n\nFile path: nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py\n\nDocstring empty.\n\nImports include TokenizerSpec, various data processors for GLUE tasks (CoLA, MNLI, MRPC, QNLI, QQP, RTE, SST-2, STS-B, WNLI, XNLI). Also Dataset, NeuralTypes, logging, numpy, os, pickle, torch, typing.\n\nGlobals: GLUE_TASKS_NUM_LABELS (likely mapping task name to number of labels).\n\nClass summaries:\n\n- GLUEDataset: ... (not detailed but likely dataset for GLUE tasks, handling tokenization, features, etc.)\n\n- InputFeatures: Encapsulates a single pre‑processed data example, storing token identifiers, attention masks, segment identifiers, and the associated label.\n\n- TextToTextGLUEDataset: Provides a dataset wrapper that transforms GLUE benchmark examples into a text-to-text representation, handling feature conversion, length queries, item retrieval, and batch collation with optional history masking and output type specification.\n\n- TextToTextXNLIDataset: Implements a PyTorch-friendly dataset for the XNLI multilingual natural language inference corpus, converting each example into a source‑target text pair suitable for text‑to‑text models and offering utilities for batching and feature extraction.\n\nThus the file defines dataset classes for GLUE benchmark tasks, both standard token classification and text-to-text format, plus XNLI variant.\n\nBusiness intent: Provide data loading and preprocessing utilities for GLUE benchmark tasks within NVIDIA NeMo framework, enabling training/evaluation of NLP models, especially seq2seq/text-to-text models.\n\nKeywords: GLUE, dataset, NLP, tokenization, text-to-text, XNLI, PyTorch, NeMo, preprocessing, features, neural types, classification, regression.\n\nNow produce JSON.\n\nMake sure not to list function names verbatim. Provide summary of file responsibilities.\n\nLet's craft.\n\nJSON:\n\n{\n  \"summary\": \"Defines dataset classes for loading and preprocessing GLUE benchmark and XNLI data within the NeMo framework. Includes a generic GLUE dataset, a feature container, and wrappers that convert examples into text‑to‑text pairs for seq2seq models, handling tokenization, masking, and batch collation.\",\n  \"business_intent\": \"Enable easy integration of GLUE and XNLI datasets into NLP", "business_intent": "We need to produce JSON with summary, business_intent, keywords list.\n\nWe need to infer from file-level metadata and class summaries.\n\nFile path: nemo/collections/nlp/data/glue_benchmark/glue_benchmark_dataset.py\n\nDocstring empty.\n\nImports include TokenizerSpec, various data processors for GLUE tasks (CoLA, MNLI, MRPC, QNLI, QQP, RTE, SST-2, STS-B, WNLI, XNLI). Also Dataset, NeuralTypes, logging, numpy, os, pickle, torch, typing.\n\nGlobals: GLUE_TASKS_NUM_LABELS (likely mapping task name to number of labels).\n\nClass summaries:\n\n- GLUEDataset: ... (not detailed but likely dataset for GLUE tasks, handling tokenization, features, etc.)\n\n- InputFeatures: Encapsulates a single pre‑processed data example, storing token identifiers, attention masks, segment identifiers, and the associated label.\n\n- TextToTextGLUEDataset: Provides a dataset wrapper that transforms GLUE benchmark examples into a text-to-text representation, handling feature conversion, length queries, item retrieval, and batch collation with optional history masking and output type specification.\n\n- TextToTextXNLIDataset: Implements a PyTorch-friendly dataset for the XNLI multilingual natural language inference corpus, converting each example into a source‑target text pair suitable for text‑to‑text models and offering utilities for batching and feature extraction.\n\nThus the file defines dataset classes for GLUE benchmark tasks, both standard token classification and text-to-text format, plus XNLI variant.\n\nBusiness intent: Provide data loading and preprocessing utilities for GLUE benchmark tasks within NVIDIA NeMo framework, enabling training/evaluation of NLP models, especially seq2seq/text-to-text models.\n\nKeywords: GLUE, dataset, NLP, tokenization, text-to-text, XNLI, PyTorch, NeMo, preprocessing, features, neural types, classification, regression.\n\nNow produce JSON.\n\nMake sure not to list function names verbatim. Provide summary of file responsibilities.\n\nLet's craft.\n\nJSON:\n\n{\n  \"summary\": \"Defines dataset classes for loading and preprocessing GLUE benchmark and XNLI data within the NeMo framework. Includes a generic GLUE dataset, a feature container, and wrappers that convert examples into text‑to‑text pairs for seq2seq models, handling tokenization, masking, and batch collation.\",\n  \"business_intent\": \"Enable easy integration of GLUE and XNLI datasets into NLP", "keywords": [], "summary_hash": "61cbee89e42d", "cached_at": "2026-02-08T11:27:22+00:00"}