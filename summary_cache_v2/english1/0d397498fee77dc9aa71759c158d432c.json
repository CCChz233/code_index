{"summary": "Provides a neural module that performs Viterbi decoding over weighted finite‑state automaton (WFSA) graphs using the k2 library. It can decode using a pure topology graph or a topology combined with a token language‑model graph, outputting either the best hypothesis or a full lattice, with configurable label handling, frame‑aligned output, and optional batch splitting to control memory consumption.", "business_intent": "Enable fast, flexible, and memory‑efficient graph‑based decoding for automatic speech recognition systems, allowing integration of language models and topology constraints to generate accurate transcription hypotheses.", "keywords": ["Viterbi", "decoder", "WFSA", "k2", "ASR", "graph decoding", "language model integration", "lattice generation", "batch splitting", "memory optimization", "NeuralModule"], "summary_hash": "a97cbcac82e8", "cached_at": "2026-02-08T11:08:14+00:00"}