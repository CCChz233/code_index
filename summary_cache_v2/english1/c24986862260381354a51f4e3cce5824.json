{"summary": "Provides a utility to assess the relevance of language model outputs by invoking an LLM as a judge, exposing a simple helper function for relevance evaluation.", "business_intent": "Enable automated quality checking of AI-generated text to ensure it aligns with expected topics or criteria, supporting content validation and model improvement workflows.", "keywords": ["LLM", "relevance evaluation", "AI content assessment", "OpenAI", "instructor", "pydantic", "helper function", "example script"], "summary_hash": "d66e4a17c792", "cached_at": "2026-02-09T06:40:30+00:00"}