{"summary": "The module implements a set of metrics for evaluating how accurately retrieved context aligns with the information needed in a conversational turn. It provides utilities to compute precision scores, both overall and per‑turn, and supports calculations with reference context sets as well as scenarios where no reference is available, using either language‑model‑based ranking or non‑LLM similarity methods.", "business_intent": "Enable developers of retrieval‑augmented generation and chatbot systems to quantitatively assess and improve the relevance and utilization of retrieved documents, thereby enhancing answer quality and user satisfaction.", "keywords": ["context precision", "retrieval relevance", "RAG evaluation", "LLM ranking", "non‑LLM similarity", "single‑turn metric", "average precision", "context utilization", "conversation AI", "performance measurement"], "summary_hash": "3426e009a659", "cached_at": "2026-02-08T22:49:52+00:00"}