{"summary": "Encapsulates configuration parameters for handling prompt injection in LiteLLM and provides a helper to validate the associated LLM API settings.", "business_intent": "Enable applications to safely configure and verify LLM API calls, reducing misconfiguration and mitigating prompt injection risks.", "keywords": ["prompt injection", "LLM API", "validation", "configuration", "safety", "helper"], "summary_hash": "faf2c9dc7ec4", "cached_at": "2026-02-08T06:47:27+00:00"}