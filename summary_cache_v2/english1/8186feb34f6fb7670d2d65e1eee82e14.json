{"summary": "A transformer-based encoder-decoder model specialized for conditional text generation on long input sequences, offering training and inference capabilities for tasks that require processing extensive documents.", "business_intent": "Facilitate applications such as document summarization, translation, or any generation task that involves long source texts, improving the handling of large-context language data.", "keywords": ["transformer", "encoder-decoder", "long document", "conditional generation", "summarization", "translation", "natural language processing", "attention", "sliding window"], "summary_hash": "cdf8acc3bbc0", "cached_at": "2026-02-09T07:08:58+00:00"}