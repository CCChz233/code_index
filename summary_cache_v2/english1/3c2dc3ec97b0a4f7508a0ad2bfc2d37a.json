{"summary": "We have to produce JSON with summary, business_intent, keywords list.\n\nWe need to infer from file-level metadata and class summaries.\n\nFile path: nemo/collections/nlp/data/spellchecking_asr_customization/bert_example.py\n\nDocstring empty.\n\nImports: collections.OrderedDict, logging, os.path, transformers.PreTrainedTokenizerBase, typing.\n\nGlobals: none.\n\nClass summaries: BertExample: encapsulates example data and utilities for demonstrating BERT model training and inference, storing a feature dictionary used in NLP pipelines.\n\nBertExampleBuilder: constructs BERT-compatible example objects from raw textual inputs by tokenizing into wordpieces, aligning character spans, extracting feature vectors, and assembling the data into a structured format ready for model consumption.\n\nThus file's responsibility: provide data structures and builder for BERT examples for spellchecking ASR customization.\n\nBusiness intent: enable preparation of training/inference data for BERT models in speech recognition spellchecking customization, facilitating tokenization and feature extraction.\n\nKeywords: BERT, example, builder, tokenization, wordpiece, feature extraction, ASR, spellchecking, data preparation, NLP, NeMo.\n\nNow produce JSON.\n\nNeed to ensure no function names verbatim (none). Provide summary, business_intent, keywords list.\n\nLet's craft.\n\nSummary: \"Defines data containers and a builder that transform raw text into BERT‑compatible feature dictionaries, handling tokenization, word‑piece alignment and span mapping for use in spell‑checking ASR customization pipelines.\"\n\nBusiness intent: \"Prepare and format input data for training or inference with BERT models in automatic speech recognition spell‑checking, streamlining the creation of feature sets required by NeMo NLP components.\"\n\nKeywords list.\n\nLet's output JSON.\n\nMake sure proper JSON with double quotes.\n\nReturn only JSON object.\n\nLet's craft final answer.\n{\n  \"summary\": \"Provides a data container and a builder that convert raw textual inputs into BERT‑compatible feature dictionaries, performing tokenization, word‑piece alignment, and span extraction for use in spell‑checking ASR customization pipelines.\",\n  \"business_intent\": \"Facilitate the preparation and formatting of training and inference data for BERT models within automatic speech recognition spell‑checking workflows, enabling efficient integration with NeMo NLP components.\",\n  \"keywords\": [\n    \"BERT\",\n    \"example\",\n    \"builder\",\n    \"tokenization\",\n    \"wordpiece\",\n    \"feature extraction\",\n    \"ASR\",\n    \"spellchecking\",\n    \"data preparation\",\n    \"NLP\",\n    \"Ne", "business_intent": "We have to produce JSON with summary, business_intent, keywords list.\n\nWe need to infer from file-level metadata and class summaries.\n\nFile path: nemo/collections/nlp/data/spellchecking_asr_customization/bert_example.py\n\nDocstring empty.\n\nImports: collections.OrderedDict, logging, os.path, transformers.PreTrainedTokenizerBase, typing.\n\nGlobals: none.\n\nClass summaries: BertExample: encapsulates example data and utilities for demonstrating BERT model training and inference, storing a feature dictionary used in NLP pipelines.\n\nBertExampleBuilder: constructs BERT-compatible example objects from raw textual inputs by tokenizing into wordpieces, aligning character spans, extracting feature vectors, and assembling the data into a structured format ready for model consumption.\n\nThus file's responsibility: provide data structures and builder for BERT examples for spellchecking ASR customization.\n\nBusiness intent: enable preparation of training/inference data for BERT models in speech recognition spellchecking customization, facilitating tokenization and feature extraction.\n\nKeywords: BERT, example, builder, tokenization, wordpiece, feature extraction, ASR, spellchecking, data preparation, NLP, NeMo.\n\nNow produce JSON.\n\nNeed to ensure no function names verbatim (none). Provide summary, business_intent, keywords list.\n\nLet's craft.\n\nSummary: \"Defines data containers and a builder that transform raw text into BERT‑compatible feature dictionaries, handling tokenization, word‑piece alignment and span mapping for use in spell‑checking ASR customization pipelines.\"\n\nBusiness intent: \"Prepare and format input data for training or inference with BERT models in automatic speech recognition spell‑checking, streamlining the creation of feature sets required by NeMo NLP components.\"\n\nKeywords list.\n\nLet's output JSON.\n\nMake sure proper JSON with double quotes.\n\nReturn only JSON object.\n\nLet's craft final answer.\n{\n  \"summary\": \"Provides a data container and a builder that convert raw textual inputs into BERT‑compatible feature dictionaries, performing tokenization, word‑piece alignment, and span extraction for use in spell‑checking ASR customization pipelines.\",\n  \"business_intent\": \"Facilitate the preparation and formatting of training and inference data for BERT models within automatic speech recognition spell‑checking workflows, enabling efficient integration with NeMo NLP components.\",\n  \"keywords\": [\n    \"BERT\",\n    \"example\",\n    \"builder\",\n    \"tokenization\",\n    \"wordpiece\",\n    \"feature extraction\",\n    \"ASR\",\n    \"spellchecking\",\n    \"data preparation\",\n    \"NLP\",\n    \"Ne", "keywords": [], "summary_hash": "4c3bc0a78e30", "cached_at": "2026-02-08T11:26:43+00:00"}