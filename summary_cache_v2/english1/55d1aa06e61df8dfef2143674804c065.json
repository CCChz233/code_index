{"summary": "TensorFlow Keras layer that implements the Longformer encoder, converting input token sequences into contextualized representations using efficient sliding‑window self‑attention.", "business_intent": "Provide fast, memory‑efficient encoding of long text sequences for NLP tasks such as classification, summarization, and retrieval.", "keywords": ["TensorFlow", "Keras", "Longformer", "encoder", "self-attention", "long sequences", "NLP", "transformer", "sequence modeling"], "summary_hash": "9614cf66bbbe", "cached_at": "2026-02-09T11:13:50+00:00"}