{"summary": "Encapsulates the configuration and metadata required to store a saved dataset in a Spark environment, providing mechanisms to translate between internal representations, protobuf messages, and generic data source objects.", "business_intent": "Enable reliable persistence and exchange of Spark dataset storage details across system boundaries, supporting serialization, deserialization, and integration with external services.", "keywords": ["Spark", "dataset", "storage", "metadata", "serialization", "protobuf", "data source", "conversion", "persistence"], "summary_hash": "39e392a96d51", "cached_at": "2026-02-09T00:14:03+00:00"}