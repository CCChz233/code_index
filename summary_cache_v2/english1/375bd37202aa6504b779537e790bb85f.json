{"summary": "Provides a safety checking component for Stable Diffusion pipelines that evaluates generated images with a pretrained CLIP vision model to identify potentially unsafe or disallowed visual content, supporting both regular PyTorch and ONNX inference paths, and includes a utility for measuring similarity between feature vectors.", "business_intent": "To enforce content moderation policies on AI‑generated images, protecting users and platforms from harmful, offensive, or policy‑violating visual outputs while maintaining efficient deployment options.", "keywords": ["safety filter", "image moderation", "stable diffusion", "CLIP vision model", "pretrained classifier", "content policy", "NSFW detection", "ONNX support", "PyTorch", "feature similarity"], "summary_hash": "3c5cc5462c2c", "cached_at": "2026-02-09T05:25:27+00:00"}