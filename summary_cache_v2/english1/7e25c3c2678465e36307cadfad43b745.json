{"summary": "Implements a linear transformation whose weight matrix is partitioned row-wise across multiple devices, handling bias and performing the forward computation in a distributed manner.", "business_intent": "Enable efficient model parallelism for large neural networks by providing a scalable, row‑parallel linear layer that speeds up training and inference on multi‑GPU or multi‑node setups.", "keywords": ["row parallelism", "linear layer", "model parallel", "distributed computation", "weight partition", "bias handling", "forward pass", "neural network", "GPU acceleration", "scalable training"], "summary_hash": "338d526f5ace", "cached_at": "2026-02-08T23:18:04+00:00"}