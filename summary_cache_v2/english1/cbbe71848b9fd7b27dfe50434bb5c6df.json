{"summary": "A configuration container that encapsulates all architectural and training hyperparameters for a Dinov2 vision‑transformer model, supporting both full model instantiation and backbone usage with customizable output stages.", "business_intent": "Enable developers to define, modify, and reproduce the exact Dinov2 model architecture—including size, depth, attention, feed‑forward, and preprocessing settings—so the model can be instantiated, fine‑tuned, or deployed consistently across vision tasks.", "keywords": ["configuration", "vision transformer", "Dinov2", "hidden size", "layer count", "attention heads", "MLP ratio", "activation function", "dropout", "initializer range", "layer norm epsilon", "image resolution", "patch size", "input channels", "bias", "layer scale", "stochastic depth", "SwiGLU", "output features", "backbone", "reshape hidden states"], "summary_hash": "c90a47bcc472", "cached_at": "2026-02-09T08:52:17+00:00"}