{"summary": "Implements a wrapper around an existing batch sampler that omits the first N batches, exposing only the subsequent batches to the data loading pipeline.", "business_intent": "Allows callers to skip a predefined number of initial batches—e.g., when resuming training from a checkpoint or ignoring warm‑up data—without modifying the original sampler.", "keywords": ["torch", "BatchSampler", "skip", "batches", "iterator", "length", "data loading", "wrapper", "sampling", "checkpoint"], "summary_hash": "ec862ee9ad0c", "cached_at": "2026-02-09T02:09:28+00:00"}