{"summary": "A collection of lightweight FastAPI mock services and a Locust user script that simulate OpenAI‑compatible endpoints and a minimal LiteLLM proxy, enabling load‑testing, benchmarking, and performance evaluation of the LiteLLM proxy layer.", "business_intent": "Provide tools for developers and operations teams to measure and validate the scalability, latency, and reliability of LiteLLM’s proxy functionality under realistic traffic patterns.", "keywords": ["load testing", "benchmarking", "LiteLLM", "proxy", "FastAPI", "OpenAI API mock", "Locust", "streaming responses", "CORS", "authentication", "routing"], "summary_hash": "e226eb4d6bb7", "cached_at": "2026-02-08T08:06:30+00:00"}