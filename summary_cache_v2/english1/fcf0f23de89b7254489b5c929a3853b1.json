{"summary": "Provides a SentencePiece tokenizer wrapper that loads a model, manages special token IDs (BOS, EOS, PAD, MASK, etc.), and offers methods to encode text to token IDs and decode IDs back to text, with optional legacy handling for compatibility.", "business_intent": "Facilitates text preprocessing for large language models during model export and inference, ensuring consistent token handling across NeMo and TensorRT pipelines.", "keywords": ["sentencepiece", "tokenizer", "token IDs", "special tokens", "BOS", "EOS", "PAD", "MASK", "legacy compatibility", "NeMo", "TensorRT", "LLM", "text encoding", "text decoding"], "summary_hash": "8fe55c6096a1", "cached_at": "2026-02-08T11:40:25+00:00"}