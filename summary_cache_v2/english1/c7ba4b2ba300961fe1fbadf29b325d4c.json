{"summary": "Implements the TFeat model that converts 32×32 grayscale image patches into 128‑dimensional learned descriptors via a shallow convolutional neural network, with optional pretrained weights.", "business_intent": "Offers a plug‑and‑play local feature descriptor extractor for computer‑vision applications like visual SLAM, image matching, retrieval, and geometric alignment.", "keywords": ["TFeat", "feature descriptor", "grayscale patches", "32x32", "128‑dimensional", "pretrained", "shallow CNN", "local features", "torch", "computer vision"], "summary_hash": "e77fd24a6a30", "cached_at": "2026-02-09T11:43:10+00:00"}