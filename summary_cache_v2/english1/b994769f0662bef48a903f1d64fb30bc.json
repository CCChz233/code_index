{"summary": "Provides a distributed sampler that selects samples from a dataset based on per‑sample weights, partitioning the weighted sampling across multiple processes and allowing configurable sample counts per rank.", "business_intent": "Facilitate probabilistic, weight‑aware data loading in multi‑node or multi‑GPU training to address class imbalance and ensure each worker receives an appropriate subset of data.", "keywords": ["distributed sampling", "weighted random sampler", "PyTorch", "data loader", "multi‑process", "rank", "num_replicas", "even divisible", "generator", "class imbalance"], "summary_hash": "52bc3e2da8e2", "cached_at": "2026-02-08T11:22:08+00:00"}