{"summary": "A comprehensive pytest suite that verifies the Litellm library's LLM translation layer, ensuring that generic chat/completion/embedding requests are correctly mapped to provider‑specific APIs and that responses—including tool calls, streaming data, images, audio, token limits, caching, and reranking—are accurately parsed and handled across a wide range of models such as OpenAI, Anthropic, Azure, Bedrock, Gemini, Vertex AI, and others.", "business_intent": "Guarantee robust, provider‑agnostic integration of large language model services within the Litellm platform, enabling downstream applications to rely on consistent request formatting, feature support, and response handling regardless of the underlying AI provider.", "keywords": ["LLM translation", "provider mapping", "chat completion", "text completion", "embedding", "tool calls", "streaming", "image handling", "audio handling", "token limits", "prompt caching", "reranking", "pytest", "mocking", "Litellm"], "summary_hash": "90aeefaceade", "cached_at": "2026-02-08T08:03:13+00:00"}