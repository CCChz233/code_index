{"summary": "Implements a sliding‑window inference strategy that partitions an input volume into overlapping sub‑regions (ROIs), runs the model on each batch of windows, blends the predictions, and stitches them back together, while handling padding, device placement, and optional buffering to reduce memory usage.", "business_intent": "Enable scalable, memory‑efficient model inference on large medical images or 3‑D data where full‑volume processing would exceed GPU capacity, supporting flexible ROI sizing, overlap handling, and output blending.", "keywords": ["sliding window", "inference", "ROI", "overlap", "blending", "gaussian weighting", "constant weighting", "device management", "memory optimization", "buffering", "padding", "coordinate passing"], "summary_hash": "1745d0a969b5", "cached_at": "2026-02-08T11:12:24+00:00"}