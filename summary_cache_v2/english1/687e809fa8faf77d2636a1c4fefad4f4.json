{"summary": "Implements scaled dot‑product attention with rotary positional embeddings, supporting multi‑head, grouped‑query, or multi‑query attention configurations for the Stable Audio model, optimized for PyTorch 2.0.", "business_intent": "Provide an efficient, flexible attention processor that accelerates high‑quality audio generation in the Stable Audio system by leveraging modern PyTorch kernels and adaptable attention variants.", "keywords": ["scaled dot-product attention", "rotary embedding", "multi-head attention", "grouped query attention", "multi-query attention", "PyTorch 2.0", "Stable Audio", "audio generation", "attention processor"], "summary_hash": "b863264043ca", "cached_at": "2026-02-09T04:06:24+00:00"}