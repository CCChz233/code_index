{"summary": "Utility module that supplies dataset loaders for several benchmark graph datasets and constructs common graph augmentation pipelines (edge dropping, feature masking, normalization). It also implements a cosine‑based decay scheduler for scalar values such as learning rates, enabling smooth reduction over training steps.", "business_intent": "Simplify the setup of graph representation learning experiments by providing ready‑to‑use data acquisition and augmentation utilities together with a learning‑rate decay mechanism, thereby accelerating development of BGRL models in PyTorch/DGL.", "keywords": ["graph dataset loading", "DGL", "PyTorch", "BGRL", "graph augmentation", "edge dropout", "feature masking", "normalization", "cosine decay scheduler", "learning rate schedule"], "summary_hash": "a7f9ad88aa83", "cached_at": "2026-02-09T00:13:28+00:00"}