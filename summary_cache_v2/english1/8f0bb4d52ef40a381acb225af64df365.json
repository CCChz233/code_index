{"summary": "Implements a specialized Trainer that orchestrates iterative supervised fine‑tuning (SFT) of transformer models, handling dataset loading, custom data collators, optional PEFT integration, evaluation loops, and automatic model‑card generation.", "business_intent": "Enable developers to efficiently fine‑tune large language models in successive stages, improving performance while managing resources and tracking experiments.", "keywords": ["iterative fine-tuning", "supervised learning", "transformers", "Trainer", "PEFT", "dataset", "data collator", "model card", "evaluation", "wandb"], "summary_hash": "96f0e37c295a", "cached_at": "2026-02-09T05:59:16+00:00"}