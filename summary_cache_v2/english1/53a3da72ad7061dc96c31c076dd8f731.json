{"summary": "Collates and preprocesses batches for BART denoising language modeling in Flax, applying random token masking with Poisson‑distributed span lengths and optional sentence permutation, and formats inputs for the model’s decoder.", "business_intent": "Prepare training data for BART-style denoising tasks, enabling efficient masked and permuted input generation for Flax/JAX models.", "keywords": ["BART", "denoising", "language modeling", "data collator", "Flax", "token masking", "span masking", "sentence permutation", "tokenizer", "mask ratio", "Poisson distribution"], "summary_hash": "fb800147d466", "cached_at": "2026-02-09T06:13:51+00:00"}