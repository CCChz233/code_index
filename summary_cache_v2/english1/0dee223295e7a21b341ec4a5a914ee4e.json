{"summary": "Provides functionality to load, preprocess, and supply examples from the Recognizing Textual Entailment (RTE) dataset in the GLUE benchmark, including training, development, and test splits, label conversion, and generation of T5‑style prompted queries.", "business_intent": "Enables downstream NLP systems to efficiently access and use RTE data for training and evaluating textual entailment models, streamlining data preparation in machine‑learning pipelines.", "keywords": ["RTE", "GLUE", "data processor", "example generation", "label mapping", "T5 prompt", "textual entailment", "NLP dataset", "training examples", "validation examples"], "summary_hash": "5934110d44bc", "cached_at": "2026-02-08T09:55:07+00:00"}