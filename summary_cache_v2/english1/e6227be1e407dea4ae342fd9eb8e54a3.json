{"summary": "Encapsulates the tensors produced by a Longformer model, including the final hidden representations and optional intermediate hidden states, local attention weights, and global attention weights.", "business_intent": "Enable downstream NLP components to retrieve and manipulate Longformer representations and attention information for tasks such as classification, extraction, or model introspection.", "keywords": ["Longformer", "model output", "hidden states", "attention weights", "global attention", "tensor", "NLP", "transformer"], "summary_hash": "00b4ead4b689", "cached_at": "2026-02-09T11:12:58+00:00"}