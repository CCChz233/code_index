{"summary": "A metric class that evaluates the factual accuracy of language‑model responses by decomposing them into atomic claims, using natural‑language‑inference against reference texts, and aggregating the outcomes into precision, recall or F1 scores based on configurable mode and beta weighting.", "business_intent": "Provide an automated way for developers and evaluators to quantify and improve the factual correctness of AI‑generated content, supporting quality assurance, compliance checks, and model refinement.", "keywords": ["factual correctness", "claim decomposition", "natural language inference", "evaluation metric", "precision recall", "language model assessment", "reference verification"], "summary_hash": "9f55da18f0e2", "cached_at": "2026-02-08T22:44:57+00:00"}