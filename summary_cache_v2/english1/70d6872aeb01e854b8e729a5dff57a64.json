{"summary": "Provides an edge-wise sparsemax transformation for a DGL graph, normalizing edge logits per source or destination node to generate sparse, nonâ€‘negative attention coefficients.", "business_intent": "Enable graph neural network layers to apply differentiable sparse attention on edges, improving efficiency and interpretability of message passing.", "keywords": ["edge sparsemax", "graph neural network", "DGL", "logits", "sparse attention", "normalization", "source node", "destination node", "tensor"], "summary_hash": "1494c7b25e2a", "cached_at": "2026-02-08T23:11:29+00:00"}