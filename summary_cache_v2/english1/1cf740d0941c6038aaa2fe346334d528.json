{"summary": "This module orchestrates the selection and execution of the most suitable fused multi‑head attention implementation (e.g., Cutlass, FlashAttention, FlashAttention‑3) for both forward and backward passes. It evaluates input characteristics, hardware capabilities, and configurable priority lists to dispatch the optimal kernel, while providing utilities for compatibility checks, error reporting, and runtime flag management.", "business_intent": "Enable high‑performance attention operations by automatically choosing the best available kernel, improving speed and resource utilization in transformer models without requiring manual kernel selection.", "keywords": ["fused multi-head attention", "kernel dispatch", "forward pass", "backward pass", "Cutlass", "FlashAttention", "FlashAttention3", "priority list", "compatibility check", "performance optimization", "torch", "triton"], "summary_hash": "e54aee807fc5", "cached_at": "2026-02-08T23:32:58+00:00"}