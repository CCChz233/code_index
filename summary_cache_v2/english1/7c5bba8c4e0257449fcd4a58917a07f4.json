{"summary": "A data structure that encapsulates the outputs of a TensorFlow XLM model with a language‑modeling head, including the prediction logits and optionally the hidden states and attention tensors for each layer.", "business_intent": "Provide a standardized container for downstream applications to access model predictions, internal representations, and attention patterns, facilitating tasks such as text generation, analysis, and fine‑tuning.", "keywords": ["logits", "hidden_states", "attentions", "TensorFlow", "XLM", "language modeling", "model output", "sequence length", "vocab size", "self‑attention"], "summary_hash": "85e4eafbd7b8", "cached_at": "2026-02-09T10:40:34+00:00"}