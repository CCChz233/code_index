{"summary": "Defines an abstract and concrete decoder for multi‑task encoder‑decoder speech models, offering configurable auto‑regressive inference with greedy, beam, and other strategies, optional language‑ID extraction, token‑set output, and alignment tracking using a transformer decoder, log‑softmax projection, and tokenizer to produce hypothesis objects.", "business_intent": "Provide a flexible, production‑ready decoding component for speech recognition systems that handle multi‑task models, enabling accurate transcription, language identification, and alignment generation across various inference modes.", "keywords": ["ASR", "multi-task decoding", "auto-regressive inference", "beam search", "greedy decoding", "language identification", "tokenization", "alignment", "transformer decoder", "hypothesis generation", "PyTorch", "NeMo"], "summary_hash": "9b9c8cc9a355", "cached_at": "2026-02-08T11:14:59+00:00"}