{"summary": "The module implements an attention‑based heterogeneous graph neural network using DGL and PyTorch. It provides a hierarchical attention layer, a relational aggregation block, a semantic attention mechanism, and a top‑level model that combines these components to generate node embeddings from multi‑type graph data.", "business_intent": "Offer a ready‑to‑use reference implementation for building and training attention‑driven graph neural networks on heterogeneous networks, facilitating research and development of applications such as node classification, recommendation, or link prediction.", "keywords": ["graph neural network", "heterogeneous graph", "attention mechanism", "relational aggregation", "semantic attention", "PyTorch", "DGL", "node embedding"], "summary_hash": "b798d61b7f3b", "cached_at": "2026-02-09T00:12:07+00:00"}