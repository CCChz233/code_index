{"summary": "Implements a SentencePiece‑based tokenizer tailored for the NLLB multilingual translation models, handling source and target language markers, special tokens, and conversion between text and token IDs.", "business_intent": "Prepare and encode multilingual text for NLLB translation pipelines, ensuring correct token ordering and language code insertion for both source and target sequences.", "keywords": ["tokenizer", "multilingual", "translation", "sentencepiece", "special tokens", "language codes", "token‑id conversion", "NLLB", "preprocessing", "seq2seq"], "summary_hash": "beb2715cafe0", "cached_at": "2026-02-09T10:05:47+00:00"}