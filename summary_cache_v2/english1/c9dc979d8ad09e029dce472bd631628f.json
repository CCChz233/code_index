{"summary": "Defines the core abstractions for the RAGAS evaluation framework, including generic metric definitions, specialized single‑turn and multi‑turn metric implementations, and support structures for embedding‑based and LLM‑based scoring, as well as response ensembling and data column validation.", "business_intent": "Enable developers to consistently assess the quality of language model outputs across various conversational scenarios by providing a modular, extensible, and reproducible metric computation infrastructure.", "keywords": ["evaluation", "metric", "language model", "single-turn", "multi-turn", "embeddings", "LLM scoring", "ensembling", "validation", "asynchronous", "RAGAS"], "summary_hash": "b83e54c554d9", "cached_at": "2026-02-08T22:50:11+00:00"}