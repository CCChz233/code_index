{"summary": "LoFTR is a neural module that computes dense local feature correspondences between a pair of images using a transformer architecture, optionally leveraging pretrained weights for outdoor or indoor scenes. It processes input tensors, optionally computes a distance matrix, and outputs matched keypoint coordinates together with confidence scores.", "business_intent": "Enable high‑accuracy, detector‑free image matching for applications such as visual localization, SLAM, augmented reality, and 3D reconstruction by providing ready‑to‑use pretrained models and a simple inference interface.", "keywords": ["image correspondence", "feature matching", "transformer", "LoFTR", "pretrained weights", "outdoor", "indoor", "confidence scores", "torch.cdist", "computer vision"], "summary_hash": "d69655fcb3ff", "cached_at": "2026-02-09T12:00:34+00:00"}