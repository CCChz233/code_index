{"summary": "A configuration container that defines all hyperparameters and sub‑component settings required to build a CLIPSeg multimodal segmentation model, including text and vision encoder configurations, projection dimensions, scaling factors, layer extraction points, decoder architecture details, and optional advanced convolution options.", "business_intent": "Allow developers and researchers to easily customize and instantiate CLIPSeg models for image segmentation tasks by providing a single, serializable object that captures model architecture choices and default values aligned with the reference CIDAS/clipseg‑rd64 implementation.", "keywords": ["CLIPSeg", "configuration", "text encoder", "vision encoder", "projection dimension", "logit scale", "layer extraction", "decoder", "attention heads", "dropout", "activation function", "FiLM", "transposed convolution", "hyperparameters"], "summary_hash": "d7869a2627d3", "cached_at": "2026-02-09T08:34:45+00:00"}