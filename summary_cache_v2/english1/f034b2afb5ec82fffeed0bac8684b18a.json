{"summary": "Implements a command‑line benchmark that measures the memory usage of inference operations on both CPU and GPU, utilizing memory_profiler and NVML, and reports execution time.", "business_intent": "Allows developers and engineers to evaluate the memory footprint of machine‑learning inference workloads, supporting resource planning and optimization of model deployment.", "keywords": ["memory profiling", "GPU memory", "CPU memory", "benchmark", "inference", "performance measurement", "command line", "py3nvml", "memory_usage", "utils"], "summary_hash": "6ce3eb98c5b4", "cached_at": "2026-02-08T12:18:45+00:00"}