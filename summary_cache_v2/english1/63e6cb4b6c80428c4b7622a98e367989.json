{"summary": "Implements a Lightning callback that manages staged fine‑tuning of a model’s backbone: it freezes the backbone initially, unfreezes it at a configured epoch, applies a user‑defined learning‑rate schedule (with optional alignment to the main optimizer), controls batch‑norm training, and provides verbose logging.", "business_intent": "Enable developers to easily integrate configurable backbone fine‑tuning into Lightning training pipelines, improving transfer‑learning performance while reducing manual boilerplate.", "keywords": ["fine‑tuning", "backbone", "learning‑rate schedule", "unfreeze", "batch‑norm", "PyTorch Lightning", "callback"], "summary_hash": "16653957d8f0", "cached_at": "2026-02-08T08:55:06+00:00"}