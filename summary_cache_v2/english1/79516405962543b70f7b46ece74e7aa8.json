{"summary": "The module implements a set of tools for measuring and reporting execution latency and throughput in machine‑learning workloads. It defines data structures for storing latency values, a generic tracker that can start/stop timers on CPU or CUDA, a processor that captures per‑token timings during model inference (separating pre‑fill and decode phases), a trainer callback that logs the duration of each training step, and a helper for computing aggregated throughput statistics.", "business_intent": "Enable developers and researchers to benchmark and optimise the performance of transformer models by providing fine‑grained latency and throughput metrics for inference and training, supporting both CPU and GPU environments and integrating with the HuggingFace Trainer workflow.", "keywords": ["latency measurement", "throughput calculation", "benchmarking", "machine learning performance", "PyTorch", "CUDA", "HuggingFace Trainer", "per‑token timing", "inference profiling", "training step profiling", "logging"], "summary_hash": "70ac88abadd8", "cached_at": "2026-02-09T02:29:19+00:00"}