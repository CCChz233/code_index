{"summary": "Implements a MobileBERT-based model for masked language modeling, offering forward computation and utilities to retrieve, modify, and resize the output token embeddings.", "business_intent": "Provide a lightweight, mobile‑optimized language model capable of predicting masked tokens and adapting its vocabulary for on‑device natural language processing applications.", "keywords": ["mobilebert", "masked language modeling", "nlp", "embeddings", "token resizing", "on-device inference", "transformer", "language model"], "summary_hash": "8d5773efb6b8", "cached_at": "2026-02-09T11:37:44+00:00"}