{"summary": "A utility that assembles multiple ONNX models or operators into a single sequential pipeline, handling loading from files, URLs or Hugging Face, managing input-output mappings, automatic IR and opset version conversion, caching, and creation of an ONNX Runtime session for inference and export.", "business_intent": "To simplify the construction and deployment of complex inference workflows by allowing developers to chain preâ€‘trained ONNX components, ensure compatibility across versions, and run them efficiently on chosen execution providers.", "keywords": ["ONNX", "model composition", "sequential pipeline", "inference", "execution providers", "version conversion", "caching", "Hugging Face", "model export", "runtime session"], "summary_hash": "ef853d02072a", "cached_at": "2026-02-09T11:43:54+00:00"}