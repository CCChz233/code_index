{"summary": "The module implements dataset classes and helper utilities for loading video‑to‑text data in multimodal speech and computer‑vision pipelines. It supports streaming video files from tar archives using JSON manifests, manifest parsing and filtering, duration‑based selection, optional silence trimming, channel handling, and various text tokenization schemes (BPE, WordPiece, character) with BOS/EOS tokens and padding. Designed for PyTorch and NeMo, it enables efficient data loading for training and inference of multimodal speech‑recognition models.", "business_intent": "Provide a robust, scalable data ingestion layer that simplifies preparation of video‑text paired datasets for developing and deploying multimodal speech‑vision AI products, accelerating model training, evaluation, and inference workflows.", "keywords": ["video-to-text", "dataset", "tar archive", "manifest", "PyTorch", "NeMo", "tokenization", "BPE", "WordPiece", "character-level", "speech recognition", "computer vision", "multimodal", "data loading", "preprocessing", "duration filtering", "silence trimming", "channel selection", "padding", "BOS/EOS"], "summary_hash": "98fe1db9e998", "cached_at": "2026-02-08T12:02:41+00:00"}