{"summary": "The module implements sampler classes used by Megatron‑based language‑model pretraining pipelines. It defines a base iterator that reports dataset size, a random index sampler for shuffling dataset positions, and a sampler that yields contiguous start‑end token ranges for feeding Megatron models.", "business_intent": "Provide scalable and flexible data sampling mechanisms to support efficient loading of token sequences during large‑scale Megatron language model training.", "keywords": ["Megatron", "sampler", "pretraining", "data loading", "token ranges", "random shuffle", "iterator", "NLP", "language modeling", "PyTorch"], "summary_hash": "4c8a0064e3d5", "cached_at": "2026-02-08T11:30:08+00:00"}