{"summary": "This module defines the core components for distributed graph data loading in DGL. It provides an abstract collator interface and concrete implementations that sample neighborhoods of target edges or nodes on a distributed graph, build the corresponding message‑flow subgraphs (blocks), and assemble minibatch inputs for graph neural network training across multiple machines. The collators handle both homogeneous and heterogeneous graphs, support negative edge generation, and manage exclusion of original or reverse edges to prevent information leakage.", "business_intent": "Enable scalable, multi‑machine training of graph neural networks by offering efficient, distributed minibatch sampling and subgraph construction for edge‑wise and node‑wise learning tasks, thereby reducing memory overhead and accelerating convergence on large‑scale graph datasets.", "keywords": ["distributed data loading", "graph neural networks", "minibatch sampling", "neighborhood sampling", "subgraph construction", "message passing blocks", "edge classification", "node classification", "negative sampling", "heterogeneous graphs", "multi‑machine training"], "summary_hash": "928658b74f5d", "cached_at": "2026-02-09T00:36:17+00:00"}