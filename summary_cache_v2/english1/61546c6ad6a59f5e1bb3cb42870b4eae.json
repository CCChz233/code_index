{"summary": "A learnable module that transforms the shortest‑path information between node pairs into attention bias vectors for graph neural networks. It truncates paths longer than a configurable length, embeds edge features of a given dimension, and optionally distributes the encoding across multiple attention heads.", "business_intent": "Enhance graph transformer models by providing path‑aware attention biases, enabling more expressive representation of graph topology and improving downstream tasks such as node classification or link prediction.", "keywords": ["path encoding", "graph neural network", "attention bias", "shortest path", "learnable embedding", "multi‑head attention", "edge features", "transformer"], "summary_hash": "6c0b7bf0e179", "cached_at": "2026-02-08T23:51:51+00:00"}