{"summary": "Container class that holds the outputs of an ELECTRA pre‑training model, including an optional scalar loss, token‑level prediction scores, and optionally the hidden states and attention matrices for each layer.", "business_intent": "Facilitate downstream processing of ELECTRA pre‑training results by providing a unified structure for loss calculation, token discrimination, and inspection of internal representations such as hidden layers and attention patterns.", "keywords": ["ELECTRA", "pretraining", "loss", "logits", "hidden_states", "attentions", "model output", "transformer", "PyTorch"], "summary_hash": "345e24357895", "cached_at": "2026-02-09T08:20:03+00:00"}