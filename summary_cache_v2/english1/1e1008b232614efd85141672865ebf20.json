{"summary": "Provides core utilities for constructing Dask DataFrames from diverse data sources (arrays, pandas objects, delayed tasks, dictionaries, mappings) and for exporting Dask DataFrames to other Dask collections or storage backends, handling chunking, metadata inference, column projection, and lazy evaluation.", "business_intent": "Enable scalable, parallel ingestion and export of data within Dask workflows, supporting heterogeneous input types and efficient conversion to and from Dask DataFrames.", "keywords": ["dask", "dataframe", "io utilities", "data ingestion", "data export", "parallel processing", "metadata handling", "chunking", "lazy evaluation", "conversion"], "summary_hash": "7a38f84f3dda", "cached_at": "2026-02-08T23:27:40+00:00"}