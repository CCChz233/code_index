{"summary": "The script showcases a distributed multi‑GPU workflow for node classification using a GraphSAGE model. It loads an OGB node property prediction dataset, constructs neighbor samplers and data loaders, wraps the model with PyTorch DistributedDataParallel, and provides utilities for training, evaluation, and layer‑wise inference across multiple GPUs.", "business_intent": "Provide a reference implementation that enables developers to scale graph neural network training and inference for node classification tasks across multiple GPUs, facilitating high‑performance, production‑ready pipelines for large graph datasets.", "keywords": ["graph neural network", "node classification", "multi‑GPU", "distributed training", "DGL", "PyTorch", "GraphSAGE", "OGB", "neighbor sampling", "DistributedDataParallel", "evaluation", "inference"], "summary_hash": "749526e39c9d", "cached_at": "2026-02-09T00:24:30+00:00"}