{"summary": "Encapsulates the full set of tensors produced by a DETR encoder‑decoder model, including the final decoder hidden states, optional per‑layer hidden states and attention maps for both encoder and decoder, and an optional stack of normalized intermediate decoder activations for auxiliary loss computation.", "business_intent": "Enable downstream components and training pipelines to access detailed encoder and decoder representations, attention patterns, and intermediate layer outputs of DETR models, supporting tasks such as object detection inference, model introspection, and multi‑loss training strategies.", "keywords": ["DETR", "encoder-decoder", "model output", "hidden states", "attention weights", "intermediate activations", "auxiliary loss", "layernorm", "tensor"], "summary_hash": "040e51aa883f", "cached_at": "2026-02-09T09:23:29+00:00"}