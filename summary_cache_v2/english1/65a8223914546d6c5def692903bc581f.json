{"summary": "Encapsulates a BridgeTower multimodal transformer architecture specialized for masked language modeling, handling token masking, forward computation, and generation of prediction logits for masked tokens.", "business_intent": "Provide a ready-to-use model component for pretraining or fineâ€‘tuning masked language models within multimodal systems, enabling improved language understanding and downstream NLP applications.", "keywords": ["masked language modeling", "multimodal transformer", "BridgeTower", "pretraining", "token prediction", "deep learning"], "summary_hash": "de27c825fbc1", "cached_at": "2026-02-09T06:53:50+00:00"}