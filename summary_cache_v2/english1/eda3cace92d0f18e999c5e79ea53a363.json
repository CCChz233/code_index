{"summary": "A training script that builds and fine‑tunes a bi‑encoder model on the MS MARCO passage ranking dataset. Queries and passages are encoded independently with a transformer to obtain fixed‑size vectors, which are compared via cosine similarity. The model is optimized using MultipleNegativesRankingLoss on triplets (query, positive passage, hard negative passage) that include cross‑encoder scores for denoising.", "business_intent": "Enable the creation of a high‑performance dense retrieval model for information‑retrieval applications, improving the relevance of passage search results in search engines or question‑answering systems.", "keywords": ["bi-encoder", "MS MARCO", "passage ranking", "dense retrieval", "sentence-transformers", "MultipleNegativesRankingLoss", "hard negatives", "cross-encoder", "cosine similarity", "embedding training"], "summary_hash": "3271d0b69479", "cached_at": "2026-02-08T13:58:27+00:00"}