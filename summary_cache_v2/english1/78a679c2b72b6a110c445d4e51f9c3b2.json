{"summary": "The module implements a configurable dataset that converts dialogue utterances and intent descriptions into premise‑hypothesis pairs suitable for training a natural language inference model. It tokenizes the text, creates input features containing token ids, attention masks, segment ids, and labels, and defines the required neural type specifications for integration with NeMo training pipelines.", "business_intent": "Provide a ready‑to‑use data pipeline that enables zero‑shot intent classification for conversational AI systems, allowing rapid addition of new intents without collecting labeled intent data.", "keywords": ["zero-shot intent classification", "dialogue dataset", "premise hypothesis", "natural language inference", "tokenization", "NeMo", "neural types", "NLU preprocessing", "conversational AI"], "summary_hash": "895e6c82521e", "cached_at": "2026-02-08T11:32:57+00:00"}