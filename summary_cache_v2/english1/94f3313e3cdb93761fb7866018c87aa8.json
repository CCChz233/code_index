{"summary": "Preprocesses the Spoken Wikipedia corpus by walking through its structure, extracting each article's OGG audio and matching transcript, optionally normalizing the text (e.g., stripping diacritics), and copying the pairs into flat destination folders with sequential numeric filenames, preparing the data for downstream CTC‑segmentation and speech‑recognition pipelines.", "business_intent": "Create a clean, uniformly named audio‑text dataset from Spoken Wikipedia to support training and evaluation of automatic speech recognition models, especially those using CTC‑based segmentation.", "keywords": ["Spoken Wikipedia", "audio extraction", "transcript processing", "diacritic removal", "dataset preparation", "CTC segmentation", "speech recognition", "flat directory", "file renaming", "preprocessing"], "summary_hash": "6ff151fd301f", "cached_at": "2026-02-08T12:15:06+00:00"}