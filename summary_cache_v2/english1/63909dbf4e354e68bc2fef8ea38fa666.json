{"summary": "Encapsulates metadata about a neural network layer for DeepSpeed, offering utilities to compute average parameters per shard, total parameter count, and the size of partitioned parameters.", "business_intent": "Support efficient distributed training by providing layer-level statistics for resource planning, performance monitoring, and debugging of model parallelism.", "keywords": ["DeepSpeed", "layer summary", "parameter count", "sharding", "partitioned size", "distributed training", "model parallelism", "resource allocation"], "summary_hash": "b212d1dd7841", "cached_at": "2026-02-08T08:22:57+00:00"}