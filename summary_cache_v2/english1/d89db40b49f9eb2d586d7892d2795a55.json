{"summary": "Integrates PyTorch's distributed runtime into Metaflow, offering a decorator that sets up the necessary environment and launches functions across multiple processes or GPUs for parallel execution.", "business_intent": "Allow Metaflow users to seamlessly run distributed PyTorch workloads, scaling training or inference across multiple GPUs or nodes without manual setup.", "keywords": ["Metaflow", "PyTorch", "distributed training", "parallel execution", "GPU scaling", "decorator", "multi-process", "runtime integration"], "summary_hash": "902c22be14e1", "cached_at": "2026-02-08T09:23:26+00:00"}