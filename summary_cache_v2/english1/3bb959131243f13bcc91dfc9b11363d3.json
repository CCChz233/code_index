{"summary": "A dataset wrapper that transforms each minibatch into tensors or dictionaries of tensors, optimising for GPU execution and reducing data‑loading overhead. It stores the batch index tensor in shared memory to prevent duplicate copies during shuffling, enabling efficient, low‑latency batch retrieval.", "business_intent": "Speed up deep‑learning training pipelines by delivering fast, memory‑efficient minibatch generation on GPU, minimizing overhead and improving throughput.", "keywords": ["dataset wrapper", "tensor minibatch", "GPU acceleration", "shared memory index", "efficient shuffling", "data loading performance", "deep learning", "PyTorch"], "summary_hash": "17b4c33b48e2", "cached_at": "2026-02-08T23:37:23+00:00"}