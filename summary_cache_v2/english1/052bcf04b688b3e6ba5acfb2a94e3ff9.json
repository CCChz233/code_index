{"summary": "Encapsulates a local attention mask used in attention mechanisms, providing controlled access to the mask data.", "business_intent": "Enable efficient computation of localized attention windows in neural network models.", "keywords": ["local attention", "mask", "neural network", "transformer", "getter", "encapsulation"], "summary_hash": "69dd8c0f0f9f", "cached_at": "2026-02-09T11:59:51+00:00"}