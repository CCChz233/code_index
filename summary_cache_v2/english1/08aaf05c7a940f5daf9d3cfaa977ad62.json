{"summary": "Implements a multimodal RNNT model that encodes video inputs and decodes them into BPE-tokenized text, integrating loss computation, decoding strategies, and evaluation metrics, and exposing pretrained model utilities.", "business_intent": "Enable developers to train and deploy video‑to‑text transcription systems (e.g., lip‑reading or audiovisual speech recognition) with subword tokenization, reducing the effort required to build high‑accuracy multimodal speech recognition solutions.", "keywords": ["visual RNNT", "BPE tokenization", "multimodal speech recognition", "lipreading", "encoder‑decoder", "RNNT loss", "decoding", "pretrained model", "NeMo"], "summary_hash": "d6de49db993a", "cached_at": "2026-02-08T10:59:54+00:00"}