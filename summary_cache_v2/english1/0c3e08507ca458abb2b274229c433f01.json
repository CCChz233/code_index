{"summary": "The module offers data access utilities for Metaflow, defining a unified interface for reading and writing objects to both local file systems and Amazon S3, and includes a helper for streaming large files in chunks. The local implementation resolves paths, enforces a configurable directory and file suffix, and manages error handling during I/O operations.", "business_intent": "Provide Metaflow users with a reliable, interchangeable storage layer that simplifies persisting workflow data locally or in the cloud, while supporting efficient processing of large datasets.", "keywords": ["Metaflow", "data storage", "local filesystem", "Amazon S3", "chunked reading", "file I/O", "workflow persistence", "storage abstraction"], "summary_hash": "38c78e9ae772", "cached_at": "2026-02-08T09:23:14+00:00"}