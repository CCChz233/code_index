{"summary": "Defines a PyTorch dataset class that converts raw text samples into token IDs and attention masks using a tokenizer, optionally attaches pre‑computed BERT embeddings, and supplies utilities for indexing and batch collation, enabling efficient loading of data for information‑retrieval model training within the NeMo framework.", "business_intent": "To streamline the preparation and feeding of large‑scale text corpora into retrieval models that leverage BERT representations, reducing preprocessing overhead and supporting scalable training pipelines.", "keywords": ["PyTorch", "Dataset", "tokenization", "BERT embeddings", "information retrieval", "batch collation", "NeMo", "NLP", "preprocessing", "large‑scale training"], "summary_hash": "0dd97d9b6da8", "cached_at": "2026-02-08T11:28:43+00:00"}