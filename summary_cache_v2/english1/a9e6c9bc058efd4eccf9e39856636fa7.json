{"summary": "Provides a BERT‑based sequence tagging model that converts spoken‑domain token streams into their written‑domain equivalents by assigning tags (e.g., KEEP, DELETE, class‑specific replacements) following the LaserTagger methodology for inverse text normalization.", "business_intent": "Automates spoken‑to‑written text conversion for speech‑recognition pipelines, voice assistants, and downstream NLP applications, reducing manual rule‑based normalization effort and improving accuracy of downstream processing.", "keywords": ["BERT", "sequence tagging", "text normalization", "inverse text normalization", "LaserTagger", "spoken-to-written conversion", "NLP", "token classification", "neural model"], "summary_hash": "096cf50ab86d", "cached_at": "2026-02-08T12:11:25+00:00"}