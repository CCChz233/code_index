{"summary": "Encapsulates every configurable parameter that influences a model's generate call, from length limits and decoding strategy selection (greedy, beam, sampling, contrastive, assisted, etc.) to logits manipulation, penalty terms, output formats, special token handling, and caching options, providing a single source of truth for generation behavior.", "business_intent": "Offer a unified, serializable configuration object that lets developers fineâ€‘tune and reproduce generation processes across text, speech, and vision models without manually managing numerous individual arguments.", "keywords": ["generation", "configuration", "decoding strategies", "beam search", "sampling", "contrastive search", "assistant model", "length control", "penalties", "logits manipulation", "output options", "special tokens", "caching"], "summary_hash": "ed3ea99541d3", "cached_at": "2026-02-09T08:00:13+00:00"}