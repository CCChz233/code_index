{"summary": "The module supplies tools for preparing and loading parallel text data for neural machine translation in NeMo. It includes utilities to tokenize raw bilingual corpora, build vocabularies, construct and package datasets, and a dataset class that reads tokenized, sharded, tarred pickle files with flexible path handling, sharding, shuffling, and language direction swapping, exposing an iterable collection sized by total tokens.", "business_intent": "Facilitate efficient training and evaluation of machine‑translation models by automating data preprocessing and providing scalable, distributed‑ready data loading mechanisms.", "keywords": ["machine translation", "dataset", "tokenization", "SentencePiece", "parallel corpora", "vocabulary", "sharding", "distributed training", "NeMo", "preprocessing"], "summary_hash": "ef5f994347e0", "cached_at": "2026-02-08T12:09:03+00:00"}