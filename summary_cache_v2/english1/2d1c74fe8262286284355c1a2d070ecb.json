{"summary": "A collection of unit tests that verify the functionality of the FSDP precision plugin, covering backward passes, configuration defaults, gradient scaler behavior, optimizer stepping with and without a scaler, BF16 support, and handling of invalid precision settings.", "business_intent": "To guarantee correct mixedâ€‘precision and scaling operations when using Fully Sharded Data Parallel training in Lightning Fabric, preventing misconfigurations and ensuring stable distributed training performance.", "keywords": ["FSDP", "precision plugin", "mixed precision", "gradient scaling", "optimizer step", "BF16", "unit testing", "PyTorch", "Lightning Fabric", "distributed training"], "summary_hash": "8fa7ca959f36", "cached_at": "2026-02-08T08:47:58+00:00"}