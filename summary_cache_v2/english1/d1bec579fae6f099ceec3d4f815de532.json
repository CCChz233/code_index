{"summary": "The module implements a graph‑edge version of the sparsemax activation, normalizing edge scores per node to produce sparse, non‑negative attention coefficients within DGL graphs. It defines a custom autograd operation and helper utilities for sorting neighbors and computing thresholds needed for the sparsemax projection.", "business_intent": "Provide a sparse attention mechanism for graph neural network models, enabling efficient and interpretable edge weighting in tasks such as graph classification, node ranking, or message passing.", "keywords": ["DGL", "sparsemax", "graph neural network", "edge attention", "autograd", "PyTorch", "thresholding", "normalization"], "summary_hash": "7e4bb721ece4", "cached_at": "2026-02-09T00:16:49+00:00"}