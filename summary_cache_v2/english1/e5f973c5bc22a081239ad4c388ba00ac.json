{"summary": "Implements a custom SentencePiece Unigram tokenizer with NMT and NKFC character normalization, space handling, and lower‑casing, offering training utilities and unknown‑token ID management.", "business_intent": "Provide robust text preprocessing for NLP applications by converting raw sentences into token IDs using a trained unigram model with advanced normalization.", "keywords": ["SentencePiece", "Unigram", "tokenizer", "normalization", "NMT", "NKFC", "lowercasing", "training", "unknown token", "iterator"], "summary_hash": "7136234ee97a", "cached_at": "2026-02-09T06:13:32+00:00"}