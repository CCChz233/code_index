{"summary": "A utility that orchestrates knowledge distillation for neural machine translation models built on the Bart family (including T5, mBART, Marian), handling configuration setup and computing generation‑based evaluation scores.", "business_intent": "To streamline the creation of compact, high‑quality translation models for deployment in commercial language services, reducing inference cost while maintaining accuracy.", "keywords": ["translation", "knowledge distillation", "Bart", "T5", "mBART", "Marian", "generative metrics", "model configuration", "NLP", "machine translation"], "summary_hash": "0516bf1eec7e", "cached_at": "2026-02-09T06:05:02+00:00"}