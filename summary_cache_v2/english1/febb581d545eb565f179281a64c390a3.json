{"summary": "A collection of data loading and subgraph sampling utilities for the Deep Graph Library (DGL) that enable efficient mini‑batch training of graph neural networks. It includes neighbor, cluster, GraphSAINT, labor, and shadow samplers, negative edge generators, and distributed collators, all with support for lazy feature loading, prefetching, device placement, and seamless PyTorch integration.", "business_intent": "Provide developers and researchers with high‑performance, flexible pipelines to train GNN models on large‑scale homogeneous or heterogeneous graphs, both on a single machine and across multiple machines, reducing memory overhead and accelerating training throughput.", "keywords": ["graph neural networks", "sampling", "mini-batch", "DGL", "PyTorch", "neighbor sampling", "cluster sampling", "GraphSAINT", "negative sampling", "distributed training", "lazy feature loading", "prefetching", "subgraph construction"], "summary_hash": "ad7258f0c908", "cached_at": "2026-02-09T00:58:32+00:00"}