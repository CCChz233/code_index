{"summary": "Manages model loading and execution using the Intel Extension for PyTorch backend, handling both pretrained and weight‑less models, preparing inputs, and providing inference operations such as forward passes, generation, and prefill, with support for data‑parallel distribution.", "business_intent": "Enable high‑performance, Intel‑optimized inference for large language models, reducing latency and resource usage in production AI services.", "keywords": ["IPEX", "backend", "model loading", "inference", "generation", "input preparation", "distributed", "weightless loading", "prefill", "forward"], "summary_hash": "a8c773964aa9", "cached_at": "2026-02-09T02:26:39+00:00"}