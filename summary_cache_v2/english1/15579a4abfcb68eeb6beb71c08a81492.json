{"summary": "Defines a diffusion pipeline that creates images guided simultaneously by textual and visual prompts. The pipeline encodes both modalities into latent space, merges them with dual attention mechanisms, denoises the combined latents using a conditional UNet and scheduler, and finally decodes the result into a PIL image.", "business_intent": "Enable developers and artists to generate highâ€‘quality, customized images by providing both a description and a reference image, supporting creative workflows such as concept art, product visualization, and multimodal content creation.", "keywords": ["diffusion pipeline", "dual guidance", "text-to-image", "image-to-image", "latent diffusion", "UNet", "scheduler", "CLIP", "transformer", "Versatile Diffusion", "conditional generation", "multimodal"], "summary_hash": "f6e46d9d8968", "cached_at": "2026-02-09T05:27:59+00:00"}