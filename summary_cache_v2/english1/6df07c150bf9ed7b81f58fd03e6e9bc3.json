{"summary": "Provides a differentiable vector quantization layer that maps continuous embeddings to discrete codebook entries using Gumbel sampling, handling forward propagation, index extraction, and update bookkeeping.", "business_intent": "Allows neural models to learn compact, discrete latent representations for compression, tokenization, or downstream processing in domains like speech, audio, and language modeling.", "keywords": ["vector quantization", "Gumbel-Softmax", "codebook", "discrete embeddings", "neural compression", "latent representation", "sampling", "update tracking"], "summary_hash": "c63dc59a553a", "cached_at": "2026-02-08T09:27:48+00:00"}