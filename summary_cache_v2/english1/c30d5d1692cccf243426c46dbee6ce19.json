{"summary": "Defines a configurable UNet backbone for diffusion models that integrates spatially‑adaptive (SPADE) normalization to condition generation on semantic label maps. The module provides residual blocks with timestep embeddings, up/down‑sampling layers, self‑attention, cross‑attention, and optional transformer conditioning, supporting multiple spatial dimensions and efficient attention implementations.", "business_intent": "Enable developers to build high‑performance, semantically‑conditioned diffusion models for medical image synthesis and related tasks, offering flexibility in architecture depth, attention mechanisms, and conditioning strategies while leveraging MONAI's deep learning utilities.", "keywords": ["diffusion model", "UNet", "SPADE", "spatially-adaptive normalization", "semantic conditioning", "attention", "cross-attention", "transformer", "residual block", "timestep embedding", "upsampling", "downsampling", "PyTorch", "MONAI"], "summary_hash": "cf9c54c8e8c2", "cached_at": "2026-02-08T13:16:51+00:00"}