{"summary": "Provides a SentencePiece‑based tokenizer tailored for the MBART multilingual seq2seq model, managing language‑specific special tokens, token‑ID conversion, and input construction for both source and target texts.", "business_intent": "Enable seamless preprocessing of multilingual data for MBART models, supporting translation and other sequence‑to‑sequence applications by handling tokenization, language codes, and special token placement.", "keywords": ["MBART", "tokenizer", "multilingual", "SentencePiece", "language codes", "special tokens", "translation", "seq2seq", "vocabulary", "token conversion"], "summary_hash": "c43a191dd560", "cached_at": "2026-02-09T11:04:20+00:00"}