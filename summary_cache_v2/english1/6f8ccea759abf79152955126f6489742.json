{"summary": "Implements a block‑diagonal causal mask that restricts each query to attend only to keys within the same block and within a configurable local window, producing a banded attention pattern.", "business_intent": "Enable efficient, causally correct attention for long‑sequence transformer models by limiting the attention scope to a local neighborhood, reducing computational cost and memory usage while preserving temporal ordering.", "keywords": ["attention mask", "block diagonal", "causal", "local window", "banded attention", "transformer", "efficient computation", "sequence modeling"], "summary_hash": "b335f255b0bf", "cached_at": "2026-02-08T23:23:44+00:00"}