{"summary": "Implements a single decoder layer of a table‑focused transformer, performing self‑attention, encoder‑decoder cross‑attention, and a position‑wise feed‑forward network with residual connections, layer normalization and dropout.", "business_intent": "Serves as the core component for models that generate or transform tabular data, enabling the system to capture inter‑cell, row and column relationships during the decoding phase.", "keywords": ["transformer", "decoder layer", "self‑attention", "cross‑attention", "feed‑forward network", "layer normalization", "dropout", "tabular data", "table generation", "neural network"], "summary_hash": "f82a37429287", "cached_at": "2026-02-09T10:11:35+00:00"}