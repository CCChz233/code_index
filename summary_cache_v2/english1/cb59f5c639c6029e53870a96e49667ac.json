{"summary": "A transformer-based model that encodes multiple-choice question options and produces scores for each choice, enabling selection of the most likely answer.", "business_intent": "Facilitate automated answering or ranking of multiple-choice questions in educational, assessment, or survey applications.", "keywords": ["RoBERTa", "multiple-choice", "transformer", "language model", "classification", "NLP", "question answering", "fine-tuning"], "summary_hash": "5356bf659af6", "cached_at": "2026-02-09T11:09:07+00:00"}