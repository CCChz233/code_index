{"summary": "The module integrates PyTorchâ€™s distributed runtime with Metaflow, providing a decorator that configures the environment and launches functions across multiple processes or GPUs for parallel execution.", "business_intent": "Enable data scientists and engineers to easily scale PyTorch training and inference workloads within Metaflow pipelines, simplifying the setup and management of distributed GPU jobs.", "keywords": ["PyTorch", "distributed training", "parallel execution", "Metaflow", "decorator", "GPU scaling", "multi-process", "runtime configuration", "machine learning pipelines"], "summary_hash": "c3d7b1f33641", "cached_at": "2026-02-08T09:11:15+00:00"}