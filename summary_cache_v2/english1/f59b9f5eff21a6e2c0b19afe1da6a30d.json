{"summary": "A tokenizer that leverages a SentencePiece model to convert raw text into token IDs compatible with the BARTpho architecture. It loads both a multilingual and a Vietnamese‑specific vocabulary, manages special tokens (CLS, SEP, PAD, MASK, etc.), and provides utilities for tokenization, ID‑to‑token conversion, building model inputs, and saving the vocabulary.", "business_intent": "Facilitate preprocessing of Vietnamese (and multilingual) text for BART-based models, enabling downstream applications such as translation, summarization, and classification by delivering consistent tokenization and special‑token handling aligned with the model's pretraining.", "keywords": ["SentencePiece", "tokenization", "Vietnamese", "BARTpho", "special tokens", "vocabulary management", "preprocessing", "token-id mapping", "masking", "padding"], "summary_hash": "828d494431ad", "cached_at": "2026-02-09T08:46:46+00:00"}