{"summary": "The class creates synthetic multi‑speaker audio sessions by mixing single‑speaker recordings according to configurable speaker counts, dominance, turn probabilities, silence and overlap ratios, and optional room impulse responses. It supports per‑segment and whole‑session augmentations such as gain perturbation, white‑noise, and background noise, normalizes speaker volumes, and outputs wav and RTTM files. Parallel processing and chunking are used for efficient large‑scale generation.", "business_intent": "Generate realistic multi‑speaker audio corpora for training and evaluating speech technologies such as diarization, speaker recognition, and automatic speech recognition, reducing the need for costly manual recording.", "keywords": ["multi‑speaker audio simulation", "synthetic speech dataset", "speaker overlap", "silence modeling", "audio augmentation", "background noise injection", "speaker volume normalization", "RTTM labeling", "parallel audio generation", "speech processing training data"], "summary_hash": "182784750e93", "cached_at": "2026-02-08T09:13:54+00:00"}