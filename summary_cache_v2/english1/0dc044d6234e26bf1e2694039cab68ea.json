{"summary": "Implements a Gumbel-Softmax based vector quantizer that maps continuous speech embeddings to discrete codebook entries, providing a forward transformation and internal metrics such as perplexity.", "business_intent": "Facilitates compact, discrete representation learning for speech models, enabling efficient storage, transmission, and downstream tasks like speech recognition or synthesis.", "keywords": ["vector quantization", "Gumbel-Softmax", "speech embeddings", "discrete representation", "codebook", "neural network quantizer", "perplexity metric"], "summary_hash": "f30ce454a54b", "cached_at": "2026-02-09T12:05:04+00:00"}