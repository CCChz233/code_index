{"summary": "Encapsulates configuration parameters for performing greedy inference with a Recurrent Neural Network Transducer (RNNT) model.", "business_intent": "Provide a simple, ready‑to‑use configuration that downstream speech‑recognition pipelines can use to run fast, low‑latency RNNT decoding without handling low‑level decoding details.", "keywords": ["greedy decoding", "RNNT", "inference configuration", "speech recognition", "transducer", "decoding parameters", "low latency"], "summary_hash": "ea3c2e31d6f4", "cached_at": "2026-02-08T09:31:24+00:00"}