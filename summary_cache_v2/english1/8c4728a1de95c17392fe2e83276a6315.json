{"summary": "Implements a differentiable vector quantization layer for speech models using the Gumbelâ€‘Softmax reparameterization, allowing continuous training while mapping latent vectors to a discrete codebook.", "business_intent": "Enable efficient compression and discrete representation learning in audio processing pipelines, improving model performance on tasks such as speech recognition, speaker identification, and downstream language modeling.", "keywords": ["vector quantization", "Gumbel-Softmax", "Flax", "Wav2Vec2", "differentiable quantization", "discrete latent representation", "speech processing", "codebook", "perplexity"], "summary_hash": "6103fedfcca6", "cached_at": "2026-02-09T10:22:55+00:00"}