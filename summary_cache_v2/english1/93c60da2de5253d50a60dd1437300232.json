{"summary": "Encapsulates the configuration for a model quality monitoring job, defining data sources, constraints, schedule, and output settings used to evaluate a machine learning model's performance and data integrity.", "business_intent": "Provide a reusable definition that automates the assessment of model quality, helping organizations maintain reliable, compliant ML models by detecting data drift, violations of quality constraints, and performance degradation.", "keywords": ["model quality", "monitoring", "job definition", "SageMaker", "configuration", "constraints", "schedule", "data drift", "validation"], "summary_hash": "ad0f876ba0a9", "cached_at": "2026-02-09T07:49:28+00:00"}