{"summary": "A layer that encapsulates an activation function and applies it element‑wise to its input tensor when called, producing the transformed output.", "business_intent": "Enable model designers to insert non‑linear activation steps into neural network graphs in a modular, configurable way, supporting both named Keras activations and custom callables.", "keywords": ["activation", "layer", "keras", "non-linear", "callable", "neural network", "forward pass", "output transformation"], "summary_hash": "b4589b79a6b6", "cached_at": "2026-02-09T12:03:27+00:00"}