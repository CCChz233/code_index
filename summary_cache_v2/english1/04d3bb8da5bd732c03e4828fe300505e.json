{"summary": "Aggregates token log‑probabilities and true token IDs to compute the mean perplexity of a batch of sequences, optionally ignoring padded positions via a mask and supporting distributed synchronization across processes.", "business_intent": "Offers a standardized metric for evaluating language‑model performance during training and validation, facilitating model comparison, monitoring of convergence, and reporting of quality indicators.", "keywords": ["perplexity", "language model", "evaluation metric", "batch processing", "masking", "distributed synchronization", "PyTorch Lightning", "metric"], "summary_hash": "de572ebc27d5", "cached_at": "2026-02-08T09:42:57+00:00"}