{"summary": "Implements a TensorFlow version of MobileBERT tailored for masked language modeling, offering model construction, forward execution, access to the language‑modeling head, handling of prefix bias naming, and utilities for converting TensorFlow weights to PyTorch format.", "business_intent": "Enable efficient, mobile‑friendly masked language modeling using a compact BERT variant, supporting deployment on resource‑limited devices and seamless weight migration between TensorFlow and PyTorch ecosystems.", "keywords": ["MobileBERT", "masked language modeling", "TensorFlow", "lightweight NLP", "lm_head", "prefix bias", "weight conversion", "mobile deployment"], "summary_hash": "2f6dfcd62abf", "cached_at": "2026-02-09T11:36:09+00:00"}