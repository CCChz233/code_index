{"summary": "Provides an optimized batched greedy decoding routine that iteratively finds the next non‑blank label while minimizing prediction network invocations, leveraging CUDA graph execution for high‑throughput sequence inference.", "business_intent": "Enable fast, scalable decoding of sequence models (such as speech or language transcription) in production environments by cutting latency and computational cost.", "keywords": ["greedy decoding", "batched inference", "label looping", "prediction network optimization", "CUDA graphs", "high‑throughput decoding", "sequence modeling", "performance scaling"], "summary_hash": "e3b16b791819", "cached_at": "2026-02-08T09:30:22+00:00"}