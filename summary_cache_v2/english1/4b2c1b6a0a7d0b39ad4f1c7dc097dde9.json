{"summary": "A comprehensive utility module that centralizes helper logic for interacting with large language model providers. It includes iterators for handling synchronous and asynchronous model responses, wrappers for streaming text completions, configuration management for providers, token counting, request preparation, retry handling, and various convenience functions for processing messages, images, and audio.", "business_intent": "Enable developers to integrate and manage multiple LLM services through a unified interface, simplifying request construction, response consumption, and ancillary tasks such as token budgeting, caching, and error handling.", "keywords": ["LLM utilities", "response iterator", "streaming wrapper", "provider configuration", "token counting", "async support", "error handling", "caching", "request preparation", "message processing"], "summary_hash": "06090b066c1c", "cached_at": "2026-02-08T07:14:52+00:00"}