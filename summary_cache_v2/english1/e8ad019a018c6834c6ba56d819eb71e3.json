{"summary": "Encapsulates the results produced by a Longformer token‑classification model, including optional loss, per‑token classification scores, and, when requested, the hidden‑state tensors and attention weight matrices for each layer.", "business_intent": "Facilitates downstream sequence‑labeling applications (e.g., named‑entity recognition, part‑of‑speech tagging) by delivering a unified, easy‑to‑consume structure that supplies both prediction data and diagnostic information for model training and analysis.", "keywords": ["Longformer", "token classification", "logits", "loss", "hidden states", "attentions", "global attentions", "sequence labeling", "PyTorch", "model output"], "summary_hash": "2054629ca8b6", "cached_at": "2026-02-09T11:13:20+00:00"}