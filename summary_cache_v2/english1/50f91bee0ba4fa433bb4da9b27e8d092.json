{"summary": "The script demonstrates how to perform distributed multi‑GPU training for link prediction on large graph datasets using DGL and PyTorch. It defines a GraphSAGE model, custom loss and negative sampling utilities, sets up data loaders with neighbor sampling, and runs training and evaluation loops across multiple processes.", "business_intent": "Provide a reference implementation for scalable graph neural network link prediction, enabling engineers and researchers to build high‑performance recommendation or network analysis pipelines that leverage multiple GPUs and distributed computing.", "keywords": ["graph neural network", "link prediction", "multi‑GPU", "distributed training", "DGL", "PyTorch", "GraphSAGE", "negative sampling", "cross‑entropy loss", "neighbor sampling", "large‑scale graphs", "OGB", "Reddit dataset", "evaluation metrics"], "summary_hash": "7252dbf561e4", "cached_at": "2026-02-09T00:24:38+00:00"}