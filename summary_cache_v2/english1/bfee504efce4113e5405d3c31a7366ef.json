{"summary": "Container class that holds the outputs of a Reformer model equipped with a language modeling head, including optional loss, token prediction logits, cached bucket and hidden states for fast sequential decoding, per‑layer hidden representations, and attention weight matrices.", "business_intent": "Facilitate downstream processing of Reformer language model results by providing a unified structure for loss tracking, next‑token prediction, efficient generation via cached states, and analysis of internal model dynamics such as hidden layers and attention patterns.", "keywords": ["loss", "logits", "past bucket states", "hidden states", "attentions", "language modeling", "Reformer", "output container", "caching", "sequential decoding"], "summary_hash": "77db27c08740", "cached_at": "2026-02-09T08:32:12+00:00"}