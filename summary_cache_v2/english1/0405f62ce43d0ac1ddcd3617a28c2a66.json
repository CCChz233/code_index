{"summary": "Implements a diffusion layer for homogeneous graphs that repeatedly propagates node features using a chosen diffusion matrix (raw adjacency, random-walk normalized, symmetrically normalized, or personalized PageRank). For a specified number of steps it computes successive powers of the diffusion operator applied to the input features and stores each step’s result as separate node attributes.", "business_intent": "Enable scalable multi‑hop feature aggregation in graph neural networks, particularly for the SIGN framework, by providing a configurable diffusion mechanism that can incorporate edge weights and different normalization schemes, facilitating downstream learning tasks on graph data.", "keywords": ["graph diffusion", "multi‑step propagation", "node feature aggregation", "raw adjacency", "random walk normalization", "GCN normalization", "personalized PageRank", "homogeneous graph", "edge weights", "DGL"], "summary_hash": "378037799c3b", "cached_at": "2026-02-08T23:36:25+00:00"}