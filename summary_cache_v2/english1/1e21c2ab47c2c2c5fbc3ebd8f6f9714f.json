{"summary": "Defines a PyTorch module that implements an edge‑aware graph attention convolution layer. The layer incorporates edge attributes into the attention score, transforms edge features, performs multi‑head attention, and updates node embeddings. It works for both homogeneous and bipartite graphs and includes options for residual connections, activation, and dropout.", "business_intent": "Provide a flexible building block for graph neural network models that need to leverage edge information, enabling improved performance on tasks such as node classification, link prediction, and graph representation learning where edge features are critical.", "keywords": ["graph attention network", "edge-aware", "EGAT", "PyTorch", "DGL", "convolution", "multi-head attention", "edge features", "message passing", "graph neural network", "heterogeneous graph", "bipartite graph", "dropout", "residual connection", "activation"], "summary_hash": "96f9aaf937b0", "cached_at": "2026-02-09T00:45:31+00:00"}