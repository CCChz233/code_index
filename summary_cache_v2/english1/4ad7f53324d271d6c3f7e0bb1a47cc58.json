{"summary": "A model class that leverages the NEZHA transformer architecture to perform token-level classification tasks, providing a forward pass that maps input sequences to per-token label predictions.", "business_intent": "Facilitate fine‑tuning and deployment of Chinese language token classification applications such as named entity recognition, part‑of‑speech tagging, or any sequence labeling task.", "keywords": ["NEZHA", "token classification", "transformer", "NLP", "sequence labeling", "pretrained model", "fine‑tuning"], "summary_hash": "8901fd9d6f32", "cached_at": "2026-02-09T08:16:17+00:00"}