{"summary": "Pipeline that performs image-guided inpainting using a Stable Diffusion model. It encodes a reference image, conditions the UNet denoiser on that encoding, runs diffusion with a scheduler, decodes the latent result back to an image via a VAE, and optionally applies a safety checker.", "business_intent": "Enable developers and creators to automatically fill or replace regions of an image based on visual examples, supporting creative workflows such as photo editing, visual effects, advertising, and rapid prototyping of graphics.", "keywords": ["image inpainting", "example-guided generation", "Stable Diffusion", "diffusion pipeline", "VAE", "UNet denoiser", "scheduler", "safety checker", "image encoder", "CLIP image processor", "generative AI", "content creation"], "summary_hash": "05e9f20ae4bd", "cached_at": "2026-02-09T05:24:15+00:00"}