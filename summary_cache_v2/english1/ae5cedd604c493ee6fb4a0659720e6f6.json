{"summary": "Encapsulates a cache of precomputed prompt encoder outputs for use during inference, offering methods to set, retrieve, and clear the stored representations.", "business_intent": "Accelerate model inference by avoiding repeated prompt encoder computations through reusable cached representations.", "keywords": ["inference", "prompt encoder", "cache", "representation", "table", "set", "get", "clear", "efficiency", "wrapper"], "summary_hash": "c94beedeee6c", "cached_at": "2026-02-08T09:43:52+00:00"}