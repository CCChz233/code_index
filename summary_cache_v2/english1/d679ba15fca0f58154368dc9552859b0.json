{"summary": "A test suite that validates the integration of Lakera AI's prompt injection guardrail within the Litellm proxy, covering detection thresholds, safe prompt handling, message ordering, role restrictions, and moderation of embeddings and function inputs.", "business_intent": "To verify that AI content moderation safeguards correctly identify and block malicious prompts, ensuring reliable protection against prompt injection attacks in the application.", "keywords": ["Lakera AI", "prompt injection", "guardrail", "moderation", "Litellm", "proxy", "testing", "thresholds", "embeddings", "function input", "message ordering", "safe prompt"], "summary_hash": "82afcdf24bbf", "cached_at": "2026-02-08T07:26:27+00:00"}