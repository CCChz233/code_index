{"summary": "Implements a residual neural network block that applies two consecutive convolutions followed by activation and group normalization, then adds the original input via a skip connection. Supports configurable spatial dimensionality, channel sizes, tensor splitting, optional half‑precision normalization, and memory‑saving options.", "business_intent": "Provide a flexible, memory‑efficient building component for constructing deep convolutional models, enabling faster training and inference in applications such as image or volume processing.", "keywords": ["residual block", "convolution", "activation", "group normalization", "tensor splitting", "memory optimization", "float16 support", "CUDA cache", "spatial dimensions", "deep learning"], "summary_hash": "fde49532d17f", "cached_at": "2026-02-08T12:18:55+00:00"}