{"summary": "Provides builder classes that assemble and configure the decoder layer components of a LLaMA transformer model for TensorRT-LLM, handling attention, layer normalization, MLP, MoE and quantization settings to produce a ready-to-use decoder layer instance.", "business_intent": "Facilitate the export and deployment of LLaMA models onto TensorRT for highâ€‘performance inference in production environments.", "keywords": ["LLaMA", "decoder layer", "builder", "configuration", "TensorRT", "LLM", "attention", "MLP", "layer normalization", "quantization", "model export", "inference acceleration"], "summary_hash": "ad84b360bf7a", "cached_at": "2026-02-08T11:39:54+00:00"}