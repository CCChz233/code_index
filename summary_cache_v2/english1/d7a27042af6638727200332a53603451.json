{"summary": "A container class that encapsulates the primary outputs of a transformer model, including the final hidden states and optional collections of intermediate hidden states, self‑attention weights, and cross‑attention weights for encoder‑decoder architectures.", "business_intent": "Standardize access to model representations and attention information so that downstream applications, analysis tools, and debugging utilities can reliably retrieve and manipulate these tensors without handling low‑level model internals.", "keywords": ["model output", "hidden states", "attention weights", "cross attention", "tensor", "transformer", "encoder-decoder", "PyTorch", "sequence representation"], "summary_hash": "3d553c6765f5", "cached_at": "2026-02-09T06:28:12+00:00"}