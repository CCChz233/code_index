{"summary": "Encapsulates an InstructBLIP vision-language model, managing its initialization, preprocessing, and inference to perform instruction‑guided visual tasks such as captioning, visual question answering, and image understanding.", "business_intent": "Enable applications that require AI-driven interpretation of images based on natural‑language instructions, supporting use cases like automated caption generation, visual QA, content moderation, and multimodal user interfaces.", "keywords": ["vision-language model", "InstructBLIP", "image captioning", "visual question answering", "multimodal AI", "instruction following", "image understanding", "AI inference"], "summary_hash": "b55739c7bec1", "cached_at": "2026-02-09T07:08:00+00:00"}