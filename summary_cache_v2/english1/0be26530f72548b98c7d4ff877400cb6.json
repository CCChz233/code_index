{"summary": "A neural network module that computes binary cross‑entropy loss directly from raw logits, applying a sigmoid internally for numerical stability and supporting optional weighting and reduction strategies.", "business_intent": "Enable training of binary or multi‑label classification models by providing a reliable loss metric that integrates activation and loss calculation in a single step.", "keywords": ["binary cross entropy", "logits", "loss function", "neural network", "PyTorch", "classification", "numerical stability", "reduction", "weighting"], "summary_hash": "26590385ab23", "cached_at": "2026-02-08T08:28:26+00:00"}