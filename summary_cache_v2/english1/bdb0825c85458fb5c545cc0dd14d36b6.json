{"summary": "Implements ORC input/output support for Dask DataFrames using Apache Arrow. It extracts schemas, aggregates metadata across multiple ORC files, and provides column‑projected, partitioned reading and writing of columnar data. The functionality integrates with Dask's high‑level graph to distribute row‑group reads and writes across workers.", "business_intent": "Enable users to efficiently load, query, and store large ORC datasets in a distributed Dask environment, offering column selection, parallel processing, and seamless integration with Dask's task scheduling.", "keywords": ["dask", "dataframe", "orc", "apache arrow", "parallel read", "parallel write", "columnar storage", "schema extraction", "partitioned processing", "high-level graph", "metadata", "row groups"], "summary_hash": "dddfe37a9df6", "cached_at": "2026-02-08T23:27:47+00:00"}