{"summary": "Provides test scenarios for assessing the prompt injection detection features of the LiteLLM proxy, including simulations of malicious prompt attempts and evaluation of detection accuracy using language model responses.", "business_intent": "To verify and strengthen security safeguards that identify and block prompt injection attacks in LLM deployments, ensuring safe and reliable model interactions.", "keywords": ["prompt injection", "detection", "LLM security", "LiteLLM", "proxy testing", "malicious prompt", "safety validation", "automated evaluation"], "summary_hash": "35d31d61e35b", "cached_at": "2026-02-08T07:30:47+00:00"}