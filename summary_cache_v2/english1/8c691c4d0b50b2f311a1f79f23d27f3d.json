{"summary": "Encapsulates a HuggingFace transformer encoder for seamless integration with NeMo NLP pipelines, managing model loading, inference execution, and exposing key model dimensions such as hidden and vocabulary sizes.", "business_intent": "Provide a reusable component that lets developers plug pretrained HuggingFace encoders into NeMo-based speech and language applications, streamlining model reuse and inference handling.", "keywords": ["HuggingFace", "encoder", "NeMo", "NLP", "transformer", "model integration", "inference", "hidden size", "vocabulary size"], "summary_hash": "a97088265152", "cached_at": "2026-02-08T09:45:59+00:00"}