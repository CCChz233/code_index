{"summary": "Implements a convolutional neural network layer that integrates squeeze‑and‑excitation and weight‑decomposition mechanisms while deliberately omitting layer normalization, and provides a forward computation.", "business_intent": "Offer a lightweight, high‑performance building block for computer‑vision models that reduces parameter count and improves feature representation without the overhead of layer‑norm.", "keywords": ["convolution", "squeeze-and-excitation", "weight decomposition", "no layer normalization", "neural network layer", "forward pass", "deep learning"], "summary_hash": "116aaf93641f", "cached_at": "2026-02-09T08:13:58+00:00"}