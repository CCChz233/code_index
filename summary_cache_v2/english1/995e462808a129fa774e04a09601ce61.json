{"summary": "A tokenizer that processes input text and combines consecutive words that match entries in a supplied vocabulary into single phrase tokens, using a configurable separator for multi‑word phrases.", "business_intent": "Enable more accurate text representation for NLP models by preserving known multi‑word expressions, facilitating compatibility with pre‑trained phrase embeddings and improving downstream tasks such as classification, search, or recommendation.", "keywords": ["tokenization", "phrase detection", "vocabulary", "ngram separator", "text preprocessing", "NLP", "embedding compatibility"], "summary_hash": "022bb4ade9aa", "cached_at": "2026-02-08T13:48:32+00:00"}