{"summary": "Test suite that validates the parity between Lightning Fabric's training loop and native PyTorch training for a simple convolutional network across single‑device and distributed configurations, checking deterministic behavior, state‑dict equality, timing, and CUDA memory usage.", "business_intent": "Guarantee that using Lightning Fabric does not alter model correctness or performance compared to standard PyTorch, providing confidence for developers to adopt Fabric in production and research pipelines.", "keywords": ["parity", "Lightning Fabric", "PyTorch", "training loop", "ConvNet", "deterministic", "CUDA", "distributed training", "state dict", "timing", "memory usage", "testing"], "summary_hash": "cc14a36c44f7", "cached_at": "2026-02-08T08:32:17+00:00"}