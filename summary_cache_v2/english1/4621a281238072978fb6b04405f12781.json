{"summary": "Provides a TensorRT engine wrapper that loads a serialized engine, allocates and manages input/output buffers, activates the execution context, and runs inference calls. Includes utilities for tensor handling, noise generation, and schedule creation to support neural rendering models.", "business_intent": "Accelerate NeRF inference by leveraging TensorRT for high‑performance, low‑latency deployment in multimodal AI applications.", "keywords": ["TensorRT", "inference engine", "NeRF", "CUDA", "engine loading", "buffer management", "high‑performance inference", "noise generation", "schedule creation", "multimodal AI"], "summary_hash": "5039b3c85c2f", "cached_at": "2026-02-08T12:03:09+00:00"}