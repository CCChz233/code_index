{"summary": "A customizable linear transformation module that separates its main weight matrix from auxiliary trainable parameters, allowing the core weights to be optionally frozen while always training any extra feature weights. When no extra features are requested, it behaves like a standard linear layer.", "business_intent": "Enable selective fine‑tuning of neural networks by freezing base parameters and learning additional features, supporting efficient transfer learning and parameter‑efficient adaptation in large models.", "keywords": ["linear layer", "parameter freezing", "decoupled parameters", "additional trainable features", "fine‑tuning", "transfer learning", "PyTorch", "neural network module"], "summary_hash": "eafc67c3020d", "cached_at": "2026-02-09T08:41:24+00:00"}