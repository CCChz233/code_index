{"summary": "We need to produce JSON with summary, business_intent, keywords list.\n\nWe have file path: nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py. The docstring is empty? Not provided. The class summary: DuplexTextNormalizationModel: A wrapper that bundles a pre‑trained tagger and decoder to perform text‑normalization inference, allowing users to run evaluations on normalized text without modifying the underlying models.\n\nWe need to infer responsibilities: It likely loads tagger and decoder models, runs inference on text normalization tasks, provides evaluation utilities, maybe integrates with dataset and utils.\n\nBusiness intent: Provide a ready-to-use model for text normalization in speech or NLP pipelines, enabling conversion of spoken-form tokens to written form, improving downstream ASR or TTS.\n\nKeywords: text normalization, inference, tagger, decoder, pre-trained, evaluation, NLP, NeMo, model wrapper, speech processing, token conversion.\n\nLet's craft summary: The module defines a model class that encapsulates a pre‑trained tagging component and a decoding component to perform end‑to‑end text normalization. It handles loading, preprocessing inputs, running the tagger to predict token classes, applying the decoder to generate normalized strings, and offers methods for batch inference and evaluation against test datasets.\n\nBusiness intent: Provide developers with a plug‑and‑play solution to normalize textual data (e.g., spoken numbers, dates) within NeMo, facilitating integration into speech recognition or synthesis pipelines and enabling performance assessment without altering underlying models.\n\nKeywords list.\n\nReturn JSON.\n\nLet's craft.\n\nassistantfinal{\n  \"summary\": \"The module implements a model class that combines a pre‑trained tagging network with a decoder to perform end‑to‑end text normalization. It manages loading of the tagger and decoder, preprocessing of raw inputs, inference to predict token tags, decoding of those tags into normalized strings, and utilities for batch processing and evaluation against standard test datasets.\",\n  \"business_intent\": \"Offer a ready‑to‑use, high‑accuracy text‑normalization component for speech and NLP applications, enabling developers to convert spoken‑form tokens (numbers, dates, abbreviations, etc.) into their written forms within NeMo pipelines and to assess performance without modifying the underlying models.\",\n  \"keywords\": [\n    \"text normalization\",\n    \"inference\",\n    \"tagger\",\n    \"decoder\",\n    \"pre‑trained model\",\n    \"evaluation\",\n    \"NLP\",\n    \"NeMo\",\n    \"speech processing\",", "business_intent": "We need to produce JSON with summary, business_intent, keywords list.\n\nWe have file path: nemo/collections/nlp/models/duplex_text_normalization/duplex_tn.py. The docstring is empty? Not provided. The class summary: DuplexTextNormalizationModel: A wrapper that bundles a pre‑trained tagger and decoder to perform text‑normalization inference, allowing users to run evaluations on normalized text without modifying the underlying models.\n\nWe need to infer responsibilities: It likely loads tagger and decoder models, runs inference on text normalization tasks, provides evaluation utilities, maybe integrates with dataset and utils.\n\nBusiness intent: Provide a ready-to-use model for text normalization in speech or NLP pipelines, enabling conversion of spoken-form tokens to written form, improving downstream ASR or TTS.\n\nKeywords: text normalization, inference, tagger, decoder, pre-trained, evaluation, NLP, NeMo, model wrapper, speech processing, token conversion.\n\nLet's craft summary: The module defines a model class that encapsulates a pre‑trained tagging component and a decoding component to perform end‑to‑end text normalization. It handles loading, preprocessing inputs, running the tagger to predict token classes, applying the decoder to generate normalized strings, and offers methods for batch inference and evaluation against test datasets.\n\nBusiness intent: Provide developers with a plug‑and‑play solution to normalize textual data (e.g., spoken numbers, dates) within NeMo, facilitating integration into speech recognition or synthesis pipelines and enabling performance assessment without altering underlying models.\n\nKeywords list.\n\nReturn JSON.\n\nLet's craft.\n\nassistantfinal{\n  \"summary\": \"The module implements a model class that combines a pre‑trained tagging network with a decoder to perform end‑to‑end text normalization. It manages loading of the tagger and decoder, preprocessing of raw inputs, inference to predict token tags, decoding of those tags into normalized strings, and utilities for batch processing and evaluation against standard test datasets.\",\n  \"business_intent\": \"Offer a ready‑to‑use, high‑accuracy text‑normalization component for speech and NLP applications, enabling developers to convert spoken‑form tokens (numbers, dates, abbreviations, etc.) into their written forms within NeMo pipelines and to assess performance without modifying the underlying models.\",\n  \"keywords\": [\n    \"text normalization\",\n    \"inference\",\n    \"tagger\",\n    \"decoder\",\n    \"pre‑trained model\",\n    \"evaluation\",\n    \"NLP\",\n    \"NeMo\",\n    \"speech processing\",", "keywords": [], "summary_hash": "ad94b8a3746c", "cached_at": "2026-02-08T11:33:44+00:00"}