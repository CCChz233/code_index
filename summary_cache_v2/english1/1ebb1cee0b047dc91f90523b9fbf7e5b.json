{"summary": "A pre‑trained multilingual ProphetNet model class that encapsulates the architecture, pretrained weights, and associated utilities for downstream natural language processing tasks such as translation, summarization, and text generation.", "business_intent": "Provide developers with an out‑of‑the‑box cross‑lingual sequence‑to‑sequence model to accelerate multilingual language understanding and generation applications without the need for extensive training.", "keywords": ["XLM", "ProphetNet", "pretrained model", "multilingual", "NLP", "transformer", "sequence-to-sequence", "language generation", "translation", "summarization", "transfer learning"], "summary_hash": "a715d57d9c1d", "cached_at": "2026-02-09T07:33:12+00:00"}