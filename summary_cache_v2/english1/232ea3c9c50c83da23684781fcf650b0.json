{"summary": "Implements a reusable neural network module that applies two consecutive 3×3 convolution layers, each followed by batch normalization and ReLU activation.", "business_intent": "Provides a compact building block for constructing deep learning models, enabling efficient feature extraction and stable training through combined convolution, normalization, and non‑linear activation.", "keywords": ["convolution", "batch normalization", "ReLU", "neural network", "feature extraction", "PyTorch", "module", "double convolution"], "summary_hash": "63f54b3499ac", "cached_at": "2026-02-08T08:07:41+00:00"}