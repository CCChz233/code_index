{"summary": "Applies temporal masking to video sequences by replacing randomly selected consecutive frames with the video's mean frame. The mask length is uniformly sampled up to a configurable maximum, and the number of masks scales with the video duration (approximately one mask per second). This augmentation follows the strategy described in the Visual Speech Recognition paper to improve model robustness to temporal variations.", "business_intent": "Enhance training data for visual speech recognition systems through realistic temporal distortions, thereby increasing model accuracy and generalization across diverse video lengths.", "keywords": ["video augmentation", "temporal masking", "frame replacement", "visual speech recognition", "data augmentation", "sequence-length scaling", "mean frame"], "summary_hash": "994182b3d5ef", "cached_at": "2026-02-08T08:48:40+00:00"}