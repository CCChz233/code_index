{"summary": "A command‑line utility that reads a JSONL chat dataset, tokenizes each record using a specified tokenizer (HuggingFace or SentencePiece), truncates to a given sequence length, discards any entries that become entirely masked after truncation, and writes the filtered records to a new JSONL file.", "business_intent": "To ensure high‑quality fine‑tuning data for large language models by automatically removing unusable or fully masked records, thereby improving training efficiency and model performance.", "keywords": ["data cleaning", "fine‑tuning", "chat dataset", "tokenization", "truncation", "masking", "HuggingFace", "SentencePiece", "JSONL", "GPTSFTChatDataset"], "summary_hash": "bc39fceb13d5", "cached_at": "2026-02-08T11:49:16+00:00"}