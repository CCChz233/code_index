{"summary": "Provides a command‑line utility to fine‑tune an existing NeMo speech‑to‑text model. It supports initializing the model from a saved NeMo checkpoint or a public pretrained model, optionally updating the tokenizer, configuring data loaders, and launching training via Hydra and PyTorch Lightning.", "business_intent": "Allow developers and researchers to adapt pre‑trained automatic speech recognition models to new domains or datasets without redesigning the model architecture, accelerating deployment of customized speech‑to‑text solutions.", "keywords": ["speech-to-text", "ASR", "fine-tuning", "NeMo", "pretrained model", "checkpoint", "tokenizer update", "Hydra configuration", "data loading", "model adaptation"], "summary_hash": "667e3523768b", "cached_at": "2026-02-08T10:35:12+00:00"}