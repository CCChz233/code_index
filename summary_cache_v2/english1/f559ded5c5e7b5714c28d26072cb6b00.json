{"summary": "A component that records and provides per-token latency statistics during model inference, maintaining separate measurements for prefill and decode phases and offering utilities to query, reset, and update these timings.", "business_intent": "Enable performance monitoring and optimization of language model serving by exposing detailed timing data for each generated token.", "keywords": ["latency", "token", "performance", "monitoring", "inference", "metrics", "prefill", "decode", "tracking", "reset"], "summary_hash": "f05e56e4054c", "cached_at": "2026-02-09T02:25:33+00:00"}