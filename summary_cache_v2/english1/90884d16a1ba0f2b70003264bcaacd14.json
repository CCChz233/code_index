{"summary": "The module implements a neural component that performs differentiable vector quantization using Gumbel sampling. It maps continuous speech embeddings to discrete codebook entries, manages the quantization process during forward passes, extracts token indices, and tracks updates for training self‑supervised speech models.", "business_intent": "Provide a reusable quantization layer that enables speech models to learn compact, discrete representations, facilitating more efficient and effective self‑supervised learning pipelines for automatic speech recognition and related applications.", "keywords": ["Gumbel", "vector quantization", "differentiable quantizer", "codebook", "speech embeddings", "self-supervised learning", "ASR", "NeuralModule", "PyTorch", "discrete representation"], "summary_hash": "6dccb5f3cf81", "cached_at": "2026-02-08T11:14:42+00:00"}