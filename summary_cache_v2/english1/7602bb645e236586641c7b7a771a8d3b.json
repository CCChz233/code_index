{"summary": "The module provides a metric that assesses how closely predicted tool (function) calls in AI-generated messages match the expected calls. It compares call names and arguments, supports both single‑turn and multi‑turn interactions, and ensures the sequence of calls aligns with the reference.", "business_intent": "Enable developers of AI agents and conversational assistants to quantitatively evaluate the correctness of tool invocation logic, improving reliability and performance of systems that rely on function calls within LLM responses.", "keywords": ["tool call evaluation", "accuracy metric", "LLM", "function call validation", "single turn", "multi turn", "argument comparison", "sequence alignment", "AI assistant testing", "ragas"], "summary_hash": "92da8d15eccf", "cached_at": "2026-02-08T22:50:19+00:00"}