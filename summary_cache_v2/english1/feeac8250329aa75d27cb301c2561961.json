{"summary": "Implements a language modeling head for the Longformer architecture, converting encoder hidden states into token prediction logits for masked language modeling tasks.", "business_intent": "Facilitates masked language modeling using Longformer, supporting applications such as text completion, token prediction, and pre‑training of large‑scale NLP models.", "keywords": ["Longformer", "masked language modeling", "language model head", "transformer", "NLP", "weight tying", "logits", "token prediction"], "summary_hash": "6f80cb30f844", "cached_at": "2026-02-09T11:12:31+00:00"}