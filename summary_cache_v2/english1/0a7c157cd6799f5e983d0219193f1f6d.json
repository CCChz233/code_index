{"summary": "EMAOptimizer wraps a PyTorch optimizer to maintain an exponential moving average of model parameters. After each optimizer step, EMA weights are updated with a configurable decay factor, and a context manager enables temporary inâ€‘place swapping of the model's regular weights with their EMA counterparts for evaluation or inference.", "business_intent": "Offer a simple mechanism to improve training stability and inference quality by using smoothed EMA weights, allowing users to evaluate or deploy models with reduced variance without altering the underlying optimizer.", "keywords": ["exponential moving average", "EMA", "optimizer wrapper", "PyTorch", "parameter smoothing", "weight swapping", "training stability", "model evaluation", "inference", "decay factor"], "summary_hash": "3d9c6cc43f7b", "cached_at": "2026-02-08T08:24:14+00:00"}