{"summary": "Implements a gated linear unit activation that splits an input tensor into two halves, using the second half as a multiplicative gate to modulate the first half, thereby controlling data flow within neural network layers.", "business_intent": "Provide an efficient gating mechanism to enhance model expressiveness and performance in deep learning architectures, especially in transformer‑based or feed‑forward components.", "keywords": ["gated linear unit", "activation function", "neural network", "tensor gating", "split hidden states", "element-wise multiplication", "deep learning", "model efficiency"], "summary_hash": "866051fb3e29", "cached_at": "2026-02-09T11:01:35+00:00"}