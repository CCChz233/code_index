{"summary": "...", "business_intent": "...", "keywords": ["self-attention", "transformer", "GPT-Neo", "multi-head attention", "split heads", "merge heads", "forward pass", "natural language processing"], "summary_hash": "88765193326e", "cached_at": "2026-02-09T11:38:51+00:00"}