{"summary": "Implements a learning‑rate schedule that applies an initial warm‑up phase followed by cosine annealing, supporting multiple repeated cycles configured via list parameters. It outputs a scaling factor assuming a base learning rate of 1.0.", "business_intent": "Automatically adjust the optimizer’s learning rate during model training to improve convergence and stability by providing a warm‑up increase and smooth cosine decay across configurable repeated intervals.", "keywords": ["learning rate scheduler", "warm-up", "cosine annealing", "repeated cycles", "configurable phases", "scaling factor", "deep learning training", "optimizer"], "summary_hash": "aafaa4fb09bd", "cached_at": "2026-02-08T08:50:38+00:00"}