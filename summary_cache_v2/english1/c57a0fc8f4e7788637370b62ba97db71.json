{"summary": "Provides a parallelized vocabulary crossâ€‘entropy loss module with utilities for computing the loss value and its gradient in distributed training scenarios.", "business_intent": "Enable efficient training of large language models by calculating loss and gradients across sharded vocabularies.", "keywords": ["cross-entropy", "loss", "gradient", "distributed training", "vocab parallelism", "neural network", "language model", "parallel computation", "forward computation", "backward computation"], "summary_hash": "2cd0d5497d85", "cached_at": "2026-02-08T09:48:30+00:00"}