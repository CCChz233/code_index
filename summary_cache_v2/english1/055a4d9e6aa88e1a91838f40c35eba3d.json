{"summary": "This module implements the integration layer for Vertex AI non‑Gemini models within the LiteLLM framework. It provides functions for synchronous and asynchronous text completions, streaming responses, and utilities for caching HTTP clients, handling errors, and converting prompts and file types to the format expected by Vertex AI Model Garden.", "business_intent": "Allow applications to easily access and use Vertex AI's non‑Gemini language models through a unified LiteLLM interface, supporting both regular and streaming completions while abstracting authentication, request formatting, and response parsing.", "keywords": ["Vertex AI", "Model Garden", "completion", "streaming", "async", "client caching", "error handling", "text streamer", "LiteLLM integration", "non‑Gemini", "HTTP requests", "prompt conversion", "file type handling"], "summary_hash": "cb044618dd2c", "cached_at": "2026-02-08T07:54:36+00:00"}