{"summary": "Provides a pooling component for RoBERTa models that applies layer normalization prior to extracting a fixed‑size representation from token embeddings.", "business_intent": "Generate a compact sentence or document embedding from RoBERTa hidden states for use in downstream NLP applications such as classification, ranking, or similarity measurement.", "keywords": ["RoBERTa", "pooling", "layer normalization", "pre‑layer norm", "sentence embedding", "transformer", "neural network", "NLP"], "summary_hash": "1418c1def4f5", "cached_at": "2026-02-09T09:10:15+00:00"}