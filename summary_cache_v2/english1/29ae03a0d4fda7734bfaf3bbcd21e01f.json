{"summary": "Encapsulates all configurable hyperparameters for a CodeGen transformer model, offering defaults that replicate the Salesforce/codegen-2B-mono architecture while allowing customization of vocabulary size, maximum sequence length, embedding dimensions, number of layers and heads, rotary position embedding size, feed‑forward dimensions, activation function, dropout rates, layer‑norm epsilon, weight initialization range, caching behavior, special token IDs, and embedding tying.", "business_intent": "Provide a straightforward way for developers to define, adjust, and reuse model architecture settings so that CodeGen models can be instantiated consistently for code generation tasks, supporting both pretrained and custom configurations.", "keywords": ["configuration", "transformer", "hyperparameters", "vocab size", "sequence length", "embedding dimension", "layer count", "attention heads", "rotary position embedding", "dropout", "activation function", "layer normalization", "initializer", "cache", "token IDs", "tie embeddings", "code generation"], "summary_hash": "d14d64e7fa2a", "cached_at": "2026-02-09T08:32:28+00:00"}