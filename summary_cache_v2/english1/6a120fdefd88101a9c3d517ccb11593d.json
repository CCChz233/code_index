{"summary": "Container class that aggregates all outputs from a FLAVA pretraining forward pass, including optional total loss, detailed loss breakdown, pooled embeddings and full model outputs for image, text, and multimodal encoders (both unmasked and masked versions), as well as the various logits required for the model's pretraining objectives such as masked image modeling, masked language modeling, image‑text matching, multimodal masked modeling, and contrastive similarity scores.", "business_intent": "Provides a unified, easy‑to‑access structure for downstream code to retrieve embeddings, model states, and loss‑related logits after running a FLAVA model, facilitating loss computation, retrieval, similarity scoring, and analysis of pretraining results.", "keywords": ["FLAVA", "pretraining", "embeddings", "image", "text", "multimodal", "loss", "logits", "contrastive", "masked", "MIM", "MLM", "ITM", "MMM", "torch", "output container"], "summary_hash": "2eb27001c0ab", "cached_at": "2026-02-09T10:16:24+00:00"}