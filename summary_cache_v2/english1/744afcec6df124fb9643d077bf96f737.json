{"summary": "Provides a Litellm integration that captures LLM request and response metadata, formats it according to Datadog's LLM Observability schema, and asynchronously batches and sends the data to Datadog's API, while handling errors and logging transmission results.", "business_intent": "Allow developers to automatically forward LLM usage information to Datadog for centralized monitoring, performance analysis, and cost tracking of language model deployments.", "keywords": ["Datadog", "LLM observability", "telemetry", "asynchronous logging", "batch transmission", "monitoring", "litellm integration", "HTTP client", "payload assembly", "error handling"], "summary_hash": "1379345fec96", "cached_at": "2026-02-08T07:52:43+00:00"}