{"summary": "Encapsulates a single preâ€‘processed data example, storing token identifiers, attention masks, segment identifiers, and the associated label.", "business_intent": "Provide a structured container for tokenized inputs and their metadata so that downstream NLP models can consume consistent feature sets during training or inference.", "keywords": ["token ids", "attention mask", "segment ids", "label", "feature container", "NLP preprocessing", "model input representation"], "summary_hash": "16bffbbbd4d8", "cached_at": "2026-02-08T09:55:31+00:00"}