{"summary": "A TensorFlow data structure that aggregates all outputs of a CLIP model, including optional contrastive loss, similarity logits for image‑to‑text and text‑to‑image, projected image and text embeddings, and the raw outputs of the underlying text and vision encoders.", "business_intent": "Facilitate multimodal applications such as image‑text retrieval, zero‑shot classification, and similarity scoring by providing a unified, easy‑to‑consume representation of CLIP inference results.", "keywords": ["TensorFlow", "CLIP", "multimodal", "image-text similarity", "contrastive loss", "logits", "embeddings", "vision model output", "text model output", "output container"], "summary_hash": "d47bb62f7305", "cached_at": "2026-02-09T11:20:43+00:00"}