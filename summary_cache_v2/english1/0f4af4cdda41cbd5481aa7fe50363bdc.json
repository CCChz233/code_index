{"summary": "A neural network layer that applies activity regularization to its inputs, adding a penalty to the loss based on the magnitude of the activations during training.", "business_intent": "To enhance model generalization and reduce overfitting by discouraging large or unnecessary activations, promoting sparsity or smoother representations in deep learning models.", "keywords": ["activity regularization", "neural network layer", "loss penalty", "overfitting mitigation", "sparsity", "L1", "L2", "deep learning"], "summary_hash": "1bb6fa762986", "cached_at": "2026-02-09T11:17:03+00:00"}