{"summary": "Implements a basic document ingestion workflow using LlamaIndex: reads files from a directory, builds a vector store index, persists it, and provides a helper function to execute queries against the stored index.", "business_intent": "Showcase a simple, experimental setup for ingesting documents into a vector store and querying them, serving as a prototype for search or retrievalâ€‘augmented generation applications.", "keywords": ["LlamaIndex", "document ingestion", "vector store", "index persistence", "query helper", "knowledge base", "experimental example", "search", "RAG"], "summary_hash": "7a87c472114a", "cached_at": "2026-02-08T05:28:09+00:00"}