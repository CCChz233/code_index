{"summary": "Implements a single EfficientNet building block that expands input channels, applies depthwise convolution (with optional padding adjustments), integrates squeeze‑and‑excitation, dropout, and optional residual skip connections, producing the transformed output tensor.", "business_intent": "Provides a reusable, configurable component for constructing EfficientNet models, enabling efficient feature extraction and scaling while supporting regularization and residual pathways.", "keywords": ["EfficientNet", "block", "expansion", "depthwise convolution", "squeeze-and-excitation", "residual skip", "dropout", "stride", "kernel size", "padding", "neural network architecture"], "summary_hash": "1ea36e4ad201", "cached_at": "2026-02-09T08:40:58+00:00"}