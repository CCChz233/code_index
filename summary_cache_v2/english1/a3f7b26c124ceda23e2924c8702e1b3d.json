{"summary": "Encapsulates all architectural and training hyperparameters needed to construct an MGP-STR scene‑text recognition model, offering a structured configuration object that can be supplied to the model constructor to define image dimensions, patch size, channel count, token limits, label vocabularies, transformer depth, attention heads, MLP scaling, bias options, distillation token, normalization epsilon, dropout rates, stochastic depth, attention output flags, and weight initialization.", "business_intent": "Provides developers a convenient way to specify, reuse, and adjust the model architecture and training settings for MGP‑STR models, enabling reproducible instantiation, fine‑tuning, and deployment of scene‑text recognition systems.", "keywords": ["configuration", "MGP-STR", "scene text recognition", "transformer", "hyperparameters", "model architecture", "dropout", "attention", "distillation", "pretrained"], "summary_hash": "6986ca9ef5cd", "cached_at": "2026-02-09T10:10:25+00:00"}