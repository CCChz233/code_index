{"summary": "Provides a lazily-evaluated collection of labeled examples for supervised fine-tuning, exposing standard sequence-like access (indexing and size) while deferring data loading until needed.", "business_intent": "Facilitates efficient preparation of training data for fine-tuning machine-learning models, minimizing memory usage and simplifying integration into training pipelines.", "keywords": ["lazy loading", "supervised dataset", "fine-tuning", "training data", "machine learning", "data pipeline", "memory efficiency", "indexed access"], "summary_hash": "a6591dc7fc23", "cached_at": "2026-02-08T09:03:48+00:00"}