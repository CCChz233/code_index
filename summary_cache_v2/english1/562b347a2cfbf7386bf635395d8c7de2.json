{"summary": "Encapsulates the output tensors of a multilingual XLM‑Roberta transformer and provides a simple forward helper to process them.", "business_intent": "Facilitate downstream NLP applications by exposing and handling XLM‑Roberta model results for tasks like classification, sequence labeling, or translation.", "keywords": ["XLM-Roberta", "output", "transformer", "multilingual", "forward", "NLP", "model", "representation"], "summary_hash": "76aae6f329b0", "cached_at": "2026-02-09T12:01:17+00:00"}