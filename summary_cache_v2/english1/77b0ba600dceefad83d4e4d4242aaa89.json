{"summary": "Provides a model head that converts token-level embeddings from a BERT encoder into a single fixed‑size vector by averaging the token representations (mean pooling).", "business_intent": "Allows downstream systems to obtain compact sentence embeddings for purposes such as similarity matching, classification, clustering, or other NLP tasks that require a uniform representation of variable‑length inputs.", "keywords": ["mean pooling", "token embeddings", "BERT head", "sentence embedding", "neural network layer", "configuration", "forward pass"], "summary_hash": "dc01592ba5dc", "cached_at": "2026-02-08T10:09:57+00:00"}