{"summary": "Implements a selfâ€‘attention layer specialized for abstract syntax tree (AST) embeddings, handling the core attention computation and score reshaping.", "business_intent": "Enable models to capture contextual relationships within code structures, enhancing applications like code analysis, generation, and security assessment.", "keywords": ["self-attention", "AST", "transformer", "neural network", "code representation", "deep learning"], "summary_hash": "2e736a810498", "cached_at": "2026-02-09T11:06:14+00:00"}