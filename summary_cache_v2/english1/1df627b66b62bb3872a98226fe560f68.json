{"summary": "Encapsulates a pooling operation for BERT-like transformer outputs, converting variable-length token representations into a fixed-size sentence embedding.", "business_intent": "Offers a ready-to-use component for extracting compact vector representations from transformer models, enabling downstream NLP applications such as classification, similarity search, and semantic indexing.", "keywords": ["BERT", "pooling", "transformer", "sentence embedding", "representation", "neural network", "NLP", "feature extraction", "downstream tasks"], "summary_hash": "c5f6a6691fa7", "cached_at": "2026-02-09T06:10:15+00:00"}