{"summary": "Implements a Swin Transformer encoder that transforms input tensors into multi‑scale hierarchical feature representations using shifted‑window self‑attention and patch merging.", "business_intent": "Provide a high‑efficiency visual feature extractor for downstream computer‑vision applications such as image classification, object detection, and semantic segmentation.", "keywords": ["Swin Transformer", "encoder", "vision", "feature extraction", "shifted window attention", "patch merging", "deep learning", "computer vision"], "summary_hash": "62d8dcc68f0f", "cached_at": "2026-02-09T09:32:49+00:00"}