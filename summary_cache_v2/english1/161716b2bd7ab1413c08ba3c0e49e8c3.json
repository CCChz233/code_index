{"summary": "Provides a mixin that equips transformer‑based models with parameter‑efficient fine‑tuning (PEFT) adapter management, including loading, activation, deactivation, and state‑dict handling, along with lightweight helper utilities for wrapping models.", "business_intent": "Enable developers to integrate and control PEFT adapters within sentence‑transformer models, simplifying efficient fine‑tuning workflows and reducing resource consumption.", "keywords": ["PEFT", "adapter", "fine-tuning", "transformer", "mixin", "state dict", "activation", "deactivation", "wrapper"], "summary_hash": "b861e8d379b1", "cached_at": "2026-02-08T13:50:34+00:00"}