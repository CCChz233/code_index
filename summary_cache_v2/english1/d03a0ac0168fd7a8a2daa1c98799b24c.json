{"summary": "Utility module that implements an engine for handling ORC columnar files in Dask DataFrames, offering capabilities to retrieve file metadata, read specific row groups as distributed partitions, and write partitioned data back to ORC format.", "business_intent": "Enable scalable, parallel ingestion and persistence of ORC data within Dask workflows, allowing users to efficiently process large columnar datasets across a cluster.", "keywords": ["ORC", "columnar storage", "Dask DataFrame", "distributed read", "partitioned write", "metadata extraction", "row groups", "parallel I/O", "big data", "engine"], "summary_hash": "fd0ac91e09de", "cached_at": "2026-02-08T23:25:44+00:00"}