{"summary": "This module defines unit tests that validate the prompt caching mechanisms for Anthropic models within the litellm library. It includes mock callbacks and helper utilities to simulate API interactions, checking that cached prompts are reused correctly across various scenarios such as basic calls, custom headers, streaming responses, content string handling, system messages, and tool usage.", "business_intent": "Verify and ensure reliable prompt caching for Anthropic APIs to reduce redundant requests, lower latency, and cut costs in applications that rely on litellm for language model interactions.", "keywords": ["litellm", "Anthropic", "prompt caching", "unit tests", "mock callbacks", "streaming", "custom headers", "system messages", "tool usage", "async HTTP handler"], "summary_hash": "21f2659c91c1", "cached_at": "2026-02-08T07:23:33+00:00"}