{"summary": "Implements a transformer encoder that sequentially applies deformable attention layers to flattened multi‑scale feature maps, producing enriched representations for downstream detection tasks.", "business_intent": "Provide a high‑performance feature encoding component for object detection models that rely on deformable attention mechanisms.", "keywords": ["transformer encoder", "deformable attention", "multi‑scale feature maps", "reference points", "Deformable DETR", "feature encoding", "attention layers"], "summary_hash": "25fe518392dc", "cached_at": "2026-02-09T11:10:15+00:00"}