{"summary": "Defines configuration classes for multiple parameter‑efficient fine‑tuning adapters (LoRA, IA3, prompt‑tuning, canonical, etc.) and maintains mappings between adapter identifiers and their implementations, offering utilities to compute derived dimensions and retrieve target module specifications.", "business_intent": "Enable developers to conveniently configure and apply lightweight adapter‑based fine‑tuning techniques to NeMo NLP models, reducing training cost while adapting models to new tasks.", "keywords": ["PEFT", "parameter-efficient fine-tuning", "adapter configuration", "LoRA", "IA3", "prompt tuning", "canonical adapters", "NLP", "NeMo", "model adaptation"], "summary_hash": "044067017ae1", "cached_at": "2026-02-08T11:19:30+00:00"}