{"summary": "Implements multi‑head attention that incorporates positional embeddings into the query and key tensors before performing scaled dot‑product attention, as described in the DETR model.", "business_intent": "Provide a transformer attention component that captures spatial relationships in visual data, supporting object detection and related computer‑vision tasks.", "keywords": ["multi-head attention", "positional embedding", "DETR", "transformer", "scaled dot-product", "computer vision", "object detection", "query", "key", "value"], "summary_hash": "aef5f0cd97f8", "cached_at": "2026-02-09T09:47:35+00:00"}