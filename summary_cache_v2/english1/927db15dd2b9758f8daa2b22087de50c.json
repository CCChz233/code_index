{"summary": "Provides an iterable dataset that streams tokenized training samples from tarred pickle archives for spellchecking ASR customization, automatically partitioning shards across distributed workers, optionally shuffling samples, and collating batches with padding.", "business_intent": "Enable scalable and efficient training of speech recognition spellchecking models by delivering a token-level dataset that supports distributed loading, sharding, and batch preparation.", "keywords": ["dataset", "tarred files", "tokenized", "pickle", "sharding", "distributed training", "spellchecking", "ASR customization", "shuffle", "padding", "batch collate"], "summary_hash": "9962128e0294", "cached_at": "2026-02-08T09:53:28+00:00"}