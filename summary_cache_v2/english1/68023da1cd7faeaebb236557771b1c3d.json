{"summary": "A Flax module that upsamples 2‑D feature maps, adjusting channel dimensions from a previous block to a new size while optionally applying dropout, stacking attention layers, and inserting a downsampling step before the final output.", "business_intent": "Supply a configurable upsampling building block for neural networks—such as diffusion, generative, or segmentation models—implemented in JAX/Flax, enabling flexible channel scaling, regularization, and attention integration.", "keywords": ["Flax", "2D upsampling", "neural network block", "channel scaling", "dropout", "attention layers", "downsampling", "JAX", "dtype"], "summary_hash": "21188dc901b5", "cached_at": "2026-02-09T04:31:32+00:00"}