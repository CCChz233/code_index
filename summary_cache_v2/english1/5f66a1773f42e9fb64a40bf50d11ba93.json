{"summary": "This module centralizes cost estimation logic for various language model providers. It gathers pricing rules (per token, per character, per query, per second) from OpenAI, Azure, Anthropic, Google, and others, determines the type of API call, extracts usage metrics, and computes the monetary cost of completions, embeddings, image generation, reranking, and other model responses. Helper utilities handle custom pricing, hidden parameters, and usage object creation.", "business_intent": "Provide developers and platform operators with accurate cost calculations for LLM API usage to enable budgeting, billing, and costâ€‘optimization across multiple AI service providers.", "keywords": ["cost calculation", "LLM pricing", "token usage", "character usage", "API call type", "model cost", "provider pricing", "budgeting", "billing", "usage metrics"], "summary_hash": "afc3e3dea451", "cached_at": "2026-02-08T07:14:18+00:00"}