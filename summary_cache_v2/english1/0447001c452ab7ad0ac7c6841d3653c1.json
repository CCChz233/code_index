{"summary": "Encapsulates the tokenized representation of a single data example, storing token IDs, attention mask, segment identifiers, and the associated label.", "business_intent": "Provides a structured format for feeding preprocessed text data into machine learning models, particularly transformerâ€‘based NLP models, to support training and inference.", "keywords": ["token IDs", "attention mask", "segment IDs", "label", "feature container", "NLP preprocessing", "model input"], "summary_hash": "16bffbbbd4d8", "cached_at": "2026-02-08T10:05:24+00:00"}