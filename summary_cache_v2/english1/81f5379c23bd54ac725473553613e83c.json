{"summary": "Defines a collection of data models and utilities for configuring and managing LiteLLM routing, including router settings, deployment metadata, model information, alerting, failure thresholds, retry policies, and standardized error types.", "business_intent": "Provide a flexible, configurable framework for routing LLM API requests across multiple deployments, handling rate limits, retries, alerts, and custom routing logic to ensure reliable and scalable AI service delivery.", "keywords": ["router", "configuration", "deployment", "model metadata", "alerting", "rate limiting", "retry policy", "failure handling", "custom routing strategy", "pydantic", "exception handling", "LiteLLM"], "summary_hash": "9a5acf3870fe", "cached_at": "2026-02-08T07:43:19+00:00"}