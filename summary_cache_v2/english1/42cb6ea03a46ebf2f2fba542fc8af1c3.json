{"summary": "Encapsulates the configuration parameters for an MLP layer used in a mixture‑of‑experts architecture, defining its hyper‑parameters and providing a helper to create the config from a NeMo model checkpoint.", "business_intent": "Enable easy specification, management and loading of MLP layer settings for building and integrating MoE neural network components, especially when importing configurations from NeMo models.", "keywords": ["MLP", "configuration", "Mixture of Experts", "NeMo", "hyperparameters", "model checkpoint", "layer settings", "neural network"], "summary_hash": "63a29ca345c7", "cached_at": "2026-02-08T10:13:09+00:00"}