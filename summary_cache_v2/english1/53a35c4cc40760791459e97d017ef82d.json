{"summary": "The module defines a metric that evaluates the proportion of ground‑truth entities that appear in the retrieved context for each input (or batch). It computes a recall score between 0 and 1, integrating with the RAG evaluation framework to assess context relevance in single‑turn interactions.", "business_intent": "Enable developers and data scientists to quantitatively measure and improve the entity coverage of retrieved documents in retrieval‑augmented generation pipelines, ensuring higher relevance and accuracy of generated answers.", "keywords": ["entity recall", "context relevance", "retrieval evaluation", "RAG metrics", "ground truth entities", "recall score", "NLP evaluation", "single turn sample", "LLM assessment"], "summary_hash": "563f3323f98c", "cached_at": "2026-02-08T22:50:41+00:00"}