{"summary": "This module implements checkpoint input/output utilities for NeMo models using PyTorch Lightning. It provides a custom checkpoint IO class for Megatron models, manages trainer checkpoint creation and metadata, defines a protocol for checkpoint serialization/deserialization, and includes helper functions for device handling and checkpoint path conversion.", "business_intent": "Facilitate reliable saving, loading, and management of large-scale distributed model checkpoints (especially Megatron) within NeMo training pipelines that leverage PyTorch Lightning, ensuring compatibility, proper device placement, and extensible checkpoint metadata.", "keywords": ["checkpoint", "serialization", "Megatron", "PyTorch Lightning", "distributed training", "device handling", "IO protocol", "model persistence", "NeMo", "trainer"], "summary_hash": "a11451ddb5f9", "cached_at": "2026-02-08T10:49:53+00:00"}