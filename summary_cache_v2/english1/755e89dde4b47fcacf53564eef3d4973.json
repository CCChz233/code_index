{"summary": "The module implements the BLEU metric, including n‑gram extraction, modified precision, brevity penalty, and a suite of smoothing techniques, to compute sentence‑level and corpus‑level similarity scores between candidate and reference texts.", "business_intent": "To provide a reliable quantitative measure for assessing the quality of generated code or natural language output by comparing it against reference examples, enabling automated evaluation of translation or code generation systems.", "keywords": ["BLEU", "n-gram", "modified precision", "brevity penalty", "smoothing", "evaluation metric", "code generation", "translation quality", "sentence-level", "corpus-level"], "summary_hash": "50fe3adc8238", "cached_at": "2026-02-08T12:39:32+00:00"}