{"summary": "The module defines a diffusion pipeline class that performs image-to-image generation using the Kandinsky 3 model. It takes an input image and a textual prompt, processes the text with a T5 encoder, prepares latents via a VQ model, runs the UNet denoiser under a scheduler, applies classifier‑free guidance, and decodes the result back to an image. Helper utilities handle image preprocessing and optional resizing.", "business_intent": "Provide a ready‑to‑use component for developers and artists to edit or transform images guided by natural language, facilitating AI‑powered creative workflows, content creation, and prototyping of visual applications.", "keywords": ["diffusion pipeline", "image-to-image", "Kandinsky 3", "text-to-image", "latent diffusion", "classifier-free guidance", "UNet", "VQ‑VAE", "T5 encoder", "scheduler", "PyTorch", "AI art"], "summary_hash": "2667daebde8b", "cached_at": "2026-02-09T05:42:41+00:00"}