{"summary": "The module contains reference scripts that demonstrate distributed multi‑GPU training of graph neural networks with DGL and PyTorch for three common tasks—graph property prediction, node classification, and link prediction—using OGB datasets, neighbor sampling, and PyTorch DistributedDataParallel to achieve scalable performance across multiple GPUs.", "business_intent": "Provide developers and data scientists with ready‑to‑run examples that illustrate how to accelerate GNN workloads on multi‑GPU systems, evaluate scalability, and serve as a template for building production‑grade, high‑throughput graph learning pipelines.", "keywords": ["multi‑GPU", "distributed training", "graph neural networks", "DGL", "PyTorch", "GraphSAGE", "GIN", "OGB datasets", "neighbor sampling", "node classification", "link prediction", "graph property prediction", "scalability"], "summary_hash": "074eba8a4b8e", "cached_at": "2026-02-09T00:55:34+00:00"}