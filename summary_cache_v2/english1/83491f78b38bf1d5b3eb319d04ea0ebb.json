{"summary": "We need to produce JSON with keys: summary, business_intent, keywords (list). Must not list method names verbatim. Focus on class responsibility and state/behavior.\n\nWe have class TypedLinear: linear transformation per type, with optional regularization (basis or block-diagonal). It takes input size, output size, number of types, regularizer, number of bases. It computes weight matrices per type using decomposition. Provides forward that applies appropriate weight to each sample based on its type.\n\nBusiness intent: Provide type-specific linear transformation for relational graph data, enabling parameter sharing via basis or block-diagonal regularization to reduce parameters and improve efficiency.\n\nKeywords: linear transformation, type-specific, basis decomposition, block-diagonal decomposition, regularization, relational data, graph neural networks, weight sharing, PyTorch, DGL.\n\nNow produce JSON.\n\nNeed to ensure no method names verbatim: we can avoid referencing __init__, etc. That's fine.\n\nLet's craft summary: \"Implements a linear layer whose weight matrix is selected according to a categorical type for each input sample, optionally factorizing the per‑type weights using basis or block‑diagonal decomposition to share parameters across types.\"\n\nBusiness intent: \"Enable efficient type‑aware linear mappings in graph neural network models, especially for relational data where different edge or node types require distinct transformations while keeping the parameter count manageable.\"\n\nKeywords list.\n\nNow produce JSON.\n\nMake sure JSON is valid, no extra spaces? It's okay.\n\nLet's output:\n\n{\n  \"summary\": \"...\",\n  \"business_intent\": \"...\",\n  \"keywords\": [...]\n}\n\nLet's craft.\n\nSummary: \"Provides a per‑type linear transformation for batched inputs, selecting a weight matrix based on each sample's type and supporting basis or block‑diagonal factorization to share parameters across types.\"\n\nBusiness intent: \"Facilitates relational graph neural networks by offering type‑specific linear layers that reduce memory and computation through regularized weight decomposition.\"\n\nKeywords: [\"type-specific linear layer\", \"basis decomposition\", \"block-diagonal decomposition\", \"parameter sharing\", \"relational graph neural networks\", \"regularization\", \"weight factorization\", \"PyTorch\", \"DGL\"]\n\nNow output JSON. Ensure no markdown. Use double quotes.\n\nLet's produce final answer.\n{\n  \"summary\": \"Provides a per‑type linear transformation for batched inputs, selecting a weight matrix based on each sample's type and supporting basis or block‑diagonal factorization to share parameters across types.\",\n  \"business_intent\": \"Facilitates relational graph neural networks", "business_intent": "We need to produce JSON with keys: summary, business_intent, keywords (list). Must not list method names verbatim. Focus on class responsibility and state/behavior.\n\nWe have class TypedLinear: linear transformation per type, with optional regularization (basis or block-diagonal). It takes input size, output size, number of types, regularizer, number of bases. It computes weight matrices per type using decomposition. Provides forward that applies appropriate weight to each sample based on its type.\n\nBusiness intent: Provide type-specific linear transformation for relational graph data, enabling parameter sharing via basis or block-diagonal regularization to reduce parameters and improve efficiency.\n\nKeywords: linear transformation, type-specific, basis decomposition, block-diagonal decomposition, regularization, relational data, graph neural networks, weight sharing, PyTorch, DGL.\n\nNow produce JSON.\n\nNeed to ensure no method names verbatim: we can avoid referencing __init__, etc. That's fine.\n\nLet's craft summary: \"Implements a linear layer whose weight matrix is selected according to a categorical type for each input sample, optionally factorizing the per‑type weights using basis or block‑diagonal decomposition to share parameters across types.\"\n\nBusiness intent: \"Enable efficient type‑aware linear mappings in graph neural network models, especially for relational data where different edge or node types require distinct transformations while keeping the parameter count manageable.\"\n\nKeywords list.\n\nNow produce JSON.\n\nMake sure JSON is valid, no extra spaces? It's okay.\n\nLet's output:\n\n{\n  \"summary\": \"...\",\n  \"business_intent\": \"...\",\n  \"keywords\": [...]\n}\n\nLet's craft.\n\nSummary: \"Provides a per‑type linear transformation for batched inputs, selecting a weight matrix based on each sample's type and supporting basis or block‑diagonal factorization to share parameters across types.\"\n\nBusiness intent: \"Facilitates relational graph neural networks by offering type‑specific linear layers that reduce memory and computation through regularized weight decomposition.\"\n\nKeywords: [\"type-specific linear layer\", \"basis decomposition\", \"block-diagonal decomposition\", \"parameter sharing\", \"relational graph neural networks\", \"regularization\", \"weight factorization\", \"PyTorch\", \"DGL\"]\n\nNow output JSON. Ensure no markdown. Use double quotes.\n\nLet's produce final answer.\n{\n  \"summary\": \"Provides a per‑type linear transformation for batched inputs, selecting a weight matrix based on each sample's type and supporting basis or block‑diagonal factorization to share parameters across types.\",\n  \"business_intent\": \"Facilitates relational graph neural networks", "keywords": [], "summary_hash": "8d2edb467aec", "cached_at": "2026-02-08T23:52:35+00:00"}