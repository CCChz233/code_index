{"summary": "Implements a dataset that loads beam hypothesis scores from a file, aligns them with ground‑truth transcripts defined in a manifest, tokenizes the text using a language‑model tokenizer, and returns fixed‑length token sequences for each beam, supporting random indexing and length queries.", "business_intent": "Facilitate evaluation or downstream processing that requires access to beam search outputs and their associated scores together with reference transcripts.", "keywords": ["dataset", "beam scores", "tokenizer", "manifest", "ground truth", "sequence length", "beam size", "data loading", "random access", "evaluation"], "summary_hash": "7de86035f3b5", "cached_at": "2026-02-08T10:23:16+00:00"}