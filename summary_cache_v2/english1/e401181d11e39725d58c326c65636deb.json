{"summary": "Aggregates channel-wise features by applying multi‑head attention across channels and then averaging, yielding a reduced representation with configurable input/output sizes and dropout.", "business_intent": "Offers an attention‑based pooling component for speech processing and other multichannel neural models to capture inter‑channel dependencies and compress feature maps.", "keywords": ["attention pooling", "multi-head attention", "channel aggregation", "feature reduction", "dropout", "speech separation", "speech enhancement", "neural networks"], "summary_hash": "6eec49907edb", "cached_at": "2026-02-08T09:29:06+00:00"}