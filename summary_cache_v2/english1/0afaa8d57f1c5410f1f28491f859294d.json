{"summary": "Container class that encapsulates the results of a Chinese CLIP model, including optional contrastive loss, similarity logits for image‑to‑text and text‑to‑image, projected embeddings for both modalities, and the raw outputs of the underlying text and vision encoders.", "business_intent": "Facilitates downstream multimodal applications such as image‑text retrieval, ranking, and cross‑modal similarity evaluation by providing a structured output that can be directly consumed by evaluation pipelines or further processing steps.", "keywords": ["contrastive loss", "similarity logits", "image embeddings", "text embeddings", "multimodal output", "CLIP", "retrieval", "ranking", "model output container", "tensor"], "summary_hash": "517a1b47f822", "cached_at": "2026-02-09T09:53:41+00:00"}