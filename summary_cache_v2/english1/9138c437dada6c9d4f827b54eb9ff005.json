{"summary": "DistTensor represents a tensor whose rows are partitioned and stored across a cluster of machines. It mirrors the metadata interface of a PyTorch tensor (shape, dtype) while allowing row‑wise slicing and assignment. The first dimension must correspond to the number of nodes or edges in a distributed graph, and the class automatically selects or accepts a partition policy to shard the data. Tensors can be named for reuse, optionally made persistent beyond the Python object’s lifetime, and initialized with a user‑provided function. Creation is synchronized across all trainer processes.", "business_intent": "Provide a scalable, distributed storage abstraction for node and edge feature matrices in large‑scale graph neural network training, enabling efficient parallel access, updates, and persistence across multiple compute nodes.", "keywords": ["distributed tensor", "sharding", "partition policy", "node features", "edge features", "persistent storage", "initialization function", "row slicing", "row assignment", "kvstore", "DGL", "graph neural networks", "cluster"], "summary_hash": "f2810339a8ff", "cached_at": "2026-02-08T23:41:36+00:00"}