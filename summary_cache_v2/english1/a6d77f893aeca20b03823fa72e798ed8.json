{"summary": "Configuration class that encapsulates all architectural hyperparameters for the vision encoder of an AltCLIP model, such as hidden dimensions, number of layers, attention heads, image and patch sizes, activation functions, and initialization settings.", "business_intent": "Allows developers to define or modify the vision transformer architecture when creating or loading an AltCLIP model, facilitating reproducible experiments and seamless integration with pretrained weights.", "keywords": ["vision transformer", "AltCLIP", "model configuration", "hidden size", "attention heads", "image size", "patch size", "projection dimension", "initialization", "dropout", "activation", "layer normalization"], "summary_hash": "2c05592c2745", "cached_at": "2026-02-09T11:24:58+00:00"}