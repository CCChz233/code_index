{"summary": "Container class that aggregates the outputs of the AltCLIP multimodal model, including optional contrastive loss, similarity logits for image‑to‑text and text‑to‑image, projected embeddings for both modalities, and the raw outputs of the underlying text and vision encoders.", "business_intent": "Facilitate training and inference for applications such as image‑text retrieval, cross‑modal ranking, and multimodal representation learning by providing a unified structure for loss computation, similarity scoring, and embedding extraction.", "keywords": ["contrastive loss", "image‑text similarity", "logits", "embeddings", "multimodal", "retrieval", "ranking", "representation learning", "AltCLIP"], "summary_hash": "f60783e38e8f", "cached_at": "2026-02-09T11:23:50+00:00"}