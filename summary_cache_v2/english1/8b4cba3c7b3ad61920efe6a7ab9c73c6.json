{"summary": "Implements the decoder component of a Transformer architecture, converting encoded source representations into target token sequences using multi‑head attention and feed‑forward layers, with optional shared embeddings.", "business_intent": "Provides the core functionality for machine translation or other sequence‑to‑sequence generation services.", "keywords": ["Transformer", "decoder", "sequence-to-sequence", "translation", "shared embedding", "attention", "neural network", "config", "inference"], "summary_hash": "434b3135c1f5", "cached_at": "2026-02-09T11:54:26+00:00"}