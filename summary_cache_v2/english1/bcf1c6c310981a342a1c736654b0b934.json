{"summary": "The module supplies dataset classes that load, tokenize, and batch grapheme‑to‑phoneme (G2P) training data for various model types (CTC, classification, and T5 seq2seq) used in the NeMo text‑to‑speech collection.", "business_intent": "To facilitate the development and evaluation of accurate G2P models for TTS systems, enabling better pronunciation handling—including heteronyms—and supporting different neural architectures.", "keywords": ["grapheme-to-phoneme", "dataset", "tokenization", "CTC", "T5", "heteronym classification", "NeMo", "text-to-speech", "PyTorch", "batching"], "summary_hash": "4bc8d4e39a05", "cached_at": "2026-02-08T12:02:24+00:00"}