{"summary": "Container class that aggregates all outputs produced by the LXMERT pre‑training model, including optional loss, language modeling logits, cross‑modal relationship scores, question‑answering logits, and optionally hidden states and attention tensors for language, vision, and cross‑encoder layers.", "business_intent": "Facilitate training, evaluation, and analysis of multimodal language‑vision models by providing a structured representation of loss and prediction scores for tasks such as masked language modeling, next‑sentence prediction, and visual question answering, while optionally exposing internal representations for debugging or downstream processing.", "keywords": ["loss", "prediction logits", "cross relationship score", "question answering score", "hidden states", "attentions", "language", "vision", "multimodal", "pretraining", "TensorFlow"], "summary_hash": "f470194d71d2", "cached_at": "2026-02-09T09:27:47+00:00"}