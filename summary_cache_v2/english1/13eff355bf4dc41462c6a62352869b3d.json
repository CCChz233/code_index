{"summary": "Utility module that provides functions for counting tokens and handling adjusted maximum token limits for language model requests.", "business_intent": "Enable applications to respect model token constraints by calculating token usage and dynamically adjusting the allowed token count for LLM API calls.", "keywords": ["token counting", "max tokens", "LLM", "language model", "utility", "token limit", "litellm"], "summary_hash": "c8e574137827", "cached_at": "2026-02-08T07:45:57+00:00"}