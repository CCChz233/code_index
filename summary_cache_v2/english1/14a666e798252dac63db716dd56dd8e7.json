{"summary": "This module implements the integration with Cohere's text generation service for the Litellm library. It defines a configuration object that maps all supported Cohere parameters (such as token limits, sampling settings, stop sequences, and biasing) to a unified schema, provides a custom exception type for Cohere‑specific errors, and contains the logic to construct, send, and process completion requests (including async handling, response parsing, usage statistics, and tool construction).", "business_intent": "Allow applications to invoke Cohere's language models through a standardized Litellm interface, simplifying model selection, request customization, error management, and result handling for developers building AI‑powered features.", "keywords": ["Cohere", "text generation", "completion API", "configuration", "parameter mapping", "error handling", "async HTTP", "model response", "usage tracking", "token limits", "sampling", "stop sequences", "biasing", "Litellm integration"], "summary_hash": "f0df3552dab0", "cached_at": "2026-02-08T07:55:24+00:00"}