{"summary": "Container for the LXMERT model's multimodal outputs, encapsulating the final hidden representations of the language and visual encoders, a pooled classification vector, and optional hidden states and attention tensors for each encoder and cross-modality layers.", "business_intent": "Enable downstream applications to retrieve and manipulate language, vision, and cross-modal features produced by LXMERT for tasks such as visual question answering, image captioning, and multimodal reasoning.", "keywords": ["LXMERT", "multimodal", "language encoder", "visual encoder", "cross-modality", "hidden states", "pooled output", "attention weights", "TensorFlow", "sequence representations"], "summary_hash": "6c156e56a3f7", "cached_at": "2026-02-09T09:27:43+00:00"}