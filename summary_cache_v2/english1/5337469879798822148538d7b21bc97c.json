{"summary": "Provides a command‑line entry point for configuring, training, and fine‑tuning a NeMo RNNT speech‑to‑text model that uses a BPE or word‑piece tokenizer. It includes instructions for preparing the tokenizer, setting dataset manifests, and specifying training hyper‑parameters via Hydra configuration.", "business_intent": "Enable users to build and improve automatic speech recognition systems based on the RNNT architecture with subword tokenization, facilitating model training and experimentation at scale.", "keywords": ["ASR", "RNNT", "BPE tokenizer", "speech-to-text", "NeMo", "Hydra", "PyTorch Lightning", "model training", "fine-tuning", "audio transcription"], "summary_hash": "b05e64537774", "cached_at": "2026-02-08T10:39:33+00:00"}