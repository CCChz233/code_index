{"summary": "The module defines a VisualEncDecHybridRNNTCTCBPEModel class that builds a multimodal speech‑to‑text system combining a visual encoder‑decoder with a recurrent neural network transducer (RNNT) and an auxiliary CTC branch, using byte‑pair‑encoding subword units. It integrates data loading utilities, transcription preparation, decoding configuration, vocabulary management, and model discovery, leveraging NeMo components for loss computation, metric evaluation, and training.", "business_intent": "Enable developers to create advanced speech‑to‑text solutions that incorporate visual cues (e.g., lip movements) and benefit from both RNNT and CTC decoding strategies. This supports applications such as video captioning, assistive communication tools, and multimodal AI services that require accurate transcription from video streams.", "keywords": ["RNNT", "CTC", "BPE tokenization", "visual encoder‑decoder", "multimodal speech recognition", "lip‑reading", "video transcription", "NeMo", "PyTorch Lightning", "loss computation", "decoding strategies", "vocabulary management", "pretrained model"], "summary_hash": "a4d466a8d30e", "cached_at": "2026-02-08T12:02:44+00:00"}