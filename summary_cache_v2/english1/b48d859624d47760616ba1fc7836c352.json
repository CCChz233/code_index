{"summary": "Implements a distributed sampler that partitions dataset indices among multiple workers, optionally sorting them for better data locality, and supports epochâ€‘wise shuffling and iteration.", "business_intent": "Enable scalable, reproducible training of machine learning models by providing each distributed process a distinct, efficiently ordered subset of data for loading.", "keywords": ["distributed sampling", "data loader", "epoch", "shuffling", "indices", "parallel training", "sortish", "torch", "sampler"], "summary_hash": "410312a6274f", "cached_at": "2026-02-09T06:04:55+00:00"}