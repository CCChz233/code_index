{"summary": "A convolutional neural network layer designed to integrate Low-Rank Adaptation (LoRA) adapters, allowing the layer's weights to be dynamically merged with or separated from LoRA parameters for efficient fine‑tuning and inference.", "business_intent": "Enable developers to incorporate parameter‑efficient LoRA fine‑tuning into convolutional models, providing a plug‑and‑play component that can toggle LoRA adapters on or off without altering the core architecture.", "keywords": ["convolution", "LoRA", "low-rank adaptation", "neural network layer", "weight fusion", "adapter", "parameter-efficient fine-tuning", "modular layer"], "summary_hash": "f79e84f4b264", "cached_at": "2026-02-09T04:00:48+00:00"}