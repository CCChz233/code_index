{"summary": "...", "business_intent": "...", "keywords": ["TensorFlow", "RoBERTa", "masked language modeling", "preâ€‘layer normalization", "language model head", "NLP", "transformer", "model building", "inference", "training"], "summary_hash": "d96cc4578746", "cached_at": "2026-02-09T09:09:26+00:00"}