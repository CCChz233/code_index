{"summary": "The module supplies a collection of reusable PyTorch components for building recurrent neural networks, including LSTM layers with dropout, layer‑norm LSTM cells, optional batch‑norm wrappers, time‑step stacking, and utilities for initializing stacked LSTMs and collating labeled data.", "business_intent": "To streamline the creation of robust, high‑performance RNN architectures for speech and audio applications within the NeMo ecosystem, improving training stability and model flexibility.", "keywords": ["recurrent neural network", "LSTM", "layer normalization", "batch normalization", "dropout", "time stacking", "PyTorch", "NeMo", "sequence modeling", "audio processing"], "summary_hash": "db358ed591de", "cached_at": "2026-02-08T10:51:52+00:00"}