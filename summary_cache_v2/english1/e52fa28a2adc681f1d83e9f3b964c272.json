{"summary": "Implements a recurrent neural network layer using Long Short-Term Memory cells, providing initialization and a forward method to process sequential input tensors.", "business_intent": "Facilitate sequence‑based learning in models such as language models, time‑series predictors, or any task requiring temporal context retention.", "keywords": ["LSTM", "recurrent layer", "sequence modeling", "forward propagation", "neural network", "temporal dependencies", "hidden state"], "summary_hash": "18e9402c1370", "cached_at": "2026-02-08T08:25:09+00:00"}