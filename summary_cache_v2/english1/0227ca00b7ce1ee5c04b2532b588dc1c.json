{"summary": "Provides a pretrained MPT transformer model adapted for token-level classification tasks, managing input encoding, model inference, and output label mapping.", "business_intent": "Allows businesses to apply state-of-the-art language models for sequence labeling applications such as named entity recognition, part-of-speech tagging, or any token-wise prediction need.", "keywords": ["MPT", "token classification", "transformer", "pretrained model", "NLP", "sequence labeling", "fine-tuning"], "summary_hash": "6b9574f1bffc", "cached_at": "2026-02-09T07:14:35+00:00"}