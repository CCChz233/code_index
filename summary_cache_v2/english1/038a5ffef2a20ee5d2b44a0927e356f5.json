{"summary": "Encapsulates the outputs of a vision transformer model, including the sequence of hidden states, optional per‑layer hidden states and attention matrices, and optionally a pooled image embedding produced by a projection layer.", "business_intent": "Supply a unified, easy‑to‑consume data structure for downstream vision tasks such as classification, retrieval, or multimodal processing, while optionally providing a compact image representation for similarity or indexing purposes.", "keywords": ["vision model output", "image embeddings", "last hidden state", "hidden states", "attention weights", "projection layer", "torch tensor", "transformer"], "summary_hash": "ef34332c7a0b", "cached_at": "2026-02-09T08:29:26+00:00"}