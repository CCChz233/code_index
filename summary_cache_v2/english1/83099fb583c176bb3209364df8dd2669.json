{"summary": "Implements a handler for Azure OpenAI's realtime `/openai/realtime` endpoint, constructing service URLs and managing asynchronous websocket communication to stream chat interactions through the LiteLLM proxy.", "business_intent": "Provide developers with a seamless way to integrate Azure OpenAI's real‑time streaming capabilities into applications, enabling low‑latency conversational AI via the LiteLLM infrastructure.", "keywords": ["Azure OpenAI", "realtime API", "websockets", "asynchronous streaming", "LiteLLM proxy", "chat completion", "endpoint construction"], "summary_hash": "9987afef46d1", "cached_at": "2026-02-08T08:00:08+00:00"}