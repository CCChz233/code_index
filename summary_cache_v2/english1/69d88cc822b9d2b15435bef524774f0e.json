{"summary": "Encapsulates the configuration and selection of various TorchDynamo backends, enabling switching between eager execution, AOT, TorchInductor, nvFuser, cudagraphs, TorchScript, TensorRT, ONNX Runtime, XLA, IPEX, TVM, and related strategies for debugging, training, or inference.", "business_intent": "Offer a unified interface to manage and apply different PyTorch compilation and optimization strategies, simplifying performance tuning and deployment across multiple hardware backends.", "keywords": ["torch dynamo", "backend selection", "compilation", "optimization", "eager execution", "AOT", "TorchInductor", "nvFuser", "cudagraphs", "TorchScript", "TensorRT", "ONNX Runtime", "XLA", "IPEX", "TVM", "training", "inference", "performance tuning"], "summary_hash": "fbbbf5af8aa2", "cached_at": "2026-02-09T02:12:00+00:00"}