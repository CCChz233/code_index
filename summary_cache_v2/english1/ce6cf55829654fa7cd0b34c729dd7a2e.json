{"summary": "Encapsulates the outputs of a TensorFlow Swin Transformer model, bundling the final hidden sequence, an optional pooled representation, optional per‑layer hidden states, attention matrices, and spatially reshaped hidden states for downstream processing.", "business_intent": "Standardize and simplify access to all relevant Swin model tensors—such as sequence embeddings, pooled vectors, layer‑wise activations, and attention weights—so that downstream applications (e.g., classification, detection, or feature extraction) can consume them consistently.", "keywords": ["Swin Transformer", "TensorFlow", "model output", "hidden states", "pooler output", "attention weights", "reshaped hidden states", "sequence embedding", "feature extraction"], "summary_hash": "93bc505e130a", "cached_at": "2026-02-09T09:31:55+00:00"}