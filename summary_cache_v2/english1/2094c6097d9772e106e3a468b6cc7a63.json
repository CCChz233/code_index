{"summary": "A dataset wrapper that converts raw dialogue turns into BERT‑compatible inputs, handling tokenization, sub‑word alignment, and feature generation while allowing users to select which annotation types (intent, slot, or both) are included.", "business_intent": "Provide a reusable preprocessing layer for training and evaluating BERT models on conversational data, supporting flexible labeling schemes and consistent feature extraction across different data sources.", "keywords": ["BERT", "tokenization", "subword mapping", "dialogue dataset", "intent classification", "slot filling", "feature extraction", "preprocessing", "configurable labels"], "summary_hash": "8bd4ba2a2247", "cached_at": "2026-02-08T10:05:01+00:00"}