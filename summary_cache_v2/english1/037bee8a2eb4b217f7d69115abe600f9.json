{"summary": "Implements the MixHop graph neural network layer with multi‑hop neighbor mixing, optional dropout, batch normalization, and activation, and provides a command‑line training and evaluation pipeline for full‑graph citation datasets (Cora, Citeseer, Pubmed) using PyTorch and DGL.", "business_intent": "Offer a ready‑to‑run reference implementation for researchers and developers to experiment with the MixHop architecture, benchmark its performance on standard citation networks, and serve as a template for building and tuning higher‑order GNN models.", "keywords": ["graph neural network", "MixHop", "multi‑hop aggregation", "DGL", "PyTorch", "citation datasets", "node classification", "dropout", "batch normalization", "training script"], "summary_hash": "b81cd69a8995", "cached_at": "2026-02-09T00:54:10+00:00"}