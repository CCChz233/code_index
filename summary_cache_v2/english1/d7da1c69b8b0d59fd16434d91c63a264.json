{"summary": "A configuration container that encapsulates all architectural and training hyper‑parameters required to build an Informer time‑series forecasting transformer. It holds settings for prediction horizon, encoder context, output distribution, loss type, input scaling, lag indices, counts of static and dynamic features, embedding sizes, model dimensions, layer counts, attention heads, feed‑forward sizes, activation functions, various dropout rates, parallel sampling, weight initialization, caching, attention mechanism choice, ProbSparse sampling factor, and optional encoder distillation.", "business_intent": "Allow developers and data scientists to precisely define and reuse the structure of an Informer forecasting model so it can be instantiated consistently across experiments, datasets, and production pipelines, thereby streamlining model setup and reproducibility for forecasting applications.", "keywords": ["time series forecasting", "transformer configuration", "hyper‑parameter management", "prediction horizon", "attention mechanism", "feature embedding", "scaling", "dropout", "parallel sampling", "model initialization"], "summary_hash": "03570923a634", "cached_at": "2026-02-09T10:39:08+00:00"}