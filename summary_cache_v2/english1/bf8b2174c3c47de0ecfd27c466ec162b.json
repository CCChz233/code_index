{"summary": "The RNNTDecoder class implements a stateful LSTM-based decoder for Recurrent Neural Network Transducer (RNN‑T) models. It handles embedding of input tokens, optional layer normalization, dropout, and specialized initializations (forget‑gate bias, chrono initialization, random state sampling). The decoder maintains hidden states across time steps, supports batch‑wise state manipulation, hypothesis scoring, and token prediction. It also integrates adapter mechanisms for flexibility and exportability.", "business_intent": "Enable efficient training and inference of RNN‑T based speech‑recognition systems by providing a robust, configurable decoder that can manage stateful predictions and support batched beam‑search decoding.", "keywords": ["RNN‑T", "decoder", "prediction", "LSTM", "stateful", "embedding", "layer normalization", "dropout", "chrono", "self‑supervised", "speech", "recognition"], "summary_hash": "1841a38fcb2d", "cached_at": "2026-02-08T11:08:16+00:00"}