{"summary": "Provides a unified streaming response handler that abstracts over different AI model providers, normalizes output chunks, applies safety and logging, and offers both synchronous and asynchronous iteration interfaces.", "business_intent": "Standardize and simplify consumption of streaming AI model outputs while ensuring safety, observability, and compatibility across multiple providers.", "keywords": ["streaming", "AI model integration", "response normalization", "async iterator", "sync iterator", "safety checks", "logging", "caching", "provider abstraction", "error handling"], "summary_hash": "34012630fb97", "cached_at": "2026-02-08T07:46:10+00:00"}