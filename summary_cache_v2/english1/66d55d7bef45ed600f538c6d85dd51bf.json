{"summary": "A GPT‑2 based transformer model that integrates two distinct output heads: a causal language modeling head for text generation and a classification head (e.g., multiple‑choice) for discriminative tasks, sharing the same underlying transformer backbone.", "business_intent": "Enable a single pretrained model to serve both generative and decision‑making use cases, such as chatbots that produce replies while selecting the most appropriate response, or QA systems that generate answers and rank candidate options.", "keywords": ["GPT-2", "transformer", "double heads", "language modeling", "classification", "multiple-choice", "pretrained", "neural network"], "summary_hash": "1a50454e09d0", "cached_at": "2026-02-09T07:05:24+00:00"}