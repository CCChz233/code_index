{"summary": "The module implements data preparation utilities for the English Google Text Normalization corpus. It offers a preprocessing pipeline that cleans and normalizes raw sentences—verbalizing long numbers digit‑by‑digit, standardizing fractions, removing non‑English characters, simplifying URL tokens, and preserving specific class types—to generate a clean training split. Additionally, it provides a balancing routine that detects under‑represented entity classes, extracts matching sentences from auxiliary processed files, and up‑samples them to produce a more evenly distributed training set for downstream normalization models.", "business_intent": "Enable developers to create high‑quality, balanced training data for English text‑normalization systems, thereby improving model accuracy and robustness in speech‑to‑text and text‑to‑speech applications.", "keywords": ["text normalization", "preprocessing", "upsampling", "dataset balancing", "English", "Google Text Normalization", "digit verbalization", "fraction handling", "NLP", "training data preparation"], "summary_hash": "d5929bd103d1", "cached_at": "2026-02-08T11:59:44+00:00"}