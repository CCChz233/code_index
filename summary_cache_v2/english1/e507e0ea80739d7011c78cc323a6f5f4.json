{"summary": "Manages an ensemble of models to generate token sequences using beam search, handling encoder states, probability averaging, length penalties, and stepwise decoding.", "business_intent": "Provide high‑quality text generation (e.g., translation, summarization, captioning) by leveraging multiple models in a beam‑search inference pipeline.", "keywords": ["ensemble", "beam search", "sequence generation", "language model", "encoder", "decoder", "probability averaging", "length penalty", "model freezing", "inference"], "summary_hash": "c26bc8077290", "cached_at": "2026-02-08T09:37:01+00:00"}