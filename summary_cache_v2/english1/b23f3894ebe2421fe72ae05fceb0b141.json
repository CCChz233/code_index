{"summary": "Provides a dataset implementation that converts raw question‑answer pairs and their source passages into tokenized inputs tailored for GPT‑style generative question answering models, handling context concatenation, query‑answer construction, feature caching, and label masking to support both training and inference pipelines.", "business_intent": "Facilitate efficient preparation and loading of data for training and deploying generative QA systems, enabling scalable model development and inference in natural language processing applications.", "keywords": ["generative QA", "GPT", "dataset", "tokenization", "context encoding", "answer masking", "caching", "training", "inference", "NLP"], "summary_hash": "eac73a359621", "cached_at": "2026-02-08T12:10:17+00:00"}