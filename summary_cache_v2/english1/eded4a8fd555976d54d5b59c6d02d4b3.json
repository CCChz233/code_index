{"summary": "A distributed data loader that mimics PyTorch’s DataLoader but leverages DGL’s pre‑started worker processes to sample graph neighborhoods and produce mini‑batches in parallel across multiple machines.", "business_intent": "Facilitate large‑scale graph neural network training by providing an efficient, multiprocessing‑based pipeline for loading and sampling node or edge IDs from a distributed graph.", "keywords": ["distributed", "data loading", "graph sampling", "mini-batch", "multiprocessing", "DGL", "iterator", "parallel processing", "RPC", "shuffle"], "summary_hash": "4f72b1c5a5a2", "cached_at": "2026-02-08T23:43:36+00:00"}