{"summary": "A TensorFlow data container that encapsulates the primary outputs of a transformer model, including the final hidden states and optional cached attention key/value tensors, as well as auxiliary hidden states and attention maps when requested.", "business_intent": "Enable downstream applications to retrieve model predictions efficiently, especially for autoregressive generation where cached past key/value tensors accelerate sequential decoding.", "keywords": ["TensorFlow", "transformer", "model output", "past key values", "caching", "sequential decoding", "hidden states", "attention weights"], "summary_hash": "2a5f9a9521ab", "cached_at": "2026-02-09T06:30:42+00:00"}