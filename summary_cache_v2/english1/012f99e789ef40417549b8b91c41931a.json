{"summary": "A callback that automatically persists model states during training, creating checkpoint files in a configurable directory with customizable naming, and selecting which checkpoints to keep based on a monitored metric, frequency rules, and top‑k criteria. It tracks the best checkpoint, supports saving only weights, linking the latest checkpoint, and integrates with the trainer lifecycle.", "business_intent": "Provide robust, configurable model checkpointing to enable model versioning, early‑stop selection, training resumption, and storage management for deep‑learning workflows.", "keywords": ["checkpoint", "model persistence", "metric monitoring", "top‑k selection", "filename templating", "training callback", "PyTorch Lightning", "resume training", "storage management"], "summary_hash": "36174400de49", "cached_at": "2026-02-08T08:14:20+00:00"}