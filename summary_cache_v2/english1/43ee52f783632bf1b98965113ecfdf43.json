{"summary": "This module implements asynchronous background tasks that coordinate the execution of evaluation scenarios for language model applications. It retrieves application configurations, prepares inputs, triggers deployments, runs evaluator logic, records individual scenario outcomes, aggregates metrics, and updates the evaluation records in the database.", "business_intent": "Enable automated, scalable assessment of LLM app performance by running predefined test scenarios, calculating evaluation scores, and storing aggregated results for monitoring and improvement.", "keywords": ["evaluation", "aggregation", "asynchronous task", "celery", "LLM", "deployment", "scenario", "metrics", "database", "result storage"], "summary_hash": "5aeceaf50076", "cached_at": "2026-02-08T05:23:49+00:00"}