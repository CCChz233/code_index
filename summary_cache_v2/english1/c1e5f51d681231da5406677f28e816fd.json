{"summary": "Container for the results produced by a multimodal LXMERT pre‑training model, encapsulating the overall loss and the various prediction tensors for language modeling, textual‑visual matching, and question answering, together with optional hidden states and attention maps for language, vision, and cross‑modal encoder layers.", "business_intent": "Enable downstream applications to access and analyze the model's training signals and internal representations for tasks such as masked language modeling, next‑sentence prediction, visual‑language alignment, and QA, facilitating further fine‑tuning or evaluation.", "keywords": ["loss", "prediction logits", "cross relationship score", "question answering score", "hidden states", "attention maps", "language", "vision", "cross‑modal encoder", "multimodal pretraining", "transformer"], "summary_hash": "4e926bbe04d5", "cached_at": "2026-02-09T09:29:02+00:00"}