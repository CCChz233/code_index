{"summary": "A data structure that encapsulates the results of a wav2vec 2.0 pre‑training forward pass, including optional total loss, contrastive and diversity loss components, projected feature vectors, quantized targets, and optionally the full hidden‑state and attention tensors for each layer.", "business_intent": "Enable downstream code to retrieve training signals and intermediate representations from wav2vec 2.0 pre‑training, facilitating loss aggregation, model diagnostics, and further processing of speech embeddings.", "keywords": ["wav2vec2", "pretraining", "output container", "loss", "contrastive loss", "diversity loss", "projected states", "quantized states", "hidden states", "attentions", "speech representation"], "summary_hash": "b5d5ac37923c", "cached_at": "2026-02-09T10:25:19+00:00"}