{"summary": "The module implements a collection of PyTorch neural layers that perform graph-level readout operations. It offers simple aggregations such as average, max, sum, and sort‑based pooling, as well as more sophisticated mechanisms like attention‑weighted pooling, multi‑head attention, Set2Set, and full Set Transformer encoders/decoders. All layers accept single or batched DGL graphs, transform variable‑size node feature sets into fixed‑dimensional graph representations, and can be integrated into graph neural network pipelines.", "business_intent": "Provide ready‑to‑use global pooling components for graph neural networks, enabling developers to extract concise graph embeddings for downstream tasks such as classification, regression, or similarity measurement in applications ranging from chemistry to social network analysis.", "keywords": ["graph neural network", "global pooling", "readout", "attention", "set transformer", "PyTorch", "DGL", "graph embedding", "batch processing", "aggregation"], "summary_hash": "dc006a159616", "cached_at": "2026-02-09T00:42:41+00:00"}