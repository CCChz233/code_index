{"summary": "The module defines an abstract base and a concrete client for interacting with a Triton inference server to perform large language model text generation, supporting both batch and streaming query modes.", "business_intent": "Provide a reusable interface that allows downstream NLP applications to generate text from deployed LLMs via Triton, simplifying integration of highâ€‘performance language model inference into production systems.", "keywords": ["large language model", "LLM", "text generation", "Triton inference server", "batch query", "streaming query", "client interface", "NLP", "numpy", "abstract base class"], "summary_hash": "c830bb967c70", "cached_at": "2026-02-08T11:38:54+00:00"}