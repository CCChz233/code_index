{"summary": "Provides a command‑line entry point that configures and launches training or fine‑tuning of a K2‑based RNNT speech‑to‑text model using BPE or word‑piece tokenization, leveraging NeMo, Hydra, and PyTorch Lightning for distributed GPU execution.", "business_intent": "Allow developers and researchers to build, train, and fine‑tune high‑accuracy automatic speech recognition models with subword tokenizers for deployment in voice‑enabled products.", "keywords": ["ASR", "RNNT", "BPE", "K2", "NeMo", "training", "tokenizer", "Hydra", "PyTorch Lightning", "distributed training", "fine‑tuning"], "summary_hash": "726746f17087", "cached_at": "2026-02-08T10:40:45+00:00"}