{"summary": "Implements a GPT‑2 style transformer block customized for decision‑transformer models, encapsulating the attention and feed‑forward operations required during the forward pass.", "business_intent": "Offer a reusable neural network component that supports sequence‑based decision making in reinforcement learning systems by providing the core computation of a decision transformer block.", "keywords": ["transformer block", "GPT-2", "decision transformer", "reinforcement learning", "sequence modeling", "neural network module", "attention", "feed‑forward", "forward pass"], "summary_hash": "a7adc57c407b", "cached_at": "2026-02-09T08:45:09+00:00"}