{"summary": "A Conformer‑based model that extracts separate linguistic content and speaker identity embeddings from raw audio by fine‑tuning a pre‑trained self‑supervised network with added downstream heads in a multi‑task setup for speech recognition and speaker verification. The disentangled embeddings can be swapped to enable voice conversion via FastPitch.", "business_intent": "Enable applications that need distinct content and speaker representations, such as voice conversion, speaker verification, and automatic speech recognition, by providing a modular embedding extractor.", "keywords": ["Conformer", "self‑supervised learning", "content embedding", "speaker embedding", "disentanglement", "multi‑task learning", "speech recognition", "speaker verification", "voice conversion", "FastPitch", "audio waveform", "downstream heads", "fine‑tuning"], "summary_hash": "5488c96753f1", "cached_at": "2026-02-08T08:44:41+00:00"}