{"summary": "Encapsulates a selectable activation layer that applies a chosen function (ELU, Leaky ReLU, or Snake) to tensors of a specified channel dimension.", "business_intent": "Enable configurable activation behavior in neural network models, allowing easy switching of activation types without altering model architecture.", "keywords": ["activation", "ELU", "Leaky ReLU", "Snake", "neural network", "configurable layer", "channels", "forward pass"], "summary_hash": "95c4519cfa29", "cached_at": "2026-02-08T08:37:12+00:00"}