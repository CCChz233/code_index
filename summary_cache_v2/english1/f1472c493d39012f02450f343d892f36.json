{"summary": "Implements a neural network layer that replaces self‑attention with a Fourier‑transform based feed‑forward operation, processing inputs in chunks for efficiency.", "business_intent": "Provide a fast, memory‑efficient alternative to attention layers for sequence modeling tasks such as natural language processing.", "keywords": ["FNet", "Fourier transform", "neural network layer", "feed forward", "sequence modeling", "attention alternative", "deep learning"], "summary_hash": "8e2aa5a03032", "cached_at": "2026-02-09T10:19:52+00:00"}