{"summary": "Provides benchmarking utilities to measure the performance of merged attention operations, including forward and backward passes, using PyTorch and xformers FMHA kernels.", "business_intent": "Enable developers to evaluate and optimize the efficiency of attention merging implementations for highâ€‘performance deep learning models.", "keywords": ["benchmark", "attention", "merge", "performance", "PyTorch", "xformers", "FMHA", "CUDA", "backward pass"], "summary_hash": "4fec962d4b76", "cached_at": "2026-02-08T23:28:15+00:00"}