{"summary": "A configuration container for the Kosmos‑2 text decoder that stores all architectural hyper‑parameters such as vocabulary size, maximum positions, embedding dimension, number of transformer layers, feed‑forward size, attention heads, activation functions, dropout rates, layer‑norm epsilon, initialization scale and caching options. It inherits from the generic PretrainedConfig, enabling serialization, loading from pretrained checkpoints, and direct use when instantiating the decoder model.", "business_intent": "Enable developers and researchers to define, adjust, and reuse the structural settings of a Kosmos‑2 text model, facilitating reproducible experiments, fine‑tuning, and deployment of the decoder in various natural‑language processing tasks.", "keywords": ["configuration", "transformer", "text decoder", "hyper‑parameters", "vocab size", "embedding dimension", "attention heads", "dropout", "layer normalization", "pretrained model"], "summary_hash": "43e5c6ac651e", "cached_at": "2026-02-09T10:42:56+00:00"}