{"summary": "A structured output container for a multimodal vision-language model that returns image-text similarity scores, optional language modeling loss, projected image embeddings, token hidden states, vision pooler output, attention maps, and question embeddings.", "business_intent": "Enable downstream applications such as image-text retrieval, visual question answering, and cross-modal ranking by providing all necessary tensors from the model in a single, easy-to-consume object.", "keywords": ["image-text similarity", "loss", "image embeddings", "hidden states", "attention weights", "vision pooler", "question embeddings", "multimodal output", "BLIP", "cross-modal retrieval"], "summary_hash": "ebade2626be2", "cached_at": "2026-02-09T10:08:14+00:00"}