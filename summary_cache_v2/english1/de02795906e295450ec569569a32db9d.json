{"summary": "Encapsulates the outputs produced by a Longformer question‑answering model, including optional loss, start‑position and end‑position logits for answer spans, and optionally the hidden states and attention tensors for each layer.", "business_intent": "Provides a structured container that downstream applications can use to compute training loss, predict answer spans, and inspect model internals such as hidden representations and attention patterns for Longformer‑based QA systems.", "keywords": ["Longformer", "question answering", "model output", "start logits", "end logits", "loss", "hidden states", "attentions", "global attentions", "span extraction"], "summary_hash": "00dcf22608d3", "cached_at": "2026-02-09T11:13:09+00:00"}