{"summary": "A model class that leverages a Vision-and-Language Transformer to perform token-level classification tasks, mapping each input token to a label based on multimodal visual and textual context.", "business_intent": "Provide a ready-to-use, fineâ€‘tunable component for applications that need to label tokens (e.g., named entities, parts of speech) in data that combines images and text, such as document understanding, image caption analysis, or visual question answering.", "keywords": ["Vilt", "token classification", "multimodal", "vision-language transformer", "pretrained model", "fine-tuning", "entity extraction", "document understanding"], "summary_hash": "37f431ef98c1", "cached_at": "2026-02-09T07:29:31+00:00"}