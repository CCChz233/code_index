{"summary": "Implements a Graph Attention Network v2 layer using DGL's GATv2Conv with sparse‑matrix‑vector multiplication optimization, enabling attention‑based feature aggregation for nodes in a graph.", "business_intent": "Provides an example implementation to help developers and researchers quickly apply and benchmark GATv2 models on graph‑structured data within the PyTorch/DGL ecosystem.", "keywords": ["GATv2", "graph neural network", "DGL", "PyTorch", "attention mechanism", "sparse matrix multiplication", "node feature aggregation", "graph representation learning"], "summary_hash": "8a7ac5a4a9ff", "cached_at": "2026-02-09T00:19:37+00:00"}