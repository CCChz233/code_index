{"summary": "Implements a basic residual block for ResNet models, applying two sequential 3×3 convolutional layers with normalization and activation, and combines the transformed output with the original input via a skip connection.", "business_intent": "Provide a reusable component for building deep residual neural networks used in image classification and other computer‑vision applications, simplifying the creation and training of very deep models.", "keywords": ["ResNet", "residual block", "3x3 convolution", "skip connection", "deep learning", "image classification", "Flax", "neural network module", "batch normalization", "activation function"], "summary_hash": "8f7377c80bb4", "cached_at": "2026-02-09T08:53:25+00:00"}