{"summary": "Encapsulates the outputs of the VipLlava causal language model, including optional loss, token prediction scores, cached attention key/value tensors for fast autoregressive decoding, per‑layer hidden representations, attention weight matrices, and image‑related hidden states from the vision encoder.", "business_intent": "Standardize the model’s result payload so that downstream applications can access loss for training, logits for token generation, cached states for efficient sequential inference, and multimodal embeddings for further processing or analysis.", "keywords": ["loss", "logits", "past_key_values", "hidden_states", "attentions", "image_hidden_states", "causal language model", "autoregressive", "multimodal", "generation", "caching"], "summary_hash": "0bc59fa929cd", "cached_at": "2026-02-09T09:24:02+00:00"}