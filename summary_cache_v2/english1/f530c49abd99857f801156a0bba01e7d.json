{"summary": "The module defines a metric class that evaluates AI‑generated text summaries. It computes several quality dimensions—including conciseness, relevance to source content via question‑answer checks, and an aggregated score—by extracting keyphrases, generating questions and answers, and leveraging LLM‑based prompts.", "business_intent": "Provide an automated, quantitative way to assess the performance of summarization components in retrieval‑augmented generation systems, enabling developers to monitor, compare, and improve the quality of generated summaries.", "keywords": ["summarization evaluation", "conciseness metric", "question‑answer relevance", "keyphrase extraction", "LLM‑based scoring", "RAG quality assessment", "automated metric", "text summary analysis"], "summary_hash": "ae1b7d113dcb", "cached_at": "2026-02-08T22:50:06+00:00"}