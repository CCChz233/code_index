{"summary": "A container class that encapsulates the tensors produced by a transformer model, including the final hidden states, optional cached key/value tensors for fast sequential generation, and optional per‑layer hidden states and attention matrices.", "business_intent": "Facilitate downstream processing and efficient text generation by providing a unified, cache‑aware output structure that can be consumed by inference pipelines, analysis tools, or further model components.", "keywords": ["transformer", "model output", "past_key_values", "caching", "sequential decoding", "hidden_state", "attention", "cross_attention", "hidden_states"], "summary_hash": "25224ca5bb7c", "cached_at": "2026-02-09T06:28:17+00:00"}