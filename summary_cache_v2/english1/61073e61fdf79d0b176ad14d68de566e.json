{"summary": "Provides a router strategy that tracks and limits tokens‑per‑minute (TPM) and requests‑per‑minute (RPM) for each model deployment. It offers thread‑safe logging, pre‑call validation, and batch retrieval of deployment data from Redis, using a dual cache to maintain per‑model counters and ensure atomic increments.", "business_intent": "Enable safe, balanced routing of AI model requests by enforcing TPM/RPM quotas, preventing overload of any deployment, and offering observability through logging.", "keywords": ["TPM", "RPM", "rate limiting", "router strategy", "LiteLLM", "caching", "Redis", "thread‑safe", "logging", "model deployment", "usage counters"], "summary_hash": "c78a95d6e222", "cached_at": "2026-02-08T07:42:18+00:00"}