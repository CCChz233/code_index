{"summary": "Provides dataset classes that wrap raw text prompts for Megatron‑based language models (GPT and T5), handling tokenization, configuration for generation or log‑probability calculation, and exposing list‑like indexing for downstream inference pipelines.", "business_intent": "Enable efficient preparation and handling of inference requests for large language models by converting user prompts into tokenized datasets suitable for generation or evaluation tasks.", "keywords": ["dataset", "language modeling", "GPT", "T5", "Megatron", "tokenization", "inference", "generation", "log‑probability", "masking", "PyTorch"], "summary_hash": "acdcfab807b6", "cached_at": "2026-02-08T11:31:16+00:00"}