{"summary": "This module implements utilities to compile MONAI neural network models into TensorRT inference engines. It handles conversion from PyTorch to ONNX, builds and manages TensorRT engines with dynamic shape support, validates input configurations, and provides automatic fallback to standard PyTorch execution when the compiled engine cannot process a given input.", "business_intent": "Accelerate medical imaging inference pipelines by leveraging TensorRT's high‑performance execution while preserving seamless integration with existing PyTorch‑based MONAI workflows.", "keywords": ["TensorRT", "ONNX", "PyTorch", "MONAI", "model compilation", "inference acceleration", "dynamic shape handling", "fallback mechanism", "medical imaging", "performance optimization"], "summary_hash": "e699a4f8897d", "cached_at": "2026-02-08T13:04:24+00:00"}