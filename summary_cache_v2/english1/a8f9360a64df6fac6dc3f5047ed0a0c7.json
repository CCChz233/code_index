{"summary": "This module defines a minimal model and dataset used in tests to verify that rank information is correctly propagated and reported when training with multi‑node Distributed Data Parallel (DDP) in the NeMo framework. It includes utilities to configure an experiment manager, instantiate a distributed trainer when possible, execute the model, retrieve rank details, and clean up temporary resources.", "business_intent": "Validate and ensure reliable handling of process ranks during multi‑node distributed training, supporting robust deployment of NeMo models in large‑scale GPU clusters.", "keywords": ["NeMo", "ModelPT", "distributed training", "rank", "DDP", "multi-node", "PyTorch Lightning", "testing", "dataset", "model setup", "cleanup"], "summary_hash": "ddc65c8fb1be", "cached_at": "2026-02-08T10:26:41+00:00"}