{"summary": "A utility that transforms raw text examples into fixed‑size input and target tensors suitable for training a T5 model with span‑masked language modeling, handling tokenization, random span masking, sentinel token insertion, and padding to the configured lengths.", "business_intent": "Generate ready‑to‑train batches for T5‑based sequence‑to‑sequence models that use span‑mask pre‑training, enabling consistent input/target dimensions for efficient model training.", "keywords": ["T5", "span masking", "language modeling", "data collator", "tokenizer", "noise density", "sentinel tokens", "padding", "Flax", "batch preparation"], "summary_hash": "bd058c7a580b", "cached_at": "2026-02-09T06:14:04+00:00"}