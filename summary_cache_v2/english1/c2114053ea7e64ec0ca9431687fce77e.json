{"summary": "Utility module that implements the core logic for Dask DataFrame's Parquet I/O, including engine selection, metadata aggregation, filesystem handling, default block size computation, and partition management, along with assorted helper functions for path analysis and option processing.", "business_intent": "Provide a robust, scalable interface for reading and writing Parquet files in a distributed Dask environment, ensuring efficient metadata handling and optimal data partitioning across various storage backends.", "keywords": ["parquet", "dask", "dataframe", "io", "metadata", "filesystem", "block size", "partitioning", "engine", "utilities"], "summary_hash": "958a21545171", "cached_at": "2026-02-08T23:26:21+00:00"}