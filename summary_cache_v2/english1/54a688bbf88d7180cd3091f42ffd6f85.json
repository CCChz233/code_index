{"summary": "Provides utilities for measuring and reporting the execution throughput of PyTorch workloads. It maintains a sliding window of recent measurements to compute rolling averages of processed batches, samples, items and floating‑point operations per second, both per device and aggregated across multiple devices. A monitor class automatically increments step counts and formats the metrics for logging, while an internal fixed‑size container ensures monotonic time stamps.", "business_intent": "Enable developers and researchers to monitor and optimise the performance of deep‑learning training or inference pipelines, facilitating detection of bottlenecks, scaling analysis, and resource‑efficiency reporting.", "keywords": ["throughput", "performance monitoring", "rolling average", "device aggregation", "FLOPs", "step counter", "logging", "monotonic window", "PyTorch", "Lightning Fabric"], "summary_hash": "44235b245dc0", "cached_at": "2026-02-08T09:03:21+00:00"}