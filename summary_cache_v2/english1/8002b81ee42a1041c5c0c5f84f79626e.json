{"summary": "A preprocessing component that takes a collection of image tensors, scales each to a specified target size, and outputs both the resized tensors and their original dimensions for downstream processing.", "business_intent": "Standardize input image dimensions for machine‑learning models while retaining size metadata needed for later stages such as bounding‑box scaling or result visualization.", "keywords": ["image preprocessing", "tensor resizing", "target dimensions", "original size preservation", "computer vision pipeline", "data normalization"], "summary_hash": "0722e2ee3c0b", "cached_at": "2026-02-09T11:51:27+00:00"}