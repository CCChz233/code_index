{"summary": "A unified processor that combines a document image feature extractor with a multilingual XLM‑RoBERTa tokenizer, delivering integrated image preprocessing and tokenization capabilities for the Donut model.", "business_intent": "Streamline the pipeline for transforming document images into token sequences suitable for language‑model inference, enabling batch decoding, feature extraction, and token handling through a single interface.", "keywords": ["image preprocessing", "multilingual tokenization", "XLM‑RoBERTa", "Donut model", "feature extraction", "batch decoding", "document OCR", "processor integration"], "summary_hash": "491ad08101a7", "cached_at": "2026-02-09T09:41:26+00:00"}