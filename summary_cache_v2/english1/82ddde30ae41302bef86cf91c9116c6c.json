{"summary": "Provides a reusable Vision Transformer (ViT) block that combines multi‑head self‑attention, a feed‑forward MLP, layer normalization and residual connections to process image patches as token sequences.", "business_intent": "Facilitates the construction of transformer‑based deep learning models for medical imaging applications such as segmentation, classification, and detection within the MONAI framework.", "keywords": ["vision transformer", "self-attention", "multi-head attention", "MLP", "layer normalization", "residual connection", "image patches", "token sequence", "medical imaging", "deep learning"], "summary_hash": "8e3e1d3fc948", "cached_at": "2026-02-08T13:21:52+00:00"}