{"summary": "A neural network component that implements a multi‑layer perceptron block with a two‑fold channel expansion, serving as a compact feed‑forward module within transformer‑based models.", "business_intent": "Offers an efficient feature‑mixing layer for deep learning systems, especially vision transformers, by providing a reduced‑size yet expressive transformation stage compared to standard four‑fold expansion blocks.", "keywords": ["MLP", "feed-forward", "channel expansion", "vision transformer", "deep learning", "neural network layer", "efficient architecture"], "summary_hash": "0454c4b0424b", "cached_at": "2026-02-09T08:38:46+00:00"}