{"summary": "The evaluation package supplies a collection of metric calculators for CrossEncoder models, covering binary and multi‑class accuracy, precision/F1 scoring, correlation of continuous predictions, and ranking effectiveness such as MRR and NDCG. Each evaluator processes sentence‑pair inputs, obtains model scores, compares them with reference labels, logs the outcomes, and optionally persists detailed results.", "business_intent": "Provide researchers and engineers with ready‑to‑use tools to quantitatively assess the performance of cross‑encoder sentence‑pair models across classification, regression, and re‑ranking tasks, enabling model comparison, tuning, and reporting.", "keywords": ["cross‑encoder", "evaluation", "accuracy", "binary classification", "softmax", "precision", "F1", "macro‑averaged", "correlation", "Pearson", "Spearman", "ranking", "re‑ranking", "MRR", "NDCG", "metrics", "logging", "CSV export"], "summary_hash": "0b1712d85d27", "cached_at": "2026-02-08T13:59:31+00:00"}