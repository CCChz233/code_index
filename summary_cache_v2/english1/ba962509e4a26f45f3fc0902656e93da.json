{"summary": "Defines the core transformer components for the Flux architecture used in Stable Diffusion 3, including single and stacked transformer blocks, attention processors, and supporting utilities such as positional embeddings, adaptive layer norms, and PEFT adapter integration, all built on PyTorch.", "business_intent": "Enable efficient and configurable transformer-based processing of image latent tensors within diffusion models, facilitating high‑quality image generation and easy fine‑tuning through parameter-efficient adapters.", "keywords": ["Flux", "Transformer", "MMDiT", "Stable Diffusion 3", "Attention", "2D model", "Adaptive LayerNorm", "PEFT", "PyTorch", "Diffusion", "Positional Embedding", "NPU support"], "summary_hash": "b9e57ce210b4", "cached_at": "2026-02-09T05:30:36+00:00"}