{"summary": "A decorator class that wraps a SentenceTransformer's forward method to cache its embedding output, allowing the cached representations to be resized and reused for multiple loss computations without recomputing embeddings each time.", "business_intent": "Reduce computational overhead and accelerate training or evaluation of sentence embedding models that require multiple dimensionalities, thereby improving efficiency and scalability.", "keywords": ["caching", "decorator", "forward pass", "sentence transformer", "embeddings", "dimensionality reduction", "loss calculation", "efficiency", "model wrapper"], "summary_hash": "a97039f15d38", "cached_at": "2026-02-08T13:45:26+00:00"}