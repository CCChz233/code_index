{"summary": "Provides a lightweight masked language modeling head tailored for the BigBird transformer, converting encoder hidden states into token prediction logits.", "business_intent": "Facilitates fine‑tuning or inference of BigBird models on masked token prediction tasks such as pre‑training, text completion, and downstream NLP applications.", "keywords": ["BigBird", "masked language modeling", "MLM head", "transformer", "neural network", "forward pass", "NLP", "language model", "token prediction"], "summary_hash": "ddb6dfc31f89", "cached_at": "2026-02-09T08:47:29+00:00"}