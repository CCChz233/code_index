{"summary": "Utility module that processes incremental chunks received from LLM streaming APIs, merges them in order, computes token usage statistics, assembles the final chat or audio response, and injects hidden metadata into the model output.", "business_intent": "Enable applications to reliably reconstruct complete LLM responses from streamed fragments while accurately tracking usage metrics and handling special content such as audio payloads.", "keywords": ["streaming", "chunk aggregation", "LLM", "token usage", "chat completion", "audio base64", "response construction", "metadata handling"], "summary_hash": "3b1d34dc8b4b", "cached_at": "2026-02-08T07:45:29+00:00"}