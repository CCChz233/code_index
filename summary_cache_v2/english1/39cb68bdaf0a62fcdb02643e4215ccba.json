{"summary": "Implements an attention-based mapper that projects textual embeddings into the feature space required by the OneFormer architecture.", "business_intent": "Provide a reusable component that fuses text information via attention, allowing downstream vision-language models to leverage textual context for tasks like segmentation or classification.", "keywords": ["attention", "text embedding", "feature projection", "OneFormer", "neural network", "forward pass", "mapping", "multimodal"], "summary_hash": "fa99ff7026ae", "cached_at": "2026-02-09T09:56:14+00:00"}