{"summary": "A neural module that computes bidirectional (two‑way) attention between two input tensors, producing enriched representations that capture mutual contextual information.", "business_intent": "Improve feature interaction for tasks such as multimodal fusion, language‑vision alignment, or any scenario requiring reciprocal attention between two data streams.", "keywords": ["attention", "bidirectional", "cross‑attention", "neural network", "feature fusion", "transformer"], "summary_hash": "742d1d43edec", "cached_at": "2026-02-08T11:34:24+00:00"}