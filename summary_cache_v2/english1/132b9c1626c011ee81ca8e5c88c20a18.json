{"summary": "Provides the core logic for assessing the correctness of executable code produced by AI models, including loading reference data, matching outputs, and applying various checking strategies (simple, parallel, REST‑based), while defining custom exceptions for authentication and API response errors.", "business_intent": "Enable reliable benchmarking of model‑generated code by automatically validating its behavior against expected results, supporting scalable evaluation workflows and robust error handling for authenticated API checks.", "keywords": ["executable evaluation", "model output verification", "ground truth comparison", "output pattern matching", "parallel checking", "REST-based validation", "custom exceptions", "authentication handling", "API response validation"], "summary_hash": "96aecc895322", "cached_at": "2026-02-08T12:46:43+00:00"}