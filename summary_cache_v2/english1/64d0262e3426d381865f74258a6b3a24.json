{"summary": "Implements the GATv2 graph convolution layer, which computes attention coefficients between each node and its neighbors using learnable linear projections and a LeakyReLU‑based score, applies softmax, optional dropout, and aggregates multi‑head messages to produce updated node embeddings. Supports homogeneous and bipartite graphs, residual connections, activation functions, bias, weight sharing, and configurable handling of zero‑in‑degree nodes.", "business_intent": "Provide a flexible, attention‑based message‑passing layer for graph neural networks, enabling models to learn rich node representations for downstream graph tasks such as node classification, link prediction, and graph classification.", "keywords": ["graph attention network", "GATv2", "graph convolution", "multi‑head attention", "message passing", "node embedding", "dropout", "residual connection", "activation function", "bias", "weight sharing", "zero‑in‑degree handling", "DGL"], "summary_hash": "5db8e8061cb8", "cached_at": "2026-02-08T23:56:16+00:00"}