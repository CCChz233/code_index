{"summary": "Provides utilities for preparing the Google Text Normalization corpus for duplex text‑normalization models, including splitting the raw data into train/dev/test sets and converting the tokenized examples into streamed tar archives suitable for NeMo training.", "business_intent": "Enable rapid development and training of text‑normalization systems by delivering ready‑to‑use, efficiently stored datasets that reduce preprocessing overhead and support scalable model training pipelines.", "keywords": ["text normalization", "dataset preparation", "data splitting", "tarred dataset", "streaming", "tokenization", "transformer tokenizer", "NeMo", "NLP", "duplex"], "summary_hash": "ce9576ce5b8f", "cached_at": "2026-02-08T11:59:30+00:00"}