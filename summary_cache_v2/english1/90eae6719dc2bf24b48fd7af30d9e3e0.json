{"summary": "Defines a NeMo speech‑to‑text model that combines an encoder‑decoder architecture with Connectionist Temporal Classification loss and Byte‑Pair Encoding tokenization. The class encapsulates data preparation, vocabulary management, transcription utilities, decoding configuration, and registration of supported model variants.", "business_intent": "Enable developers and researchers to quickly train, fine‑tune, and deploy high‑accuracy automatic speech recognition systems that leverage subword tokenization for flexible vocabulary handling and efficient CTC‑based decoding.", "keywords": ["ASR", "CTC", "BPE", "speech recognition", "encoder‑decoder", "NeMo", "PyTorch", "transcription", "decoding", "vocabulary management", "pretrained model"], "summary_hash": "1235fdee4403", "cached_at": "2026-02-08T11:10:26+00:00"}