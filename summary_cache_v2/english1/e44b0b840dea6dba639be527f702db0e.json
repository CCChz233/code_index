{"summary": "Provides an abstract interface for defining regularization penalties that can be applied to layer weights or activations, allowing the penalty to be computed as a scalar loss term and incorporated into a modelâ€™s total loss.", "business_intent": "Facilitates the addition of configurable regularization terms (e.g., L1, L2, combined) to neural network layers, supporting custom implementations and serialization so that models can be trained with regularization and later saved or transferred.", "keywords": ["regularization", "penalty", "loss", "layer", "kernel", "bias", "activity", "L1", "L2", "serialization", "config", "callable", "tensor", "model", "training"], "summary_hash": "ecfb905541ec", "cached_at": "2026-02-09T11:52:48+00:00"}