{"summary": "Provides a comprehensive motion‑aware UNet implementation for video diffusion models, combining a 3D transformer core with cross‑attention down‑sampling and up‑sampling blocks, motion adapters, and modular motion components to process spatio‑temporal latent tensors.", "business_intent": "Enables AI systems that generate, edit, or enhance animated video content by offering a flexible, temporally‑conditioned UNet architecture suitable for diffusion‑based video synthesis and motion‑focused generative pipelines.", "keywords": ["UNet", "motion", "video diffusion", "3D transformer", "cross-attention", "downsampling", "upsampling", "temporal conditioning", "generative AI", "latent representation"], "summary_hash": "c72aa1f9b9b1", "cached_at": "2026-02-09T05:28:59+00:00"}