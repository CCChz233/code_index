{"summary": "TensorFlow implementation of the BLIP text encoder augmented with a language modeling head, providing methods for building, calling, cache handling, and generation preparation.", "business_intent": "Allow developers to leverage a pre‑trained or fine‑tuned BLIP text model for text generation, captioning, and other multimodal language tasks within TensorFlow workflows.", "keywords": ["TensorFlow", "BLIP", "text encoder", "language modeling head", "text generation", "embeddings", "cache reordering", "generation preparation", "multimodal", "pretrained model"], "summary_hash": "bb822d34bc83", "cached_at": "2026-02-09T10:09:54+00:00"}