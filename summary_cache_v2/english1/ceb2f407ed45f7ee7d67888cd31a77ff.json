{"summary": "This module implements the decision‑making logic for selecting the appropriate large language model (LLM) provider based on supplied configuration parameters. It evaluates compatibility with OpenAI‑style APIs, distinguishes Azure‑hosted non‑OpenAI models, and includes special handling for Cohere chat models, while also retrieving necessary secrets for authentication.", "business_intent": "To provide a flexible, centralized mechanism that routes requests to the correct LLM service (e.g., OpenAI, Azure, Cohere) according to user settings, enabling seamless multi‑provider integration within the application.", "keywords": ["LLM provider selection", "OpenAI compatibility", "Azure model handling", "Cohere chat integration", "dynamic routing", "configuration parsing", "secret management"], "summary_hash": "5c2491d56a31", "cached_at": "2026-02-08T07:45:50+00:00"}