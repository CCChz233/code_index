{"summary": "Manages dynamic gradient scaling for model-parallel training, detecting overflow across tensor-parallel ranks during optimizer steps and scaler updates.", "business_intent": "Provides robust mixed-precision training in distributed settings by identifying gradient infinities across parallel ranks, adjusting the scaling factor, and coordinating safe optimizer execution.", "keywords": ["gradient scaling", "overflow detection", "tensor parallel", "model parallel", "distributed training", "mixed precision", "optimizer step coordination", "scaling factor adjustment", "state management"], "summary_hash": "eaa7e2f34f2a", "cached_at": "2026-02-08T09:42:03+00:00"}