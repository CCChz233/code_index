{"summary": "Manages the lifecycle and execution of ONNX Runtime models, handling loading, preparation of inputs, optimization, quantization, and validation of execution providers, while exposing simple interfaces for inference operations such as forward passes and text generation.", "business_intent": "Enable high-performance, production-ready inference of machine-learning models through ONNX Runtime by providing automated model preparation, optimization, and deployment capabilities.", "keywords": ["ONNX Runtime", "model loading", "optimization", "quantization", "inference backend", "execution provider validation", "input preparation", "distributed inference", "text generation"], "summary_hash": "e9c814c4c5b6", "cached_at": "2026-02-09T02:26:45+00:00"}