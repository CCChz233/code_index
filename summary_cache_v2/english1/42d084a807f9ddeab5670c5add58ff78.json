{"summary": "This module implements centralized configuration and request transformation logic for OpenAI's O1 reasoning model family. It adapts message structures and maps generic LiteLLM parameters to the specific fields required by the OpenAI API, handling special cases such as image inputs, system role conversion, streaming emulation, and optional dropping of tools, response formats, and logprob settings.", "business_intent": "To extend LiteLLM's capabilities to seamlessly integrate OpenAI O1 models, ensuring correct API interaction and parameter handling so developers can leverage advanced reasoning models without manual request adjustments.", "keywords": ["OpenAI", "O1", "configuration", "message transformation", "parameter mapping", "LiteLLM", "chat models", "reasoning", "API compatibility", "streaming", "tools", "response format", "logprobs", "image modality"], "summary_hash": "eab503b88047", "cached_at": "2026-02-08T07:57:01+00:00"}