{"summary": "A test suite that validates the behavior of the streaming chunk builder across different LLM response scenarios, including empty chunks, function and tool calls, usage data, multiple tool calls, audio outputs, and prompt caching.", "business_intent": "To guarantee that the streaming chunk builder correctly assembles and interprets streamed responses from language model APIs, supporting advanced features like function/tool invocation, usage tracking, audio handling, and caching for reliable integration in production applications.", "keywords": ["streaming", "chunk builder", "LLM", "litellm", "openai", "function call", "tool call", "usage tracking", "audio output", "prompt caching", "pytest", "async"], "summary_hash": "5eefaba1bbc0", "cached_at": "2026-02-08T07:25:20+00:00"}