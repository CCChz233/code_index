{"summary": "A wrapper that augments any pretrained seq2seq language model with an additional value head, exposing standard model utilities and generation capabilities.", "business_intent": "Enable reinforcement‑learning‑based fine‑tuning of sequence‑to‑sequence models by providing value predictions alongside text generation.", "keywords": ["seq2seq", "value head", "language model", "reinforcement learning", "model wrapper", "generation", "pretrained", "huggingface", "push to hub", "state dict"], "summary_hash": "8641a726617c", "cached_at": "2026-02-09T05:55:37+00:00"}