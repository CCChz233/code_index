{"summary": "This module implements support for Vertex AI and Google AI Studio context‑caching. It includes utilities to translate chat messages between OpenAI and Gemini/Vertex AI representations, handling system prompts and cached content requests, and a high‑level client that manages authentication, builds request URLs, and performs cache verification, creation, and retrieval operations in both synchronous and asynchronous modes.", "business_intent": "Provide developers with a streamlined way to leverage Vertex AI's context‑caching capabilities, reducing token consumption and latency for LLM applications that need to reuse prior conversation context.", "keywords": ["context caching", "Vertex AI", "Google AI Studio", "message transformation", "OpenAI format", "Gemini format", "authentication", "API client", "synchronous", "asynchronous", "cache verification", "cache creation", "cache retrieval", "system messages", "error handling"], "summary_hash": "a4162dbee605", "cached_at": "2026-02-08T08:10:22+00:00"}